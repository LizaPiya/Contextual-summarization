{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "825838cd-aeac-4593-8920-e02e2a24e768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers huggingface_hub langchain_community\n",
    "!pip install -q --upgrade accelerate\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q neo4j\n",
    "!pip install -q --upgrade accelerate\n",
    "!pip install -q -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "161b54d3-791b-4cd4-91be-89900c0e18e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "d4cecdb2-9491-4594-8dcf-bc25c2153a31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Graphdb configuration\n",
    "NEO4J_URI=\"neo4j+s://0e49642b.databases.neo4j.io\"\n",
    "NEO4J_USERNAME=\"neo4j\"\n",
    "NEO4J_PASSWORD=\"XB8uxzAOAquawNok7UiA5DlrnC2oncJdgPfNUmWYvnI\"\n",
    "\n",
    "import os\n",
    "os.environ[\"NEO4J_URI\"]=NEO4J_URI\n",
    "os.environ[\"NEO4J_USERNAME\"]=NEO4J_USERNAME\n",
    "os.environ[\"NEO4J_PASSWORD\"]=NEO4J_PASSWORD\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "neo4j_graph=Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b4d962d6-9fc0-4221-809d-f4ce31bdcfd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.graphs.neo4j_graph.Neo4jGraph at 0x7f2b36ee8460>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neo4j_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84896e12-325a-4b65-9e74-e0157df207f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          note_id                                              input  \\\n",
      "0  16002318-DS-17  <SEX> F <SERVICE> SURGERY <ALLERGIES> Iodine /...   \n",
      "1   15638884-DS-4  <SEX> M <SERVICE> MEDICINE <ALLERGIES> Augment...   \n",
      "2  12435705-DS-14  <SEX> M <SERVICE> MEDICINE <ALLERGIES> ibuprof...   \n",
      "3   12413577-DS-4  <SEX> F <SERVICE> OBSTETRICS/GYNECOLOGY <ALLER...   \n",
      "4  17967161-DS-29  <SEX> M <SERVICE> SURGERY <ALLERGIES> lisinopr...   \n",
      "\n",
      "                                        reduced_text  \\\n",
      "0  <|begin_of_text|><SEX> F <SERVICE> SURGERY <AL...   \n",
      "1  <|begin_of_text|><SEX> M <SERVICE> MEDICINE <A...   \n",
      "2  <|begin_of_text|><SEX> M <SERVICE> MEDICINE <A...   \n",
      "3  <|begin_of_text|><SEX> F <SERVICE> OBSTETRICS/...   \n",
      "4  <|begin_of_text|><SEX> M <SERVICE> SURGERY <AL...   \n",
      "\n",
      "                                            entities  \\\n",
      "0  {'PROBLEM': ['101', '7 pound weight loss', 'a ...   \n",
      "1  {'PROBLEM': ['+', '-', '1 cm area', 'a \" cyst ...   \n",
      "2  {'PROBLEM': ['a 0. 7 x 0. 7 x 0. 7 cm simple c...   \n",
      "3  {'PROBLEM': ['a third - degree uterine prolaps...   \n",
      "4  {'PROBLEM': ['101', 'abuse', 'acute pancreatit...   \n",
      "\n",
      "                                            problems  \\\n",
      "0  ['101', '7 pound weight loss', 'a fever', 'a l...   \n",
      "1  ['+', '-', '1 cm area', 'a \" cyst \"', 'a 2cm d...   \n",
      "2  ['a 0. 7 x 0. 7 x 0. 7 cm simple cyst', 'a 2. ...   \n",
      "3  ['a third - degree uterine prolapse', 'abnorma...   \n",
      "4  ['101', 'abuse', 'acute pancreatitis', 'angina...   \n",
      "\n",
      "                                          treatments  \\\n",
      "0  ['abdominal exercises', 'albuterol sulfate', '...   \n",
      "1  ['a bankart repair', 'a nicotine patch', 'a st...   \n",
      "2  ['2', 'a prolonged course', 'ampicillin', 'ant...   \n",
      "3  ['a stool softener', 'acetaminophen', 'admissi...   \n",
      "4  ['a', 'a 3 mm x 40 mm balloon percutaneous tra...   \n",
      "\n",
      "                                               tests  \n",
      "0         ['b12', 'bmi', 'calcium', 'physical exam']  \n",
      "1  ['.', '_', 'a', 'a ct scan', 'absbaso', 'abseo...  \n",
      "2  ['16s rdna primer set', 'aa', 'abl', 'acid fas...  \n",
      "3  ['hct', 'hgb', 'mch', 'mchc', 'mcv', 'nadr', '...  \n",
      "4  ['angap', 'blood', 'blood calcium', 'blood ck ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "merged_df = pd.read_csv(\"merged_data.csv\")\n",
    "\n",
    "# Check the data\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb79409c-5ca6-47d9-824b-dd7d474dd8bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['a completion colectomy', 'a new ileostomy', 'advil', 'advil ( ibuprofen )', 'albuteral', 'alcohol', 'allopurinol', 'allopurinol _', 'amlodipine', 'amoxicillin', 'an over the counter stool softener', 'anterior left - sided component separation', 'any other medications', 'atenolol', 'chemotherapy', 'clonidine', 'codeine', 'cold medication', 'dental procedures', 'discharge medications', 'endoscope', 'enteric tube', 'furosemide', 'hernia repair material', 'hip replacement', 'his previous colostomy', 'inciscional prevena vac', 'invasive procedure', 'lasix', 'left component separation', 'lisinopril', 'major surgical', 'medication', 'medications', 'mesh', 'midline hernia repair', 'narcotic pain medications', 'other sedating medications', 'placement of', 'plastic surgery', 'potassium er', 'primary midline repair', 'r', 'r jp drain serosang', 'radiation', 'removal', 'resection', 'rivaroxaban', 'rivaroxaban [ xarelto ]', 'steri - strips', 'surgery', 'surgical resection', 'symbicort', 'the', 'the drain placement', 'the ileostomy', 'the narcotic pain medication', 'this medication', 'this procedure', 'total colectomy', 'total right hip arthroplasty', 'tylen', 'tylenol', 'vitamin d', 'volume mesenteric free - fluid', 'with', 'xarelto', 'your home blood pressure medications', 'your new ileostomy']\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['treatments'].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d2ef831-4b23-4c1c-b321-012b95004d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><SEX> M <SERVICE> SURGERY <ALLERGIES> Codeine / Tetracycline <ATTENDING> ___ ___ Complaint: Large ___ hernia and sessile polyp <MAJOR SURGICAL OR INVASIVE PROCEDURE> ___ and midline hernia repair, left component separation, retrorectus repair of the stomal hernia primary midline repair with the above-mentioned anterior left-sided component separation and placement of mesh and panniculectomy <HISTORY OF PRESENT ILLNESS> Mr. ___ is a ___ year old male with history of rectal cancer and a longstanding left-sided colostomy. He had a colonoscopy in ___ of this year where a large polyp that was unable to be extracted by endoscope was found by Dr. ___. He was referred to Dr. ___ surgical resection of the polyp. Per last clinic note by Dr. ___: It has been 2 months since I last saw Mr. ___ for his ___ hernia and a month since he underwent colonoscopy with identification of a low-grade cancer proximal to his end colostomy. Since he is last seen there are no changes in his health and well-being. He has no new complaints. He is here to discuss removal of the cancer and management of his large ___ hernia. I discussed with him in detail the findings from Dr. ___ ___ and the pathology report as well as multiple polyps that he has currently and the issue that he generated a cancer in the ___ years since his last colonoscopy. I made out a plan for him by which she would undergo completion colectomy via a midline incision with removal of his previous colostomy and creation of a new ileostomy reinforced with mesh. Also with resultant repair of the stomal hernia where his previous colostomy will have been. I plan to do this in conjunction with Dr. ___ of plastic surgery. He and I and his wife discussed the risks benefits and potential outcomes of a variety of surgical options but they agree that this would be the best option. I plan to have him see Dr. ___ at his earliest convenience, hopefully very soon since he has had some difficulty getting to appointments quickly. In addition I have asked him to check in with his primary care doctor and his cardiologist for medical clearance. He recently had an abdominal CT for other reasons that did not demonstrate any metastatic disease to the liver but he does still need a chest CAT scan as part of routine staging for this new finding. <PAST MEDICAL HISTORY> -Atrial fibrillation, currently not on home Xarelto -Hypertension -Rectal cancer status post resection, chemotherapy and radiation (___) -Hip replacement ___ -Knee replacement ___ <SOCIAL HISTORY> ___ <FAMILY HISTORY> His mother had a stroke in her elderly years. Otherwise, denies any family history of stroke or neurologic disease. <PHYSICAL EXAM> Physical exam ___ VS: 98.6 bp105 / 69 hr93 rr18 93%RA GEN: WD, WN in NAD HEENT: NCAT, EOMI, anicteric CV: Irregular rate and rhythm PULM: No respiratory distress ABD: Obese abdomen, soft, non distended, non tender. Inciscional prevena vac in place. R JP drain serosang. ileostomy with pink stoma with stool/gas in bag EXT: WWP, no CCE NEURO: A&Ox3, no focal neurologic deficits PSYCH: normal judgment/insight, normal memory, normal mood/affect <PERTINENT RESULTS> ADMISSION LABS: ___ 03: 20PM WBC-12.2* RBC-3.42* HGB-10.6* HCT-31.2* MCV-91 MCH-31.0 MCHC-34.0 RDW-12.6 RDWSD-41.4 ___ 03: 20PM NEUTS-88.4* LYMPHS-2.9* MONOS-7.8 EOS-0.0* BASOS-0.2 IM ___ AbsNeut-10.82* AbsLymp-0.36* AbsMono-0.96* AbsEos-0.00* AbsBaso-0.02 ___ 03: 20PM PLT COUNT-191 ___ 03: 15PM GLUCOSE-171* UREA N-20 CREAT-1.8* SODIUM-142 POTASSIUM-4.2 CHLORIDE-104 TOTAL CO2-26 ANION GAP-12 ___ 03: 15PM estGFR-Using this ___ 03: 15PM CALCIUM-8.5 PHOSPHATE-5.0* MAGNESIUM-1.9 ___ 03: 15PM WBC-UNABLE TO. DISCHARGE LABS: ___ 05: 49AM BLOOD WBC-4.5 RBC-2.62* Hgb-8.2* Hct-25.8* MCV-99* MCH-31.3 MCHC-31.8* RDW-13.2 RDWSD-47.2* Plt ___ ___ 05: 49AM BLOOD Glucose-87 UreaN-29* Creat-1.1 Na-137 K-4.5 Cl-104 HCO3-19* AnGap-14 ___ 05: 49AM BLOOD Calcium-8.3* Phos-3.8 Mg-2.0. IMAGING: ___ CT A/P LOWER CHEST: There is a moderate right pleural effusion. There is bibasilar atelectasis. Large calcified granulomas noted in the right lower lobe. No pericardial effusion. ABDOMEN: HEPATOBILIARY: The liver demonstrates homogenous attenuation throughout. A 3.9 cm hypoenhancing lesion in segment ___ is unchanged from prior and likely represents a simple cyst. There is no evidence of intrahepatic or extrahepatic biliary dilatation. The gallbladder is within normal limits. PANCREAS: The pancreas has normal attenuation throughout, without evidence of focal lesions or pancreatic ductal dilatation. There is no peripancreatic stranding. SPLEEN: There is a 7.5 x 8.6 cm heterogeneous lesion with minimal enhancement (when compared to the sure start series) in the anterior peripheral aspect of the spleen, new from exam in ___. There are additional hypodense lesions in the spleen (e.g. 05: 26 and 05: 30). Supple area of hyperenhancement and a peripheral posterior aspect of the spleen (05'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['reduced_text'].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d07a38-ede3-4423-9f4d-c77cb7ae33cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Function to escape and preprocess text for Cypher queries\n",
    "def escape_text(text):\n",
    "    return text.replace(\"'\", \" \")  # Replace apostrophes with spaces\n",
    "\n",
    "# Function to build the Knowledge Graph\n",
    "def build_knowledge_graph_generalized(df, neo4j_graph):\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Building Knowledge Graph\"):\n",
    "        # Extract data\n",
    "        patient_id = escape_text(row['note_id'])\n",
    "        problems = [escape_text(problem) for problem in eval(row['problems'])]\n",
    "        treatments = [escape_text(treatment) for treatment in eval(row['treatments'])]\n",
    "        tests = [escape_text(test) for test in eval(row['tests'])]\n",
    "\n",
    "        # Create Patient node\n",
    "        patient_query = f\"\"\"\n",
    "        MERGE (p:Patient {{id: '{patient_id}'}})\n",
    "        \"\"\"\n",
    "        neo4j_graph.query(patient_query)\n",
    "\n",
    "        # Create Problem nodes and relationships\n",
    "        for problem in problems:\n",
    "            problem_query = f\"\"\"\n",
    "            MERGE (pr:Problem {{title: '{problem}'}})\n",
    "            MERGE (p:Patient {{id: '{patient_id}'}})\n",
    "            MERGE (p)-[:HAS_PROBLEM]->(pr)\n",
    "            \"\"\"\n",
    "            neo4j_graph.query(problem_query)\n",
    "\n",
    "        # Create Treatment nodes and relationships\n",
    "        for treatment in treatments:\n",
    "            treatment_query = f\"\"\"\n",
    "            MERGE (tr:Treatment {{title: '{treatment}'}})\n",
    "            MERGE (p:Patient {{id: '{patient_id}'}})\n",
    "            MERGE (p)-[:WAS_TREATED_WITH]->(tr)\n",
    "            \"\"\"\n",
    "            neo4j_graph.query(treatment_query)\n",
    "\n",
    "        # Create Test nodes and relationships\n",
    "        for test in tests:\n",
    "            test_query = f\"\"\"\n",
    "            MERGE (t:Test {{title: '{test}'}})\n",
    "            MERGE (p:Patient {{id: '{patient_id}'}})\n",
    "            MERGE (p)-[:UNDERWENT_TEST]->(t)\n",
    "            \"\"\"\n",
    "            neo4j_graph.query(test_query)\n",
    "\n",
    "# Execute the function to build the KG\n",
    "build_knowledge_graph_generalized(merged_df, neo4j_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb2fe5c4-ad94-4851-903d-2120a373b3e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Counts by Type:\n",
      "Node Type: ['Problem'], Count: 3841\n",
      "Node Type: ['Treatment'], Count: 1686\n",
      "Node Type: ['Test'], Count: 1468\n",
      "Node Type: ['Patient'], Count: 100\n",
      "\n",
      "Relationship Counts by Type:\n",
      "Relationship Type: HAS_PROBLEM, Count: 6760\n",
      "Relationship Type: UNDERWENT_TEST, Count: 5469\n",
      "Relationship Type: WAS_TREATED_WITH, Count: 3214\n",
      "\n",
      "Total Counts:\n",
      "Total Nodes: 7095\n",
      "Total Relationships: 15443\n"
     ]
    }
   ],
   "source": [
    "def get_graph_statistics(neo4j_graph):\n",
    "    # Query to count nodes by type\n",
    "    node_count_query = \"\"\"\n",
    "    MATCH (n)\n",
    "    RETURN labels(n) AS node_type, COUNT(*) AS count\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "\n",
    "    # Query to count relationships by type\n",
    "    relationship_count_query = \"\"\"\n",
    "    MATCH ()-[r]->()\n",
    "    RETURN TYPE(r) AS relationship_type, COUNT(*) AS count\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "\n",
    "    # Query to count total nodes\n",
    "    total_nodes_query = \"\"\"\n",
    "    MATCH (n)\n",
    "    RETURN COUNT(*) AS total_nodes\n",
    "    \"\"\"\n",
    "\n",
    "    # Query to count total relationships\n",
    "    total_relationships_query = \"\"\"\n",
    "    MATCH ()-[r]->()\n",
    "    RETURN COUNT(*) AS total_relationships\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute queries and fetch results\n",
    "    node_counts = neo4j_graph.query(node_count_query)\n",
    "    relationship_counts = neo4j_graph.query(relationship_count_query)\n",
    "    total_nodes = neo4j_graph.query(total_nodes_query)\n",
    "    total_relationships = neo4j_graph.query(total_relationships_query)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Node Counts by Type:\")\n",
    "    for record in node_counts:\n",
    "        print(f\"Node Type: {record['node_type']}, Count: {record['count']}\")\n",
    "\n",
    "    print(\"\\nRelationship Counts by Type:\")\n",
    "    for record in relationship_counts:\n",
    "        print(f\"Relationship Type: {record['relationship_type']}, Count: {record['count']}\")\n",
    "\n",
    "    print(\"\\nTotal Counts:\")\n",
    "    print(f\"Total Nodes: {total_nodes[0]['total_nodes']}\")\n",
    "    print(f\"Total Relationships: {total_relationships[0]['total_relationships']}\")\n",
    "\n",
    "# Call the function\n",
    "get_graph_statistics(neo4j_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ee5a918-312d-4c4b-8918-ba89dfe8c1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irrelevant nodes and relationships have been deleted.\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# GraphDB configuration\n",
    "NEO4J_URI = \"neo4j+s://0e49642b.databases.neo4j.io\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"XB8uxzAOAquawNok7UiA5DlrnC2oncJdgPfNUmWYvnI\"\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "# Function to execute a query\n",
    "def execute_query(query):\n",
    "    with driver.session() as session:\n",
    "        session.run(query)\n",
    "\n",
    "# Query to delete irrelevant relationships\n",
    "delete_relationships_query = \"\"\"\n",
    "MATCH ()-[r]->()\n",
    "WHERE NOT type(r) IN ['HAS_PROBLEM', 'UNDERWENT_TEST', 'WAS_TREATED_WITH']\n",
    "DELETE r;\n",
    "\"\"\"\n",
    "\n",
    "# Query to delete irrelevant nodes\n",
    "delete_nodes_query = \"\"\"\n",
    "MATCH (n)\n",
    "WHERE NOT labels(n)[0] IN ['Problem', 'Treatment', 'Test', 'Patient']\n",
    "DETACH DELETE n;\n",
    "\"\"\"\n",
    "\n",
    "# Execute queries sequentially\n",
    "execute_query(delete_relationships_query)\n",
    "execute_query(delete_nodes_query)\n",
    "\n",
    "# Close the driver connection\n",
    "driver.close()\n",
    "\n",
    "print(\"Irrelevant nodes and relationships have been deleted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1981a9bc-361b-4b72-ad6b-29f903c22453",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Counts by Type:\n",
      "Node Type: ['Problem'], Count: 3841\n",
      "Node Type: ['Treatment'], Count: 1686\n",
      "Node Type: ['Test'], Count: 1468\n",
      "Node Type: ['Patient'], Count: 100\n",
      "\n",
      "Relationship Counts by Type:\n",
      "Relationship Type: HAS_PROBLEM, Count: 6760\n",
      "Relationship Type: UNDERWENT_TEST, Count: 5469\n",
      "Relationship Type: WAS_TREATED_WITH, Count: 3214\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# GraphDB configuration\n",
    "NEO4J_URI = \"neo4j+s://0e49642b.databases.neo4j.io\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"XB8uxzAOAquawNok7UiA5DlrnC2oncJdgPfNUmWYvnI\"\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "# Function to execute a query and return results\n",
    "def fetch_query_results(query):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        return [record.data() for record in result]\n",
    "\n",
    "# Query to count nodes by label\n",
    "node_count_query = \"\"\"\n",
    "MATCH (n)\n",
    "RETURN labels(n) AS NodeType, COUNT(n) AS Count\n",
    "ORDER BY Count DESC\n",
    "\"\"\"\n",
    "\n",
    "# Query to count relationships by type\n",
    "relationship_count_query = \"\"\"\n",
    "MATCH ()-[r]->()\n",
    "RETURN type(r) AS RelationshipType, COUNT(r) AS Count\n",
    "ORDER BY Count DESC\n",
    "\"\"\"\n",
    "\n",
    "# Fetch and display node counts\n",
    "node_counts = fetch_query_results(node_count_query)\n",
    "print(\"Node Counts by Type:\")\n",
    "for record in node_counts:\n",
    "    print(f\"Node Type: {record['NodeType']}, Count: {record['Count']}\")\n",
    "\n",
    "# Fetch and display relationship counts\n",
    "relationship_counts = fetch_query_results(relationship_count_query)\n",
    "print(\"\\nRelationship Counts by Type:\")\n",
    "for record in relationship_counts:\n",
    "    print(f\"Relationship Type: {record['RelationshipType']}, Count: {record['Count']}\")\n",
    "\n",
    "# Close the driver connection\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26702fb-a290-4f67-95e5-947a5ad38027",
   "metadata": {},
   "source": [
    "### Summarization Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19b312c2-8de2-492f-9729-f26fdc5e88d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Use your Hugging Face token\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3710ebf-d246-463e-a624-23f06e5effb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup and quantization configuration done.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variable for better memory management\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Configure quantization (8-bit)\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_enable_fp32_cpu_offload=True\n",
    ")\n",
    "print(\"Environment setup and quantization configuration done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a4e3f4-d6d2-4a82-8aee-b59432ae0463",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.3 requires dill>=0.3.9, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.3 requires multiprocess>=0.70.17, but you have multiprocess 0.70.16 which is incompatible.\n",
      "s3fs 2024.12.0 requires fsspec==2024.12.0.*, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install -q --upgrade packaging\n",
    "#!pip install -q --upgrade transformers bitsandbytes datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a377856-874c-48fc-a542-1d0f50edbf6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Model and Tokenizer: 100%|██████████| 2/2 [00:02<00:00,  1.08s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "print(\"Loading model and tokenizer...\")\n",
    "with tqdm(total=2, desc=\"Initializing Model and Tokenizer\", unit=\"step\") as pbar:\n",
    "    model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\",\n",
    "        #output_attentions=True,  # Enable attention outputs for AGTD\n",
    "        #return_dict_in_generate=True  # Ensures attention outputs are generated\n",
    "    )\n",
    "    pbar.update(1)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.padding_side = 'left'\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    pbar.update(1)\n",
    "print(\"Model and tokenizer loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7d4119c-3dec-452f-b2a6-4518e76ad5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>input</th>\n",
       "      <th>reduced_text</th>\n",
       "      <th>entities</th>\n",
       "      <th>problems</th>\n",
       "      <th>treatments</th>\n",
       "      <th>tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16002318-DS-17</td>\n",
       "      <td>&lt;SEX&gt; F &lt;SERVICE&gt; SURGERY &lt;ALLERGIES&gt; Iodine /...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;SEX&gt; F &lt;SERVICE&gt; SURGERY &lt;AL...</td>\n",
       "      <td>{'PROBLEM': ['101', '7 pound weight loss', 'a ...</td>\n",
       "      <td>['101', '7 pound weight loss', 'a fever', 'a l...</td>\n",
       "      <td>['abdominal exercises', 'albuterol sulfate', '...</td>\n",
       "      <td>['b12', 'bmi', 'calcium', 'physical exam']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15638884-DS-4</td>\n",
       "      <td>&lt;SEX&gt; M &lt;SERVICE&gt; MEDICINE &lt;ALLERGIES&gt; Augment...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;SEX&gt; M &lt;SERVICE&gt; MEDICINE &lt;A...</td>\n",
       "      <td>{'PROBLEM': ['+', '-', '1 cm area', 'a \" cyst ...</td>\n",
       "      <td>['+', '-', '1 cm area', 'a \" cyst \"', 'a 2cm d...</td>\n",
       "      <td>['a bankart repair', 'a nicotine patch', 'a st...</td>\n",
       "      <td>['.', '_', 'a', 'a ct scan', 'absbaso', 'abseo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          note_id                                              input  \\\n",
       "0  16002318-DS-17  <SEX> F <SERVICE> SURGERY <ALLERGIES> Iodine /...   \n",
       "1   15638884-DS-4  <SEX> M <SERVICE> MEDICINE <ALLERGIES> Augment...   \n",
       "\n",
       "                                        reduced_text  \\\n",
       "0  <|begin_of_text|><SEX> F <SERVICE> SURGERY <AL...   \n",
       "1  <|begin_of_text|><SEX> M <SERVICE> MEDICINE <A...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'PROBLEM': ['101', '7 pound weight loss', 'a ...   \n",
       "1  {'PROBLEM': ['+', '-', '1 cm area', 'a \" cyst ...   \n",
       "\n",
       "                                            problems  \\\n",
       "0  ['101', '7 pound weight loss', 'a fever', 'a l...   \n",
       "1  ['+', '-', '1 cm area', 'a \" cyst \"', 'a 2cm d...   \n",
       "\n",
       "                                          treatments  \\\n",
       "0  ['abdominal exercises', 'albuterol sulfate', '...   \n",
       "1  ['a bankart repair', 'a nicotine patch', 'a st...   \n",
       "\n",
       "                                               tests  \n",
       "0         ['b12', 'bmi', 'calcium', 'physical exam']  \n",
       "1  ['.', '_', 'a', 'a ct scan', 'absbaso', 'abseo...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e1b83384-d121-4fd2-9188-13db75bbf709",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Initializing Model and Tokenizer:   0%|          | 0/2 [00:00<?, ?step/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Initializing Model and Tokenizer:  50%|█████     | 1/2 [00:01<00:01,  1.85s/step]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Initializing Model and Tokenizer: 100%|██████████| 2/2 [00:02<00:00,  1.24s/step]\u001b[A\u001b[A\u001b[A\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n",
      "Pipeline and generation parameters are ready.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Model name\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# Load the model with quantization\n",
    "print(\"Loading model and tokenizer...\")\n",
    "with tqdm(total=2, desc=\"Initializing Model and Tokenizer\", unit=\"step\") as pbar:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quantization_config,  # Quantization applied here\n",
    "        device_map=\"auto\",  # Use `accelerate` to manage device allocation\n",
    "    )\n",
    "    pbar.update(1)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.padding_side = 'left'\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id  # Avoid padding errors\n",
    "    pbar.update(1)\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully.\")\n",
    "\n",
    "# Initialize the pipeline\n",
    "summarizer = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,  # Pass pre-loaded model\n",
    "    tokenizer=tokenizer,  # Pass pre-loaded tokenizer\n",
    ")\n",
    "\n",
    "# Generation parameters\n",
    "generation_params = {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.8,\n",
    "    \"temperature\": 0.9,\n",
    "    \"top_k\": 100,\n",
    "    \"max_new_tokens\": 300,\n",
    "    \"repetition_penalty\": 1.1\n",
    "}\n",
    "\n",
    "print(\"Pipeline and generation parameters are ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71425d6-950c-4aa1-82b7-2cc6182a4977",
   "metadata": {},
   "source": [
    "### Construct Zero Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1416acb9-5a11-405b-8020-6f25df14d82e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Function to retrieve context from KG with limits\n",
    "def retrieve_context(patient_id, neo4j_graph, limit=2):\n",
    "    query = f\"\"\"\n",
    "    MATCH (p:Patient {{id: '{patient_id}'}})-[r]-(n)\n",
    "    WHERE type(r) IN ['HAS_PROBLEM', 'UNDERWENT_TEST', 'WAS_TREATED_WITH']\n",
    "    RETURN n.title AS node, type(r) AS relationship_type\n",
    "    \"\"\"\n",
    "    results = neo4j_graph.query(query)\n",
    "    context = {\"Problems\": [], \"Treatments\": [], \"Tests\": []}\n",
    "    counts = {\"HAS_PROBLEM\": 0, \"WAS_TREATED_WITH\": 0, \"UNDERWENT_TEST\": 0}  # Initialize counts\n",
    "\n",
    "    for record in results:\n",
    "        relationship_type = record[\"relationship_type\"]\n",
    "        node = record[\"node\"]\n",
    "\n",
    "        # Check limits for each category and append if within limit\n",
    "        if relationship_type == \"HAS_PROBLEM\" and counts[\"HAS_PROBLEM\"] < limit:\n",
    "            context[\"Problems\"].append(node)\n",
    "            counts[\"HAS_PROBLEM\"] += 1\n",
    "        elif relationship_type == \"WAS_TREATED_WITH\" and counts[\"WAS_TREATED_WITH\"] < limit:\n",
    "            context[\"Treatments\"].append(node)\n",
    "            counts[\"WAS_TREATED_WITH\"] += 1\n",
    "        elif relationship_type == \"UNDERWENT_TEST\" and counts[\"UNDERWENT_TEST\"] < limit:\n",
    "            context[\"Tests\"].append(node)\n",
    "            counts[\"UNDERWENT_TEST\"] += 1\n",
    "\n",
    "        # Break early if all categories reach their limits\n",
    "        if all(count == limit for count in counts.values()):\n",
    "            break\n",
    "\n",
    "    return context\n",
    "\n",
    "\n",
    "# Function to construct a zero-shot prompt\n",
    "def construct_zero_shot_prompt(reduced_text, context):\n",
    "    prompt = f\"\"\"\n",
    "    ### Task ###\n",
    "    You are a highly knowledgeable and best medical expert working at NIH. Your task is to summarize clinical notes concisely and professionally using only the information provided in the Input and Context.\n",
    "    - Use a clear, organized structure.\n",
    "    - Summarize in a narrative storytelling tone.\n",
    "    - Avoid technical jargon when unnecessary, and focus on readability.\n",
    "    - Ensure the summary is factual, concise, and consistent with the provided data.\n",
    "\n",
    "    ### Task ###\n",
    "    Summarize the following patient note concisely and professionally in a clear and organized manner:\n",
    "    Input: {reduced_text}\n",
    "    Context: Problems: {context['Problems']}, Treatments: {context['Treatments']}, Tests: {context['Tests']}\n",
    "    Generated Summary:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Function to parse generated summaries\n",
    "def parse_summary_output(output):\n",
    "    if isinstance(output, dict) and \"generated_text\" in output:\n",
    "        return output[\"generated_text\"].split(\"Output:\")[-1].strip()\n",
    "    elif isinstance(output, str):\n",
    "        return output.split(\"Output:\")[-1].strip()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "print(\"Helper functions defined.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b68fb9-10cb-4c3c-b9b5-956fabc09fe6",
   "metadata": {},
   "source": [
    "### three shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "93c1b7f4-9dcc-40e0-88a4-d1ac6a2467eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Function to retrieve context from KG with limits\n",
    "def retrieve_context(patient_id, neo4j_graph, limit=2):\n",
    "    query = f\"\"\"\n",
    "    MATCH (p:Patient {{id: '{patient_id}'}})-[r]-(n)\n",
    "    WHERE type(r) IN ['HAS_PROBLEM', 'UNDERWENT_TEST', 'WAS_TREATED_WITH']\n",
    "    RETURN n.title AS node, type(r) AS relationship_type\n",
    "    \"\"\"\n",
    "    results = neo4j_graph.query(query)\n",
    "    context = {\"Problems\": [], \"Treatments\": [], \"Tests\": []}\n",
    "    counts = {\"HAS_PROBLEM\": 0, \"WAS_TREATED_WITH\": 0, \"UNDERWENT_TEST\": 0}  # Initialize counts\n",
    "\n",
    "    for record in results:\n",
    "        relationship_type = record[\"relationship_type\"]\n",
    "        node = record[\"node\"]\n",
    "\n",
    "        # Check limits for each category and append if within limit\n",
    "        if relationship_type == \"HAS_PROBLEM\" and counts[\"HAS_PROBLEM\"] < limit:\n",
    "            context[\"Problems\"].append(node)\n",
    "            counts[\"HAS_PROBLEM\"] += 1\n",
    "        elif relationship_type == \"WAS_TREATED_WITH\" and counts[\"WAS_TREATED_WITH\"] < limit:\n",
    "            context[\"Treatments\"].append(node)\n",
    "            counts[\"WAS_TREATED_WITH\"] += 1\n",
    "        elif relationship_type == \"UNDERWENT_TEST\" and counts[\"UNDERWENT_TEST\"] < limit:\n",
    "            context[\"Tests\"].append(node)\n",
    "            counts[\"UNDERWENT_TEST\"] += 1\n",
    "\n",
    "        # Break early if all categories reach their limits\n",
    "        if all(count == limit for count in counts.values()):\n",
    "            break\n",
    "\n",
    "    return context\n",
    "\n",
    "\n",
    "def construct_three_shot_prompt(reduced_text, context):\n",
    "    prompt = f\"\"\"\n",
    "    ### Task ###\n",
    "    You are a highly knowledgeable medical expert working at NIH. Your task is to summarize clinical notes concisely and professionally using only the information provided in the Input and Context. \n",
    "    - Do not include details or assumptions not explicitly mentioned.\n",
    "    - Do not add, infer, or guess any additional information.\n",
    "    - Ensure the summary is factual and consistent with the provided data.\n",
    "\n",
    "    ### Example 1 ###\n",
    "    Input: <SEX> F <CHIEF COMPLAINT> RUQ pain, nausea, vomiting\n",
    "    Context: Problems: [Acute cholecystitis, Obesity], Treatments: [Open cholecystectomy]\n",
    "    Output: Patient underwent cholecystectomy for acute cholecystitis and obesity.\n",
    "\n",
    "    ### Example 2 ###\n",
    "    Input: <SEX> M <CHIEF COMPLAINT> Severe chest pain, left arm pain\n",
    "    Context: Problems: [Myocardial infarction], Treatments: [PCI, Antiplatelet therapy]\n",
    "    Output: Patient had a myocardial infarction treated with PCI and therapy.\n",
    "\n",
    "    ### Example 3 ###\n",
    "    Input: <SEX> F <CHIEF COMPLAINT> Frequent urination, excessive thirst\n",
    "    Context: Problems: [Type 2 diabetes], Treatments: [Insulin therapy]\n",
    "    Output: Patient diagnosed with diabetes and started on insulin therapy.\n",
    "\n",
    "    ### Task ###\n",
    "    Summarize the following patient note concisely and professionally:\n",
    "    Input: {reduced_text}\n",
    "    Context: Problems: {context['Problems']}, Treatments: {context['Treatments']}, Tests: {context['Tests']}\n",
    "    Output:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Function to parse generated summaries\n",
    "def parse_summary_output(output):\n",
    "    if isinstance(output, dict) and \"generated_text\" in output:\n",
    "        return output[\"generated_text\"].split(\"Output:\")[-1].strip()\n",
    "    elif isinstance(output, str):\n",
    "        return output.split(\"Output:\")[-1].strip()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "print(\"Helper functions defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "219b4773-1bdb-4fb6-91cd-da5d328a4f06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Function to retrieve context from KG with limits\n",
    "def retrieve_context(patient_id, neo4j_graph, limit=10):\n",
    "    query = f\"\"\"\n",
    "    MATCH (p:Patient {{id: '{patient_id}'}})-[r]-(n)\n",
    "    WHERE type(r) IN ['HAS_PROBLEM', 'UNDERWENT_TEST', 'WAS_TREATED_WITH']\n",
    "    RETURN n.title AS node, type(r) AS relationship_type\n",
    "    \"\"\"\n",
    "    results = neo4j_graph.query(query)\n",
    "    context = {\"Problems\": [], \"Treatments\": [], \"Tests\": []}\n",
    "    counts = {\"HAS_PROBLEM\": 0, \"WAS_TREATED_WITH\": 0, \"UNDERWENT_TEST\": 0}  # Initialize counts\n",
    "\n",
    "    for record in results:\n",
    "        relationship_type = record[\"relationship_type\"]\n",
    "        node = record[\"node\"]\n",
    "\n",
    "        # Check limits for each category and append if within limit\n",
    "        if relationship_type == \"HAS_PROBLEM\" and counts[\"HAS_PROBLEM\"] < limit:\n",
    "            context[\"Problems\"].append(node)\n",
    "            counts[\"HAS_PROBLEM\"] += 1\n",
    "        elif relationship_type == \"WAS_TREATED_WITH\" and counts[\"WAS_TREATED_WITH\"] < limit:\n",
    "            context[\"Treatments\"].append(node)\n",
    "            counts[\"WAS_TREATED_WITH\"] += 1\n",
    "        elif relationship_type == \"UNDERWENT_TEST\" and counts[\"UNDERWENT_TEST\"] < limit:\n",
    "            context[\"Tests\"].append(node)\n",
    "            counts[\"UNDERWENT_TEST\"] += 1\n",
    "\n",
    "        # Break early if all categories reach their limits\n",
    "        if all(count == limit for count in counts.values()):\n",
    "            break\n",
    "\n",
    "    return context\n",
    "\n",
    "def construct_few_shot_prompt(reduced_text, context):\n",
    "    prompt = f\"\"\"You are a WORLD-CLASS EXPERT AT WRITING CLINICAL SUMMARIES. Summarize the input text in a clear, cohesive, and medically accurate manner.\n",
    "\n",
    "### Example 1:\n",
    "**Input:**  \n",
    "<SEX> M <AGE> 67 <SERVICE> CARDIOLOGY <HISTORY> Patient with known CAD and diabetes presented with chest pain and shortness of breath. ECG showed ST elevations in V2-V4. Troponin elevated at 2.3.  \n",
    "**Context:**  \n",
    "Problems: [Acute MI, CAD, Diabetes]  \n",
    "Tests: [ECG, Troponin]  \n",
    "Treatments: [PCI, Anticoagulation]  \n",
    "**Summary:**  \n",
    "67-year-old male with CAD and diabetes presented with chest pain and dyspnea. ECG revealed ST elevations V2-V4 with elevated troponin 2.3, indicating acute MI. Patient underwent PCI and started on anticoagulation.\n",
    "\n",
    "### Example 2:\n",
    "**Input:**  \n",
    "<SEX> F <AGE> 58 <SERVICE> NEUROLOGY <HISTORY> Patient with history of stroke presented with sudden onset left-sided weakness and slurred speech. CT head negative for hemorrhage. tPA administered within window.  \n",
    "**Context:**  \n",
    "Problems: [Acute Ischemic Stroke, Prior CVA]  \n",
    "Tests: [CT Head]  \n",
    "Treatments: [tPA]  \n",
    "**Summary:**  \n",
    "58-year-old female with history of stroke presented with acute left-sided weakness and slurred speech. CT head excluded hemorrhage, and patient received tPA within therapeutic window.\n",
    "\n",
    "---\n",
    "\n",
    "### YOUR TASK:\n",
    "1️⃣ Focus **ONLY on documented findings** – NO assumptions  \n",
    "2️⃣ Include **ALL relevant clinical data** from input  \n",
    "3️⃣ Maintain **chronological order** of events  \n",
    "4️⃣ Use **precise medical terminology**  \n",
    "5️⃣ Keep summary **concise but complete**  \n",
    "\n",
    "---\n",
    "### **Patient Data for Summarization**\n",
    "**Input:**  \n",
    "{reduced_text}\n",
    "\n",
    "**Context:**  \n",
    "- Problems: {\", \".join(context['Problems']) if context['Problems'] else \"None\"}  \n",
    "- Tests: {\", \".join(context['Tests']) if context['Tests'] else \"None\"}  \n",
    "- Treatments: {\", \".join(context['Treatments']) if context['Treatments'] else \"None\"}  \n",
    "\n",
    "---\n",
    "**Generated Summary:**  \n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "\n",
    "# Function to parse generated summaries\n",
    "def parse_summary_output(output):\n",
    "    if isinstance(output, dict) and \"generated_text\" in output:\n",
    "        return output[\"generated_text\"].split(\"Output:\")[-1].strip()\n",
    "    elif isinstance(output, str):\n",
    "        return output.split(\"Output:\")[-1].strip()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "print(\"Helper functions defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13a75d6e-a111-4b7d-a275-b67fa935c0fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Function to retrieve context from KG with limits\n",
    "def retrieve_context(patient_id, neo4j_graph, limit=1):\n",
    "    query = f\"\"\"\n",
    "    MATCH (p:Patient {{id: '{patient_id}'}})-[r]-(n)\n",
    "    WHERE type(r) IN ['HAS_PROBLEM', 'UNDERWENT_TEST', 'WAS_TREATED_WITH']\n",
    "    RETURN n.title AS node, type(r) AS relationship_type\n",
    "    \"\"\"\n",
    "    results = neo4j_graph.query(query)\n",
    "    context = {\"Problems\": [], \"Treatments\": [], \"Tests\": []}\n",
    "    counts = {\"HAS_PROBLEM\": 0, \"WAS_TREATED_WITH\": 0, \"UNDERWENT_TEST\": 0}  # Initialize counts\n",
    "\n",
    "    for record in results:\n",
    "        relationship_type = record[\"relationship_type\"]\n",
    "        node = record[\"node\"]\n",
    "\n",
    "        # Check limits for each category and append if within limit\n",
    "        if relationship_type == \"HAS_PROBLEM\" and counts[\"HAS_PROBLEM\"] < limit:\n",
    "            context[\"Problems\"].append(node)\n",
    "            counts[\"HAS_PROBLEM\"] += 1\n",
    "        elif relationship_type == \"WAS_TREATED_WITH\" and counts[\"WAS_TREATED_WITH\"] < limit:\n",
    "            context[\"Treatments\"].append(node)\n",
    "            counts[\"WAS_TREATED_WITH\"] += 1\n",
    "        elif relationship_type == \"UNDERWENT_TEST\" and counts[\"UNDERWENT_TEST\"] < limit:\n",
    "            context[\"Tests\"].append(node)\n",
    "            counts[\"UNDERWENT_TEST\"] += 1\n",
    "\n",
    "        # Break early if all categories reach their limits\n",
    "        if all(count == limit for count in counts.values()):\n",
    "            break\n",
    "\n",
    "    return context\n",
    "\n",
    "def construct_one_shot_prompt(reduced_text, context):\n",
    "    prompt = f\"\"\"\n",
    "    Summarize the following clinical note concisely while preserving key medical details. Only generate the summary—do not repeat the input text, instructions, or formatting.\n",
    "\n",
    "    Clinical Note:\n",
    "    {reduced_text}\n",
    "\n",
    "    Patient Context:\n",
    "    - Problems: {\", \".join(context['Problems']) if context['Problems'] else \"None\"}\n",
    "    - Tests: {\", \".join(context['Tests']) if context['Tests'] else \"None\"}\n",
    "    - Treatments: {\", \".join(context['Treatments']) if context['Treatments'] else \"None\"}\n",
    "\n",
    "    ### Summary of the Patient's Condition:\n",
    "    \"\"\"\n",
    "    return prompt.strip()\n",
    "\n",
    "\n",
    "# Function to parse generated summaries\n",
    "def parse_summary_output(output):\n",
    "    if isinstance(output, dict) and \"generated_text\" in output:\n",
    "        return output[\"generated_text\"].split(\"Output:\")[-1].strip()\n",
    "    elif isinstance(output, str):\n",
    "        return output.split(\"Output:\")[-1].strip()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "print(\"Helper functions defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f75e8439-fc5b-4ec7-8991-e8048d0c43c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Generating Summaries:   0%|          | 0/100 [00:00<?, ?notes/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:   2%|▏         | 2/100 [00:37<30:21, 18.58s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:   4%|▍         | 4/100 [01:15<30:07, 18.83s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:   6%|▌         | 6/100 [01:53<29:39, 18.93s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:   8%|▊         | 8/100 [02:31<29:06, 18.98s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  10%|█         | 10/100 [03:09<28:24, 18.94s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  12%|█▏        | 12/100 [03:40<26:11, 17.86s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  14%|█▍        | 14/100 [04:17<25:50, 18.03s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  16%|█▌        | 16/100 [04:55<25:42, 18.36s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  18%|█▊        | 18/100 [05:33<25:26, 18.61s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  20%|██        | 20/100 [06:08<24:17, 18.22s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  22%|██▏       | 22/100 [06:46<23:59, 18.45s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  24%|██▍       | 24/100 [07:23<23:20, 18.43s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  26%|██▌       | 26/100 [07:55<21:54, 17.77s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  28%|██▊       | 28/100 [08:26<20:32, 17.11s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  30%|███       | 30/100 [09:05<20:38, 17.70s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  32%|███▏      | 32/100 [09:43<20:32, 18.12s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  34%|███▍      | 34/100 [10:20<20:08, 18.31s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  36%|███▌      | 36/100 [10:58<19:46, 18.53s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  38%|███▊      | 38/100 [11:30<18:20, 17.75s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  40%|████      | 40/100 [12:08<18:08, 18.15s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  42%|████▏     | 42/100 [12:37<16:25, 17.00s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  44%|████▍     | 44/100 [13:09<15:31, 16.64s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  46%|████▌     | 46/100 [13:47<15:41, 17.43s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  48%|████▊     | 48/100 [14:20<14:50, 17.12s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  50%|█████     | 50/100 [14:53<14:04, 16.89s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  52%|█████▏    | 52/100 [15:23<13:04, 16.35s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  54%|█████▍    | 54/100 [15:56<12:32, 16.37s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  56%|█████▌    | 56/100 [16:34<12:35, 17.17s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  58%|█████▊    | 58/100 [17:12<12:25, 17.76s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  60%|██████    | 60/100 [17:35<10:36, 15.91s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  62%|██████▏   | 62/100 [18:07<10:06, 15.97s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  64%|██████▍   | 64/100 [18:45<10:04, 16.79s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  66%|██████▌   | 66/100 [19:16<09:18, 16.43s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  68%|██████▊   | 68/100 [19:54<09:08, 17.14s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  70%|███████   | 70/100 [20:30<08:42, 17.41s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  72%|███████▏  | 72/100 [21:05<08:09, 17.47s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  74%|███████▍  | 74/100 [21:43<07:45, 17.90s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  76%|███████▌  | 76/100 [22:15<06:56, 17.36s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  78%|███████▊  | 78/100 [22:50<06:22, 17.40s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  80%|████████  | 80/100 [23:28<05:59, 17.96s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  82%|████████▏ | 82/100 [24:06<05:27, 18.22s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  84%|████████▍ | 84/100 [24:44<04:55, 18.47s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  86%|████████▌ | 86/100 [25:17<04:10, 17.88s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  88%|████████▊ | 88/100 [25:51<03:31, 17.62s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  90%|█████████ | 90/100 [26:29<03:00, 18.02s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  92%|█████████▏| 92/100 [27:08<02:27, 18.39s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  94%|█████████▍| 94/100 [27:45<01:50, 18.49s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  96%|█████████▌| 96/100 [28:23<01:14, 18.68s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries:  98%|█████████▊| 98/100 [29:02<00:37, 18.81s/notes]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Generating Summaries: 100%|██████████| 100/100 [29:39<00:00, 17.80s/notes]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Computational Efficiency Metrics:\n",
      "📌 Total Input Tokens: 138888\n",
      "📌 Total Output Tokens: 28078\n",
      "📌 Total Time Spent: 1779.75 seconds\n",
      "📌 Average Latency (Time per Summary): 17.7975 seconds\n",
      "📌 Average TTFT (Time to First Token): 35434.25 ms\n",
      "📌 Average Throughput: 94.61 tokens/second\n",
      "📌 Token Efficiency (TE): 0.2022\n",
      "✅ Summarization complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------- Context Retrieval from Neo4j -------------------------\n",
    "def retrieve_context(patient_id, neo4j_graph, limit=2):\n",
    "    \"\"\"Retrieves patient context (problems, tests, treatments) from Neo4j\"\"\"\n",
    "    query = f\"\"\"\n",
    "    MATCH (p:Patient {{id: '{patient_id}'}})-[r]-(n)\n",
    "    WHERE type(r) IN ['HAS_PROBLEM', 'UNDERWENT_TEST', 'WAS_TREATED_WITH']\n",
    "    RETURN n.title AS node, type(r) AS relationship_type\n",
    "    \"\"\"\n",
    "    results = neo4j_graph.query(query)\n",
    "    \n",
    "    # Initialize context dictionary\n",
    "    context = {\"Problems\": [], \"Treatments\": [], \"Tests\": []}\n",
    "    counts = {\"HAS_PROBLEM\": 0, \"WAS_TREATED_WITH\": 0, \"UNDERWENT_TEST\": 0} \n",
    "\n",
    "    for record in results:\n",
    "        relationship_type = record[\"relationship_type\"]\n",
    "        node = record[\"node\"]\n",
    "\n",
    "        # Store retrieved context within limit\n",
    "        if relationship_type == \"HAS_PROBLEM\" and counts[\"HAS_PROBLEM\"] < limit:\n",
    "            context[\"Problems\"].append(node)\n",
    "            counts[\"HAS_PROBLEM\"] += 1\n",
    "        elif relationship_type == \"WAS_TREATED_WITH\" and counts[\"WAS_TREATED_WITH\"] < limit:\n",
    "            context[\"Treatments\"].append(node)\n",
    "            counts[\"WAS_TREATED_WITH\"] += 1\n",
    "        elif relationship_type == \"UNDERWENT_TEST\" and counts[\"UNDERWENT_TEST\"] < limit:\n",
    "            context[\"Tests\"].append(node)\n",
    "            counts[\"UNDERWENT_TEST\"] += 1\n",
    "\n",
    "        # Stop early if all categories reach the limit\n",
    "        if all(count == limit for count in counts.values()):\n",
    "            break\n",
    "\n",
    "    return context\n",
    "\n",
    "\n",
    "# ------------------------- Few-Shot Prompt Construction -------------------------\n",
    "def construct_few_shot_prompt(reduced_text, context):\n",
    "    \"\"\"Creates a structured few-shot prompt for summarization.\"\"\"\n",
    "    \n",
    "    def safe_join(items):\n",
    "        \"\"\"Helper function to safely join list items, converting None to empty strings.\"\"\"\n",
    "        return \", \".join(str(item) for item in items if item is not None) if items else \"None\"\n",
    "\n",
    "    prompt = f\"\"\"You are a WORLD-CLASS EXPERT AT WRITING CLINICAL SUMMARIES. Summarize the input text in a clear, cohesive, and medically accurate manner. Do not include the input & prompt in the final summary.\n",
    "\n",
    "### **Patient Data for Summarization**\n",
    "**Input:**  \n",
    "{reduced_text}\n",
    "\n",
    "**Context:**  \n",
    "- Problems: {safe_join(context['Problems'])}  \n",
    "- Tests: {safe_join(context['Tests'])}  \n",
    "- Treatments: {safe_join(context['Treatments'])}  \n",
    "\n",
    "---\n",
    "### **Generated Summary:**  \n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# ------------------------- Batch Summarization with Efficiency Metrics -------------------------\n",
    "def generate_summaries(df, neo4j_graph, summarizer, tokenizer, generation_params, batch_size=2):\n",
    "    \"\"\"Generates summaries for all patient records while tracking efficiency metrics.\"\"\"\n",
    "    generated_summaries = []\n",
    "\n",
    "    # ✅ Initialize Metrics\n",
    "    total_input_tokens = 0\n",
    "    total_output_tokens = 0\n",
    "    total_time_spent = 0\n",
    "    ttft_list = []  # Time to first token\n",
    "    latency_list = []  # Time per summary\n",
    "    throughput_list = []  # Tokens processed per second\n",
    "\n",
    "    # ✅ Progress bar\n",
    "    main_progress = tqdm(total=len(df), desc=\"Generating Summaries\", unit=\"notes\")\n",
    "\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        prompts = []\n",
    "        batch_start_time = time.time()\n",
    "\n",
    "        # Construct prompts with retrieved context\n",
    "        for _, row in batch.iterrows():\n",
    "            patient_id = row[\"note_id\"]\n",
    "            reduced_text = row[\"reduced_text\"]\n",
    "            \n",
    "            # Retrieve context from KG\n",
    "            context = retrieve_context(patient_id, neo4j_graph)\n",
    "            \n",
    "            # Construct the few-shot prompt\n",
    "            prompt = construct_few_shot_prompt(reduced_text, context)\n",
    "            prompts.append(prompt)\n",
    "\n",
    "        try:\n",
    "            # ✅ Tokenization for input size tracking\n",
    "            batch_input_tokens = sum(len(tokenizer.encode(prompt)) for prompt in prompts)\n",
    "\n",
    "            # ✅ Generate summaries\n",
    "            single_start_time = time.time()\n",
    "            summaries = summarizer(prompts, **generation_params)\n",
    "            single_end_time = time.time()\n",
    "\n",
    "            # ✅ Measure TTFT\n",
    "            ttft_list.append((single_end_time - single_start_time) * 1000)  # Convert to milliseconds\n",
    "\n",
    "            # ✅ Parse and store summaries\n",
    "            batch_output_tokens = 0\n",
    "            for summary in summaries:\n",
    "                if isinstance(summary, list) and len(summary) > 0:  # Handles nested lists\n",
    "                    summary = summary[0]  # Extract first item if it's a nested list\n",
    "                \n",
    "                if isinstance(summary, dict) and \"generated_text\" in summary:\n",
    "                    generated_text = summary[\"generated_text\"]\n",
    "                else:\n",
    "                    generated_text = str(summary)  # Convert to string if unexpected format\n",
    "                \n",
    "                # ✅ Extract only the summary part after \"### **Generated Summary:**\"\n",
    "                summary_start = generated_text.find(\"### **Generated Summary:**\")\n",
    "                if summary_start != -1:\n",
    "                    generated_summary = generated_text[summary_start + len(\"### **Generated Summary:**\"):].strip()\n",
    "                else:\n",
    "                    generated_summary = generated_text.strip()  # Fallback in case parsing fails\n",
    "\n",
    "                generated_summaries.append(generated_summary)\n",
    "                batch_output_tokens += len(tokenizer.encode(generated_summary))\n",
    "\n",
    "            batch_end_time = time.time()\n",
    "\n",
    "            # ✅ Compute batch metrics\n",
    "            batch_latency = batch_end_time - batch_start_time  # Total batch time\n",
    "            latency_list.append(batch_latency / len(batch))  # Average latency per summary\n",
    "            throughput_list.append((batch_input_tokens + batch_output_tokens) / batch_latency)\n",
    "\n",
    "            # ✅ Update global metrics\n",
    "            total_input_tokens += batch_input_tokens\n",
    "            total_output_tokens += batch_output_tokens\n",
    "            total_time_spent += batch_latency\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing batch starting at index {i}: {e}\")\n",
    "            generated_summaries.extend([\"Error generating summary\"] * len(prompts))  # Fill missing entries\n",
    "\n",
    "        # ✅ Update progress bar\n",
    "        main_progress.update(len(batch))\n",
    "\n",
    "    # ✅ Close progress bar\n",
    "    main_progress.close()\n",
    "\n",
    "    # ✅ Store summaries in dataframe\n",
    "    df[\"generated_summary\"] = generated_summaries\n",
    "\n",
    "    # ✅ Compute Final Metrics\n",
    "    average_latency = sum(latency_list) / len(latency_list) if latency_list else 0\n",
    "    average_ttft = sum(ttft_list) / len(ttft_list) if ttft_list else 0  # Now in milliseconds\n",
    "    average_throughput = sum(throughput_list) / len(throughput_list) if throughput_list else 0\n",
    "    token_efficiency = total_output_tokens / total_input_tokens if total_input_tokens else 0\n",
    "\n",
    "    # ✅ Print Final Metrics (Only Once)\n",
    "    print(\"\\n🔹 Computational Efficiency Metrics:\")\n",
    "    print(f\"📌 Total Input Tokens: {total_input_tokens}\")\n",
    "    print(f\"📌 Total Output Tokens: {total_output_tokens}\")\n",
    "    print(f\"📌 Total Time Spent: {total_time_spent:.2f} seconds\")\n",
    "    print(f\"📌 Average Latency (Time per Summary): {average_latency:.4f} seconds\")\n",
    "    print(f\"📌 Average TTFT (Time to First Token): {average_ttft:.2f} ms\")  # Display in milliseconds\n",
    "    print(f\"📌 Average Throughput: {average_throughput:.2f} tokens/second\")\n",
    "    print(f\"📌 Token Efficiency (TE): {token_efficiency:.4f}\")\n",
    "\n",
    "    print(\"✅ Summarization complete!\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ------------------------- Execution -------------------------\n",
    "# Assuming merged_df contains patient data\n",
    "merged_df = generate_summaries(merged_df, neo4j_graph, summarizer, tokenizer, generation_params)\n",
    "\n",
    "# ✅ Save results to CSV if needed\n",
    "# merged_df.to_csv(\"summarized_output.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ee79ab61-dcb7-4641-a38a-854bb279423d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>input</th>\n",
       "      <th>reduced_text</th>\n",
       "      <th>entities</th>\n",
       "      <th>problems</th>\n",
       "      <th>treatments</th>\n",
       "      <th>tests</th>\n",
       "      <th>generated_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16002318-DS-17</td>\n",
       "      <td>&lt;SEX&gt; F &lt;SERVICE&gt; SURGERY &lt;ALLERGIES&gt; Iodine /...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;SEX&gt; F &lt;SERVICE&gt; SURGERY &lt;AL...</td>\n",
       "      <td>{'PROBLEM': ['101', '7 pound weight loss', 'a ...</td>\n",
       "      <td>['101', '7 pound weight loss', 'a fever', 'a l...</td>\n",
       "      <td>['abdominal exercises', 'albuterol sulfate', '...</td>\n",
       "      <td>['b12', 'bmi', 'calcium', 'physical exam']</td>\n",
       "      <td>The patient is a female presenting with morbid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15638884-DS-4</td>\n",
       "      <td>&lt;SEX&gt; M &lt;SERVICE&gt; MEDICINE &lt;ALLERGIES&gt; Augment...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;SEX&gt; M &lt;SERVICE&gt; MEDICINE &lt;A...</td>\n",
       "      <td>{'PROBLEM': ['+', '-', '1 cm area', 'a \" cyst ...</td>\n",
       "      <td>['+', '-', '1 cm area', 'a \" cyst \"', 'a 2cm d...</td>\n",
       "      <td>['a bankart repair', 'a nicotine patch', 'a st...</td>\n",
       "      <td>['.', '_', 'a', 'a ct scan', 'absbaso', 'abseo...</td>\n",
       "      <td>The patient presented with painless jaundice a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12435705-DS-14</td>\n",
       "      <td>&lt;SEX&gt; M &lt;SERVICE&gt; MEDICINE &lt;ALLERGIES&gt; ibuprof...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;SEX&gt; M &lt;SERVICE&gt; MEDICINE &lt;A...</td>\n",
       "      <td>{'PROBLEM': ['a 0. 7 x 0. 7 x 0. 7 cm simple c...</td>\n",
       "      <td>['a 0. 7 x 0. 7 x 0. 7 cm simple cyst', 'a 2. ...</td>\n",
       "      <td>['2', 'a prolonged course', 'ampicillin', 'ant...</td>\n",
       "      <td>['16s rdna primer set', 'aa', 'abl', 'acid fas...</td>\n",
       "      <td>The patient presents with a history of rupture...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12413577-DS-4</td>\n",
       "      <td>&lt;SEX&gt; F &lt;SERVICE&gt; OBSTETRICS/GYNECOLOGY &lt;ALLER...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;SEX&gt; F &lt;SERVICE&gt; OBSTETRICS/...</td>\n",
       "      <td>{'PROBLEM': ['a third - degree uterine prolaps...</td>\n",
       "      <td>['a third - degree uterine prolapse', 'abnorma...</td>\n",
       "      <td>['a stool softener', 'acetaminophen', 'admissi...</td>\n",
       "      <td>['hct', 'hgb', 'mch', 'mchc', 'mcv', 'nadr', '...</td>\n",
       "      <td>The patient presents with a history of uterine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17967161-DS-29</td>\n",
       "      <td>&lt;SEX&gt; M &lt;SERVICE&gt; SURGERY &lt;ALLERGIES&gt; lisinopr...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;SEX&gt; M &lt;SERVICE&gt; SURGERY &lt;AL...</td>\n",
       "      <td>{'PROBLEM': ['101', 'abuse', 'acute pancreatit...</td>\n",
       "      <td>['101', 'abuse', 'acute pancreatitis', 'angina...</td>\n",
       "      <td>['a', 'a 3 mm x 40 mm balloon percutaneous tra...</td>\n",
       "      <td>['angap', 'blood', 'blood calcium', 'blood ck ...</td>\n",
       "      <td>Peripheral vascular disease, right foot ulcer,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          note_id                                              input  \\\n",
       "0  16002318-DS-17  <SEX> F <SERVICE> SURGERY <ALLERGIES> Iodine /...   \n",
       "1   15638884-DS-4  <SEX> M <SERVICE> MEDICINE <ALLERGIES> Augment...   \n",
       "2  12435705-DS-14  <SEX> M <SERVICE> MEDICINE <ALLERGIES> ibuprof...   \n",
       "3   12413577-DS-4  <SEX> F <SERVICE> OBSTETRICS/GYNECOLOGY <ALLER...   \n",
       "4  17967161-DS-29  <SEX> M <SERVICE> SURGERY <ALLERGIES> lisinopr...   \n",
       "\n",
       "                                        reduced_text  \\\n",
       "0  <|begin_of_text|><SEX> F <SERVICE> SURGERY <AL...   \n",
       "1  <|begin_of_text|><SEX> M <SERVICE> MEDICINE <A...   \n",
       "2  <|begin_of_text|><SEX> M <SERVICE> MEDICINE <A...   \n",
       "3  <|begin_of_text|><SEX> F <SERVICE> OBSTETRICS/...   \n",
       "4  <|begin_of_text|><SEX> M <SERVICE> SURGERY <AL...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'PROBLEM': ['101', '7 pound weight loss', 'a ...   \n",
       "1  {'PROBLEM': ['+', '-', '1 cm area', 'a \" cyst ...   \n",
       "2  {'PROBLEM': ['a 0. 7 x 0. 7 x 0. 7 cm simple c...   \n",
       "3  {'PROBLEM': ['a third - degree uterine prolaps...   \n",
       "4  {'PROBLEM': ['101', 'abuse', 'acute pancreatit...   \n",
       "\n",
       "                                            problems  \\\n",
       "0  ['101', '7 pound weight loss', 'a fever', 'a l...   \n",
       "1  ['+', '-', '1 cm area', 'a \" cyst \"', 'a 2cm d...   \n",
       "2  ['a 0. 7 x 0. 7 x 0. 7 cm simple cyst', 'a 2. ...   \n",
       "3  ['a third - degree uterine prolapse', 'abnorma...   \n",
       "4  ['101', 'abuse', 'acute pancreatitis', 'angina...   \n",
       "\n",
       "                                          treatments  \\\n",
       "0  ['abdominal exercises', 'albuterol sulfate', '...   \n",
       "1  ['a bankart repair', 'a nicotine patch', 'a st...   \n",
       "2  ['2', 'a prolonged course', 'ampicillin', 'ant...   \n",
       "3  ['a stool softener', 'acetaminophen', 'admissi...   \n",
       "4  ['a', 'a 3 mm x 40 mm balloon percutaneous tra...   \n",
       "\n",
       "                                               tests  \\\n",
       "0         ['b12', 'bmi', 'calcium', 'physical exam']   \n",
       "1  ['.', '_', 'a', 'a ct scan', 'absbaso', 'abseo...   \n",
       "2  ['16s rdna primer set', 'aa', 'abl', 'acid fas...   \n",
       "3  ['hct', 'hgb', 'mch', 'mchc', 'mcv', 'nadr', '...   \n",
       "4  ['angap', 'blood', 'blood calcium', 'blood ck ...   \n",
       "\n",
       "                                   generated_summary  \n",
       "0  The patient is a female presenting with morbid...  \n",
       "1  The patient presented with painless jaundice a...  \n",
       "2  The patient presents with a history of rupture...  \n",
       "3  The patient presents with a history of uterine...  \n",
       "4  Peripheral vascular disease, right foot ulcer,...  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3c2d120d-8c02-4b11-b63d-6e22d166c4bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summaries saved to 'summarization_output.csv'\n"
     ]
    }
   ],
   "source": [
    "# ✅ Save the DataFrame to a CSV file\n",
    "merged_df.to_csv(\"summarization_output.csv\", index=False)\n",
    "print(\"\\nSummaries saved to 'summarization_output.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71b081e-f9de-4e96-8cea-b5b535b5277c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf29d86-9bb2-4ddc-9995-4de975b5fe66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d88c89-ca9e-44c6-b501-04ec23fe44e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6f4f8b-f61d-409f-bf96-2872465d3a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17907712-b98b-42f1-8558-1161555bb8d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc20869c-a614-49b5-ba1f-8f22f53c99bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e22802-a29d-432a-af1c-bb4dd25a0353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
