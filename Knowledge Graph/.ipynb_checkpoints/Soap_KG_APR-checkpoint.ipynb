{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "825838cd-aeac-4593-8920-e02e2a24e768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers huggingface_hub langchain_community\n",
    "!pip install -q --upgrade accelerate\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q neo4j\n",
    "!pip install -q --upgrade accelerate\n",
    "!pip install -q -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "161b54d3-791b-4cd4-91be-89900c0e18e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce108d38-28a3-416b-9d1f-faf8105fc7bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-neo4j\n",
      "  Downloading langchain_neo4j-0.4.0-py3-none-any.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-neo4j) (0.3.23)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-neo4j) (0.3.51)\n",
      "Requirement already satisfied: neo4j<6.0.0,>=5.25.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-neo4j) (5.28.1)\n",
      "Collecting neo4j-graphrag<2.0.0,>=1.5.0 (from langchain-neo4j)\n",
      "  Downloading neo4j_graphrag-1.6.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.7->langchain-neo4j) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.7->langchain-neo4j) (0.3.30)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.7->langchain-neo4j) (2.10.6)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.7->langchain-neo4j) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.7->langchain-neo4j) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.7->langchain-neo4j) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.7->langchain-neo4j) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.8->langchain-neo4j) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.8->langchain-neo4j) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.8->langchain-neo4j) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.8->langchain-neo4j) (4.12.2)\n",
      "Requirement already satisfied: pytz in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from neo4j<6.0.0,>=5.25.0->langchain-neo4j) (2024.1)\n",
      "Collecting fsspec<2025.0.0,>=2024.9.0 (from neo4j-graphrag<2.0.0,>=1.5.0->langchain-neo4j)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting json-repair<0.40.0,>=0.39.1 (from neo4j-graphrag<2.0.0,>=1.5.0->langchain-neo4j)\n",
      "  Downloading json_repair-0.39.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting pypdf<6.0.0,>=5.1.0 (from neo4j-graphrag<2.0.0,>=1.5.0->langchain-neo4j)\n",
      "  Downloading pypdf-5.4.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting types-pyyaml<7.0.0.0,>=6.0.12.20240917 (from neo4j-graphrag<2.0.0,>=1.5.0->langchain-neo4j)\n",
      "  Downloading types_pyyaml-6.0.12.20250402-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.8->langchain-neo4j) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.7->langchain-neo4j) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.7->langchain-neo4j) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.7->langchain-neo4j) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.7->langchain-neo4j) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain-neo4j) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain-neo4j) (2.27.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.7->langchain-neo4j) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.7->langchain-neo4j) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.7->langchain-neo4j) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain<0.4.0,>=0.3.7->langchain-neo4j) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain<0.4.0,>=0.3.7->langchain-neo4j) (3.1.1)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.7->langchain-neo4j) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.7->langchain-neo4j) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.7->langchain-neo4j) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.7->langchain-neo4j) (1.2.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain<0.4.0,>=0.3.7->langchain-neo4j) (1.3.1)\n",
      "Downloading langchain_neo4j-0.4.0-py3-none-any.whl (31 kB)\n",
      "Downloading neo4j_graphrag-1.6.1-py3-none-any.whl (171 kB)\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "Downloading json_repair-0.39.1-py3-none-any.whl (20 kB)\n",
      "Downloading pypdf-5.4.0-py3-none-any.whl (302 kB)\n",
      "Downloading types_pyyaml-6.0.12.20250402-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: types-pyyaml, pypdf, json-repair, fsspec, neo4j-graphrag, langchain-neo4j\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2025.2.0\n",
      "    Uninstalling fsspec-2025.2.0:\n",
      "      Successfully uninstalled fsspec-2025.2.0\n",
      "Successfully installed fsspec-2024.12.0 json-repair-0.39.1 langchain-neo4j-0.4.0 neo4j-graphrag-1.6.1 pypdf-5.4.0 types-pyyaml-6.0.12.20250402\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4cecdb2-9491-4594-8dcf-bc25c2153a31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2117/32962046.py:22: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
      "  neo4j_graph=Neo4jGraph(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_neo4j import Neo4jGraph  # Updated import statement\n",
    "\n",
    "# Graphdb configuration\n",
    "NEO4J_URI = \"\"\n",
    "NEO4J_USERNAME = \"\"\n",
    "NEO4J_PASSWORD = \"\"\n",
    "\n",
    "# Setting environment variables for Neo4j\n",
    "os.environ[\"NEO4J_URI\"] = NEO4J_URI\n",
    "os.environ[\"NEO4J_USERNAME\"] = NEO4J_USERNAME\n",
    "os.environ[\"NEO4J_PASSWORD\"] = NEO4J_PASSWORD\n",
    "\n",
    "# Creating a Neo4j graph instance\n",
    "neo4j_graph = Neo4jGraph(\n",
    "    url=os.getenv(\"NEO4J_URI\"),\n",
    "    username=os.getenv(\"NEO4J_USERNAME\"),\n",
    "    password=os.getenv(\"NEO4J_PASSWORD\"),\n",
    ")\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "neo4j_graph=Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d962d6-9fc0-4221-809d-f4ce31bdcfd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.graphs.neo4j_graph.Neo4jGraph at 0x7f8e9c127880>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neo4j_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84896e12-325a-4b65-9e74-e0157df207f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  \\\n",
      "0  Good afternoon, champ, how you holding up? Goo...   \n",
      "1  What brings you in here today? Hi, I'm um, I'm...   \n",
      "2  Do you have any known allergies to medications...   \n",
      "3  How may I help you today? Yeah I've had, a fev...   \n",
      "4  It sounds like that you're experiencing some c...   \n",
      "\n",
      "                                              output  \\\n",
      "0  Subjective:\\n- Symptoms: Lower back pain, radi...   \n",
      "1  Subjective:\\n- Presenting with dry cough for 1...   \n",
      "2  Subjective:\\n- No known allergies to medicatio...   \n",
      "3  Subjective:\\n- Fever and dry cough started 4 d...   \n",
      "4  Subjective:\\n- Presenting with chest pain for ...   \n",
      "\n",
      "                                     id  \\\n",
      "0  39a26c55-f710-4272-8609-2a725ef6d068   \n",
      "1  b1448089-3c41-423a-9737-0ed25e0e99c8   \n",
      "2  78cf9b57-3a1f-41df-ba55-af3bbe843228   \n",
      "3  44be7957-be23-4cc9-a5e2-cb7139dc2079   \n",
      "4  3324cd95-1729-4b0b-8916-dba010ac811e   \n",
      "\n",
      "                                            entities  \\\n",
      "0  {'PROBLEM': ['radiculopathy', 'the pain', 'wea...   \n",
      "1  {'PROBLEM': ['known sick contacts', 'flu - lik...   \n",
      "2  {'PROBLEM': ['known allergies'], 'TREATMENT': ...   \n",
      "3  {'PROBLEM': ['hee', 'sp', 'blood', 'symptoms',...   \n",
      "4  {'PROBLEM': ['significant stress', 'chronic co...   \n",
      "\n",
      "                                            problems  \\\n",
      "0  ['radiculopathy', 'the pain', 'weakness in the...   \n",
      "1  ['known sick contacts', 'flu - like illness', ...   \n",
      "2                                ['known allergies']   \n",
      "3  ['hee', 'sp', 'blood', 'symptoms', 'w', 'um', ...   \n",
      "4  ['significant stress', 'chronic conditions', '...   \n",
      "\n",
      "                                          treatments  \\\n",
      "0  ['anti - inflammatory medications', 'treatment...   \n",
      "1  ['appendect', 'omy', 'infection control measur...   \n",
      "2                                    ['medications']   \n",
      "3                                   ['multivitamin']   \n",
      "4      ['advil', 'tu', 'ms', 'tylenol', 'treatment']   \n",
      "\n",
      "                                               tests  \n",
      "0  ['differential diagnoses', 'x - rays of the lo...  \n",
      "1                 ['sw', 'covid', 'swab', 'testing']  \n",
      "2                                                 []  \n",
      "3                   ['covid', 'swab', 'temperature']  \n",
      "4  ['physical examination', 's signs', 'vital', '...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "NER_df = pd.read_csv(\"processed_output.csv\")\n",
    "\n",
    "# Check the data\n",
    "print(NER_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb79409c-5ca6-47d9-824b-dd7d474dd8bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['the ant bait', 'borax', 'ant bait', 'medications']\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NER_df['treatments'].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a853f0d-b038-4de0-b26e-324dc7553b19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input         100\n",
       "output        100\n",
       "id            100\n",
       "entities       95\n",
       "problems       84\n",
       "treatments     51\n",
       "tests          41\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NER_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3bd5c0bd-50b1-4b05-b481-f6962ab4c341",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Knowledge Graph: 100%|██████████| 100/100 [15:55<00:00,  9.56s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Function to escape and preprocess text for Cypher queries\n",
    "def escape_text(text):\n",
    "    return text.replace(\"'\", \" \").replace('\"', ' ')  # Escape both single and double quotes\n",
    "\n",
    "# Function to build the Knowledge Graph for SOAP dataset\n",
    "def build_knowledge_graph_soap(df, neo4j_graph):\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Building Knowledge Graph\"):\n",
    "        # Use existing ID from the DataFrame\n",
    "        patient_id = escape_text(str(row['id']))\n",
    "        \n",
    "        # Extract and preprocess data\n",
    "        problems = [escape_text(problem) for problem in row['problems']]\n",
    "        treatments = [escape_text(treatment) for treatment in row['treatments']]\n",
    "        tests = [escape_text(test) for test in row['tests']]\n",
    "\n",
    "        # Create Patient node\n",
    "        patient_query = f\"\"\"\n",
    "        MERGE (p:Patient {{id: '{patient_id}'}})\n",
    "        \"\"\"\n",
    "        neo4j_graph.query(patient_query)\n",
    "\n",
    "        # Create Problem nodes and relationships\n",
    "        for problem in problems:\n",
    "            problem_query = f\"\"\"\n",
    "            MERGE (pr:Problem {{title: '{problem}'}})\n",
    "            MERGE (p)-[:HAS_PROBLEM]->(pr)\n",
    "            \"\"\"\n",
    "            neo4j_graph.query(problem_query)\n",
    "\n",
    "        # Create Treatment nodes and relationships\n",
    "        for treatment in treatments:\n",
    "            treatment_query = f\"\"\"\n",
    "            MERGE (tr:Treatment {{title: '{treatment}'}})\n",
    "            MERGE (p)-[:WAS_TREATED_WITH]->(tr)\n",
    "            \"\"\"\n",
    "            neo4j_graph.query(treatment_query)\n",
    "\n",
    "        # Create Test nodes and relationships\n",
    "        for test in tests:\n",
    "            test_query = f\"\"\"\n",
    "            MERGE (t:Test {{title: '{test}'}})\n",
    "            MERGE (p)-[:UNDERWENT_TEST]->(t)\n",
    "            \"\"\"\n",
    "            neo4j_graph.query(test_query)\n",
    "\n",
    "# Example usage, assuming 'neo4j_graph' is already connected and 'df' is your DataFrame\n",
    "build_knowledge_graph_soap(NER_df, neo4j_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10230ab6-996c-472f-adb0-be48d517314f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Counts by Type:\n",
      "Node Type: None (No label), Count: {record['count']}\n",
      "Node Type: Patient, Count: 100\n",
      "Node Type: Problem, Count: 37\n",
      "Node Type: Treatment, Count: 34\n",
      "Node Type: Test, Count: 31\n",
      "\n",
      "Relationship Counts by Type:\n",
      "Relationship Type: HAS_PROBLEM, Count: 37\n",
      "Relationship Type: WAS_TREATED_WITH, Count: 34\n",
      "Relationship Type: UNDERWENT_TEST, Count: 31\n",
      "Error retrieving graph statistics: 'list' object has no attribute 'single'\n"
     ]
    }
   ],
   "source": [
    "def get_graph_statistics(neo4j_graph):\n",
    "    try:\n",
    "        # Query to count nodes by type\n",
    "        node_count_query = \"\"\"\n",
    "        MATCH (n)\n",
    "        RETURN labels(n) AS node_type, COUNT(*) AS count\n",
    "        ORDER BY count DESC\n",
    "        \"\"\"\n",
    "\n",
    "        # Query to count relationships by type\n",
    "        relationship_count_query = \"\"\"\n",
    "        MATCH ()-[r]->()\n",
    "        RETURN TYPE(r) AS relationship_type, COUNT(*) AS count\n",
    "        ORDER BY count DESC\n",
    "        \"\"\"\n",
    "\n",
    "        # Query to count total nodes\n",
    "        total_nodes_query = \"\"\"\n",
    "        MATCH (n)\n",
    "        RETURN COUNT(*) AS total_nodes\n",
    "        \"\"\"\n",
    "\n",
    "        # Query to count total relationships\n",
    "        total_relationships_query = \"\"\"\n",
    "        MATCH ()-[r]->()\n",
    "        RETURN COUNT(*) AS total_relationships\n",
    "        \"\"\"\n",
    "\n",
    "        # Execute queries and fetch results\n",
    "        print(\"Node Counts by Type:\")\n",
    "        node_counts = neo4j_graph.query(node_count_query)\n",
    "        for record in node_counts:\n",
    "            node_type = record['node_type']\n",
    "            if node_type:  # Check if the node_type list is not empty\n",
    "                print(f\"Node Type: {node_type[0]}, Count: {record['count']}\")\n",
    "            else:\n",
    "                print(\"Node Type: None (No label), Count: {record['count']}\")  # Handle nodes with no labels\n",
    "\n",
    "        print(\"\\nRelationship Counts by Type:\")\n",
    "        relationship_counts = neo4j_graph.query(relationship_count_query)\n",
    "        for record in relationship_counts:\n",
    "            print(f\"Relationship Type: {record['relationship_type']}, Count: {record['count']}\")\n",
    "\n",
    "        total_nodes_result = neo4j_graph.query(total_nodes_query).single()\n",
    "        total_nodes = total_nodes_result['total_nodes'] if total_nodes_result else 0\n",
    "\n",
    "        total_relationships_result = neo4j_graph.query(total_relationships_query).single()\n",
    "        total_relationships = total_relationships_result['total_relationships'] if total_relationships_result else 0\n",
    "\n",
    "        print(\"\\nTotal Counts:\")\n",
    "        print(f\"Total Nodes: {total_nodes}\")\n",
    "        print(f\"Total Relationships: {total_relationships}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving graph statistics: {e}\")\n",
    "\n",
    "# Call the function\n",
    "get_graph_statistics(neo4j_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "66a4a4a3-adc6-4aaf-896a-96e4537be83a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>id</th>\n",
       "      <th>entities</th>\n",
       "      <th>problems</th>\n",
       "      <th>treatments</th>\n",
       "      <th>tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon, champ, how you holding up? Goo...</td>\n",
       "      <td>Subjective:\\n- Symptoms: Lower back pain, radi...</td>\n",
       "      <td>39a26c55-f710-4272-8609-2a725ef6d068</td>\n",
       "      <td>{'PROBLEM': ['radiculopathy', 'the pain', 'wea...</td>\n",
       "      <td>['radiculopathy', 'the pain', 'weakness in the...</td>\n",
       "      <td>['anti - inflammatory medications', 'treatment...</td>\n",
       "      <td>['differential diagnoses', 'x - rays of the lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What brings you in here today? Hi, I'm um, I'm...</td>\n",
       "      <td>Subjective:\\n- Presenting with dry cough for 1...</td>\n",
       "      <td>b1448089-3c41-423a-9737-0ed25e0e99c8</td>\n",
       "      <td>{'PROBLEM': ['known sick contacts', 'flu - lik...</td>\n",
       "      <td>['known sick contacts', 'flu - like illness', ...</td>\n",
       "      <td>['appendect', 'omy', 'infection control measur...</td>\n",
       "      <td>['sw', 'covid', 'swab', 'testing']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Do you have any known allergies to medications...</td>\n",
       "      <td>Subjective:\\n- No known allergies to medicatio...</td>\n",
       "      <td>78cf9b57-3a1f-41df-ba55-af3bbe843228</td>\n",
       "      <td>{'PROBLEM': ['known allergies'], 'TREATMENT': ...</td>\n",
       "      <td>['known allergies']</td>\n",
       "      <td>['medications']</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  Good afternoon, champ, how you holding up? Goo...   \n",
       "1  What brings you in here today? Hi, I'm um, I'm...   \n",
       "2  Do you have any known allergies to medications...   \n",
       "\n",
       "                                              output  \\\n",
       "0  Subjective:\\n- Symptoms: Lower back pain, radi...   \n",
       "1  Subjective:\\n- Presenting with dry cough for 1...   \n",
       "2  Subjective:\\n- No known allergies to medicatio...   \n",
       "\n",
       "                                     id  \\\n",
       "0  39a26c55-f710-4272-8609-2a725ef6d068   \n",
       "1  b1448089-3c41-423a-9737-0ed25e0e99c8   \n",
       "2  78cf9b57-3a1f-41df-ba55-af3bbe843228   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'PROBLEM': ['radiculopathy', 'the pain', 'wea...   \n",
       "1  {'PROBLEM': ['known sick contacts', 'flu - lik...   \n",
       "2  {'PROBLEM': ['known allergies'], 'TREATMENT': ...   \n",
       "\n",
       "                                            problems  \\\n",
       "0  ['radiculopathy', 'the pain', 'weakness in the...   \n",
       "1  ['known sick contacts', 'flu - like illness', ...   \n",
       "2                                ['known allergies']   \n",
       "\n",
       "                                          treatments  \\\n",
       "0  ['anti - inflammatory medications', 'treatment...   \n",
       "1  ['appendect', 'omy', 'infection control measur...   \n",
       "2                                    ['medications']   \n",
       "\n",
       "                                               tests  \n",
       "0  ['differential diagnoses', 'x - rays of the lo...  \n",
       "1                 ['sw', 'covid', 'swab', 'testing']  \n",
       "2                                                 []  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NER_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e905794d-6305-4053-9990-8e5acdd51d1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "reduced = pd.read_csv(\"soap_cptf_generated_summaries.csv\")\n",
    "# Display the first few rows\n",
    "print(reduced.head())\n",
    "\n",
    "# Check DataFrame info\n",
    "print(reduced.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0542d9-5508-4ce8-bc71-33d3a4948d47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming 'NER_df' and 'reduced' are your existing DataFrames\n",
    "\n",
    "# Ensure both dataframes are sorted or indexed in the same way if they are not already\n",
    "NER_df = NER_df.reset_index(drop=True)\n",
    "reduced = reduced.reset_index(drop=True)\n",
    "\n",
    "# Merge the 'reduced_text' column from 'reduced' into 'NER_df'\n",
    "NER_df['reduced_text'] = reduced['reduced_text']\n",
    "\n",
    "# Verify the merge by displaying the updated DataFrame\n",
    "print(NER_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26702fb-a290-4f67-95e5-947a5ad38027",
   "metadata": {},
   "source": [
    "### Summarization Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19b312c2-8de2-492f-9729-f26fdc5e88d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Use your Hugging Face token\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "207b966f-5da2-42c4-bf11-83886073a879",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers huggingface_hub\n",
    "!pip install -q --upgrade accelerate\n",
    "!pip install -q bitsandbytes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73d1b8e1-5d78-4e86-82c2-80c0ec07a3e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Model and Tokenizer:   0%|          | 0/2 [00:00<?, ?step/s]/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/accelerate/utils/modeling.py:1569: UserWarning: Current model requires 128 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n",
      "Initializing Model and Tokenizer: 100%|██████████| 2/2 [00:02<00:00,  1.00s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "print(\"Loading model and tokenizer...\")\n",
    "with tqdm(total=2, desc=\"Initializing Model and Tokenizer\", unit=\"step\") as pbar:\n",
    "    model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        device_map=\"auto\",  # Automatically map the model to the available device\n",
    "    )\n",
    "    pbar.update(1)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.padding_side = 'left'\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    pbar.update(1)\n",
    "print(\"Model and tokenizer loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a48f159d-2f4c-4d7d-a063-d5ac0c034fae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "# Initialize the pipeline\n",
    "summarizer = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,  # Pass pre-loaded model\n",
    "    tokenizer=tokenizer,  # Pass pre-loaded tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5fc33a-396f-46ad-b010-d2448449e0bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ------------------------- Context Retrieval from Neo4j -------------------------\n",
    "def retrieve_context(patient_id, neo4j_graph, limit=2):\n",
    "    \"\"\"Retrieves patient context (problems, tests, treatments) from Neo4j\"\"\"\n",
    "    query = f\"\"\"\n",
    "    MATCH (p:Patient {{id: '{patient_id}'}})-[r]-(n)\n",
    "    WHERE type(r) IN ['HAS_PROBLEM', 'UNDERWENT_TEST', 'WAS_TREATED_WITH']\n",
    "    RETURN n.title AS node, type(r) AS relationship_type\n",
    "    \"\"\"\n",
    "    results = neo4j_graph.query(query)\n",
    "    \n",
    "    context = {\"Problems\": [], \"Treatments\": [], \"Tests\": []}\n",
    "    counts = {\"HAS_PROBLEM\": 0, \"WAS_TREATED_WITH\": 0, \"UNDERWENT_TEST\": 0} \n",
    "\n",
    "    for record in results:\n",
    "        relationship_type = record[\"relationship_type\"]\n",
    "        node = record[\"node\"]\n",
    "        if relationship_type == \"HAS_PROBLEM\" and counts[\"HAS_PROBLEM\"] < limit:\n",
    "            context[\"Problems\"].append(node)\n",
    "            counts[\"HAS_PROBLEM\"] += 1\n",
    "        elif relationship_type == \"WAS_TREATED_WITH\" and counts[\"WAS_TREATED_WITH\"] < limit:\n",
    "            context[\"Treatments\"].append(node)\n",
    "            counts[\"WAS_TREATED_WITH\"] += 1\n",
    "        elif relationship_type == \"UNDERWENT_TEST\" and counts[\"UNDERWENT_TEST\"] < limit:\n",
    "            context[\"Tests\"].append(node)\n",
    "            counts[\"UNDERWENT_TEST\"] += 1\n",
    "        if all(count == limit for count in counts.values()):\n",
    "            break\n",
    "\n",
    "    return context\n",
    "\n",
    "# ------------------------- Few-Shot Prompt Construction -------------------------\n",
    "def construct_few_shot_prompt(reduced_text, context):\n",
    "    def safe_join(items):\n",
    "        return \", \".join(str(item) for item in items if item is not None) if items else \"None\"\n",
    "\n",
    "    prompt = f\"\"\"You are a medical expert. Summarize the input text in a clear, cohesive, and medically accurate manner. Do not include the input & prompt in the final summary.\n",
    "\n",
    "### **Patient Data for Summarization**\n",
    "**Input:**  \n",
    "{reduced_text}\n",
    "\n",
    "**Context:**  \n",
    "- Problems: {safe_join(context['Problems'])}  \n",
    "- Tests: {safe_join(context['Tests'])}  \n",
    "- Treatments: {safe_join(context['Treatments'])}  \n",
    "\n",
    "---\n",
    "### **Generated Summary:**  \n",
    "\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Generation parameters\n",
    "generation_params = {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.8,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_k\": 20,\n",
    "    \"max_new_tokens\": 200,\n",
    "    \"repetition_penalty\": 1.1\n",
    "}\n",
    "\n",
    "def generate_summaries(df, neo4j_graph, summarizer, tokenizer, generation_params, batch_size=2):\n",
    "    generated_summaries = []\n",
    "    latency_list = []  # Time per summary\n",
    "    throughput_list = []  # Tokens processed per second\n",
    "    main_progress = tqdm(total=len(df), desc=\"Generating Summaries\", unit=\"notes\")\n",
    "\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        prompts = []\n",
    "        batch_start_time = time.time()\n",
    "\n",
    "        for _, row in batch.iterrows():\n",
    "            patient_id = row[\"id\"]\n",
    "            reduced_text = row[\"reduced_text\"]\n",
    "            context = retrieve_context(patient_id, neo4j_graph)\n",
    "            prompt = construct_few_shot_prompt(reduced_text, context)\n",
    "            prompts.append(prompt)\n",
    "\n",
    "        batch_input_tokens = sum(len(tokenizer.encode(prompt)) for prompt in prompts)\n",
    "        summaries = summarizer(prompts, **generation_params)\n",
    "        batch_end_time = time.time()\n",
    "\n",
    "        latency_list.append((batch_end_time - batch_start_time) / len(batch))\n",
    "        throughput_list.append(batch_input_tokens / (batch_end_time - batch_start_time))\n",
    "\n",
    "        # Handle different formats of summaries\n",
    "        for summary in summaries:\n",
    "            # Check if the summary is a list of dictionaries (common in batch processing)\n",
    "            if isinstance(summary, list) and len(summary) > 0 and isinstance(summary[0], dict):\n",
    "                generated_summary = summary[0].get(\"generated_text\", \"\")\n",
    "            elif isinstance(summary, dict):  # Single dictionary output\n",
    "                generated_summary = summary.get(\"generated_text\", \"\")\n",
    "            else:\n",
    "                generated_summary = str(summary)  # Convert to string if unexpected format\n",
    "            \n",
    "            generated_summaries.append(generated_summary)\n",
    "\n",
    "        main_progress.update(len(batch))\n",
    "\n",
    "    main_progress.close()\n",
    "    df[\"generated_summary\"] = generated_summaries\n",
    "    print(\"\\n🔹 Computational Efficiency Metrics:\")\n",
    "    print(f\"📌 Average Latency (Time per Summary): {sum(latency_list) / len(latency_list):.4f} seconds\")\n",
    "    print(f\"📌 Average Throughput: {sum(throughput_list) / len(throughput_list):.2f} tokens/second\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ------------------------- Execution -------------------------\n",
    "# Assuming merged_df contains patient data\n",
    "NER_df = generate_summaries(NER_df, neo4j_graph, summarizer, tokenizer, generation_params)\n",
    "\n",
    "# ✅ Save results to CSV if needed\n",
    "NER_df.to_csv(\"summarized_output.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64143a9-8568-42e2-a4c2-8707c1820860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
