{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "825838cd-aeac-4593-8920-e02e2a24e768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers huggingface_hub langchain_community\n",
    "!pip install -q --upgrade accelerate\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q neo4j\n",
    "!pip install -q --upgrade accelerate\n",
    "!pip install -q -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "161b54d3-791b-4cd4-91be-89900c0e18e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4cecdb2-9491-4594-8dcf-bc25c2153a31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Graphdb configuration\n",
    "NEO4J_URI=\"neo4j+s://0e49642b.databases.neo4j.io\"\n",
    "NEO4J_USERNAME=\"neo4j\"\n",
    "NEO4J_PASSWORD=\"XB8uxzAOAquawNok7UiA5DlrnC2oncJdgPfNUmWYvnI\"\n",
    "\n",
    "import os\n",
    "os.environ[\"NEO4J_URI\"]=NEO4J_URI\n",
    "os.environ[\"NEO4J_USERNAME\"]=NEO4J_USERNAME\n",
    "os.environ[\"NEO4J_PASSWORD\"]=NEO4J_PASSWORD\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "neo4j_graph=Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4d962d6-9fc0-4221-809d-f4ce31bdcfd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.graphs.neo4j_graph.Neo4jGraph at 0x7f855017acb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neo4j_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84896e12-325a-4b65-9e74-e0157df207f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          note_id                                              input  \\\n",
      "0  16002318-DS-17  <SEX> F <SERVICE> SURGERY <ALLERGIES> Iodine /...   \n",
      "1   15638884-DS-4  <SEX> M <SERVICE> MEDICINE <ALLERGIES> Augment...   \n",
      "2  12435705-DS-14  <SEX> M <SERVICE> MEDICINE <ALLERGIES> ibuprof...   \n",
      "3   12413577-DS-4  <SEX> F <SERVICE> OBSTETRICS/GYNECOLOGY <ALLER...   \n",
      "4  17967161-DS-29  <SEX> M <SERVICE> SURGERY <ALLERGIES> lisinopr...   \n",
      "\n",
      "                                        reduced_text  \\\n",
      "0  <|begin_of_text|><SEX> F <SERVICE> SURGERY <AL...   \n",
      "1  <|begin_of_text|><SEX> M <SERVICE> MEDICINE <A...   \n",
      "2  <|begin_of_text|><SEX> M <SERVICE> MEDICINE <A...   \n",
      "3  <|begin_of_text|><SEX> F <SERVICE> OBSTETRICS/...   \n",
      "4  <|begin_of_text|><SEX> M <SERVICE> SURGERY <AL...   \n",
      "\n",
      "                                            entities  \\\n",
      "0  {'PROBLEM': ['101', '7 pound weight loss', 'a ...   \n",
      "1  {'PROBLEM': ['+', '-', '1 cm area', 'a \" cyst ...   \n",
      "2  {'PROBLEM': ['a 0. 7 x 0. 7 x 0. 7 cm simple c...   \n",
      "3  {'PROBLEM': ['a third - degree uterine prolaps...   \n",
      "4  {'PROBLEM': ['101', 'abuse', 'acute pancreatit...   \n",
      "\n",
      "                                            problems  \\\n",
      "0  ['101', '7 pound weight loss', 'a fever', 'a l...   \n",
      "1  ['+', '-', '1 cm area', 'a \" cyst \"', 'a 2cm d...   \n",
      "2  ['a 0. 7 x 0. 7 x 0. 7 cm simple cyst', 'a 2. ...   \n",
      "3  ['a third - degree uterine prolapse', 'abnorma...   \n",
      "4  ['101', 'abuse', 'acute pancreatitis', 'angina...   \n",
      "\n",
      "                                          treatments  \\\n",
      "0  ['abdominal exercises', 'albuterol sulfate', '...   \n",
      "1  ['a bankart repair', 'a nicotine patch', 'a st...   \n",
      "2  ['2', 'a prolonged course', 'ampicillin', 'ant...   \n",
      "3  ['a stool softener', 'acetaminophen', 'admissi...   \n",
      "4  ['a', 'a 3 mm x 40 mm balloon percutaneous tra...   \n",
      "\n",
      "                                               tests  \n",
      "0         ['b12', 'bmi', 'calcium', 'physical exam']  \n",
      "1  ['.', '_', 'a', 'a ct scan', 'absbaso', 'abseo...  \n",
      "2  ['16s rdna primer set', 'aa', 'abl', 'acid fas...  \n",
      "3  ['hct', 'hgb', 'mch', 'mchc', 'mcv', 'nadr', '...  \n",
      "4  ['angap', 'blood', 'blood calcium', 'blood ck ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "merged_df = pd.read_csv(\"merged_data.csv\")\n",
    "\n",
    "# Check the data\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb79409c-5ca6-47d9-824b-dd7d474dd8bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['a completion colectomy', 'a new ileostomy', 'advil', 'advil ( ibuprofen )', 'albuteral', 'alcohol', 'allopurinol', 'allopurinol _', 'amlodipine', 'amoxicillin', 'an over the counter stool softener', 'anterior left - sided component separation', 'any other medications', 'atenolol', 'chemotherapy', 'clonidine', 'codeine', 'cold medication', 'dental procedures', 'discharge medications', 'endoscope', 'enteric tube', 'furosemide', 'hernia repair material', 'hip replacement', 'his previous colostomy', 'inciscional prevena vac', 'invasive procedure', 'lasix', 'left component separation', 'lisinopril', 'major surgical', 'medication', 'medications', 'mesh', 'midline hernia repair', 'narcotic pain medications', 'other sedating medications', 'placement of', 'plastic surgery', 'potassium er', 'primary midline repair', 'r', 'r jp drain serosang', 'radiation', 'removal', 'resection', 'rivaroxaban', 'rivaroxaban [ xarelto ]', 'steri - strips', 'surgery', 'surgical resection', 'symbicort', 'the', 'the drain placement', 'the ileostomy', 'the narcotic pain medication', 'this medication', 'this procedure', 'total colectomy', 'total right hip arthroplasty', 'tylen', 'tylenol', 'vitamin d', 'volume mesenteric free - fluid', 'with', 'xarelto', 'your home blood pressure medications', 'your new ileostomy']\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['treatments'].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d2ef831-4b23-4c1c-b321-012b95004d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|begin_of_text|><SEX> M <SERVICE> SURGERY <ALLERGIES> Codeine / Tetracycline <ATTENDING> ___ ___ Complaint: Large ___ hernia and sessile polyp <MAJOR SURGICAL OR INVASIVE PROCEDURE> ___ and midline hernia repair, left component separation, retrorectus repair of the stomal hernia primary midline repair with the above-mentioned anterior left-sided component separation and placement of mesh and panniculectomy <HISTORY OF PRESENT ILLNESS> Mr. ___ is a ___ year old male with history of rectal cancer and a longstanding left-sided colostomy. He had a colonoscopy in ___ of this year where a large polyp that was unable to be extracted by endoscope was found by Dr. ___. He was referred to Dr. ___ surgical resection of the polyp. Per last clinic note by Dr. ___: It has been 2 months since I last saw Mr. ___ for his ___ hernia and a month since he underwent colonoscopy with identification of a low-grade cancer proximal to his end colostomy. Since he is last seen there are no changes in his health and well-being. He has no new complaints. He is here to discuss removal of the cancer and management of his large ___ hernia. I discussed with him in detail the findings from Dr. ___ ___ and the pathology report as well as multiple polyps that he has currently and the issue that he generated a cancer in the ___ years since his last colonoscopy. I made out a plan for him by which she would undergo completion colectomy via a midline incision with removal of his previous colostomy and creation of a new ileostomy reinforced with mesh. Also with resultant repair of the stomal hernia where his previous colostomy will have been. I plan to do this in conjunction with Dr. ___ of plastic surgery. He and I and his wife discussed the risks benefits and potential outcomes of a variety of surgical options but they agree that this would be the best option. I plan to have him see Dr. ___ at his earliest convenience, hopefully very soon since he has had some difficulty getting to appointments quickly. In addition I have asked him to check in with his primary care doctor and his cardiologist for medical clearance. He recently had an abdominal CT for other reasons that did not demonstrate any metastatic disease to the liver but he does still need a chest CAT scan as part of routine staging for this new finding. <PAST MEDICAL HISTORY> -Atrial fibrillation, currently not on home Xarelto -Hypertension -Rectal cancer status post resection, chemotherapy and radiation (___) -Hip replacement ___ -Knee replacement ___ <SOCIAL HISTORY> ___ <FAMILY HISTORY> His mother had a stroke in her elderly years. Otherwise, denies any family history of stroke or neurologic disease. <PHYSICAL EXAM> Physical exam ___ VS: 98.6 bp105 / 69 hr93 rr18 93%RA GEN: WD, WN in NAD HEENT: NCAT, EOMI, anicteric CV: Irregular rate and rhythm PULM: No respiratory distress ABD: Obese abdomen, soft, non distended, non tender. Inciscional prevena vac in place. R JP drain serosang. ileostomy with pink stoma with stool/gas in bag EXT: WWP, no CCE NEURO: A&Ox3, no focal neurologic deficits PSYCH: normal judgment/insight, normal memory, normal mood/affect <PERTINENT RESULTS> ADMISSION LABS: ___ 03: 20PM WBC-12.2* RBC-3.42* HGB-10.6* HCT-31.2* MCV-91 MCH-31.0 MCHC-34.0 RDW-12.6 RDWSD-41.4 ___ 03: 20PM NEUTS-88.4* LYMPHS-2.9* MONOS-7.8 EOS-0.0* BASOS-0.2 IM ___ AbsNeut-10.82* AbsLymp-0.36* AbsMono-0.96* AbsEos-0.00* AbsBaso-0.02 ___ 03: 20PM PLT COUNT-191 ___ 03: 15PM GLUCOSE-171* UREA N-20 CREAT-1.8* SODIUM-142 POTASSIUM-4.2 CHLORIDE-104 TOTAL CO2-26 ANION GAP-12 ___ 03: 15PM estGFR-Using this ___ 03: 15PM CALCIUM-8.5 PHOSPHATE-5.0* MAGNESIUM-1.9 ___ 03: 15PM WBC-UNABLE TO. DISCHARGE LABS: ___ 05: 49AM BLOOD WBC-4.5 RBC-2.62* Hgb-8.2* Hct-25.8* MCV-99* MCH-31.3 MCHC-31.8* RDW-13.2 RDWSD-47.2* Plt ___ ___ 05: 49AM BLOOD Glucose-87 UreaN-29* Creat-1.1 Na-137 K-4.5 Cl-104 HCO3-19* AnGap-14 ___ 05: 49AM BLOOD Calcium-8.3* Phos-3.8 Mg-2.0. IMAGING: ___ CT A/P LOWER CHEST: There is a moderate right pleural effusion. There is bibasilar atelectasis. Large calcified granulomas noted in the right lower lobe. No pericardial effusion. ABDOMEN: HEPATOBILIARY: The liver demonstrates homogenous attenuation throughout. A 3.9 cm hypoenhancing lesion in segment ___ is unchanged from prior and likely represents a simple cyst. There is no evidence of intrahepatic or extrahepatic biliary dilatation. The gallbladder is within normal limits. PANCREAS: The pancreas has normal attenuation throughout, without evidence of focal lesions or pancreatic ductal dilatation. There is no peripancreatic stranding. SPLEEN: There is a 7.5 x 8.6 cm heterogeneous lesion with minimal enhancement (when compared to the sure start series) in the anterior peripheral aspect of the spleen, new from exam in ___. There are additional hypodense lesions in the spleen (e.g. 05: 26 and 05: 30). Supple area of hyperenhancement and a peripheral posterior aspect of the spleen (05'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['reduced_text'].iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d07a38-ede3-4423-9f4d-c77cb7ae33cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Function to escape and preprocess text for Cypher queries\n",
    "def escape_text(text):\n",
    "    return text.replace(\"'\", \" \")  # Replace apostrophes with spaces\n",
    "\n",
    "# Function to build the Knowledge Graph\n",
    "def build_knowledge_graph_generalized(df, neo4j_graph):\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Building Knowledge Graph\"):\n",
    "        # Extract data\n",
    "        patient_id = escape_text(row['note_id'])\n",
    "        problems = [escape_text(problem) for problem in eval(row['problems'])]\n",
    "        treatments = [escape_text(treatment) for treatment in eval(row['treatments'])]\n",
    "        tests = [escape_text(test) for test in eval(row['tests'])]\n",
    "\n",
    "        # Create Patient node\n",
    "        patient_query = f\"\"\"\n",
    "        MERGE (p:Patient {{id: '{patient_id}'}})\n",
    "        \"\"\"\n",
    "        neo4j_graph.query(patient_query)\n",
    "\n",
    "        # Create Problem nodes and relationships\n",
    "        for problem in problems:\n",
    "            problem_query = f\"\"\"\n",
    "            MERGE (pr:Problem {{title: '{problem}'}})\n",
    "            MERGE (p:Patient {{id: '{patient_id}'}})\n",
    "            MERGE (p)-[:HAS_PROBLEM]->(pr)\n",
    "            \"\"\"\n",
    "            neo4j_graph.query(problem_query)\n",
    "\n",
    "        # Create Treatment nodes and relationships\n",
    "        for treatment in treatments:\n",
    "            treatment_query = f\"\"\"\n",
    "            MERGE (tr:Treatment {{title: '{treatment}'}})\n",
    "            MERGE (p:Patient {{id: '{patient_id}'}})\n",
    "            MERGE (p)-[:WAS_TREATED_WITH]->(tr)\n",
    "            \"\"\"\n",
    "            neo4j_graph.query(treatment_query)\n",
    "\n",
    "        # Create Test nodes and relationships\n",
    "        for test in tests:\n",
    "            test_query = f\"\"\"\n",
    "            MERGE (t:Test {{title: '{test}'}})\n",
    "            MERGE (p:Patient {{id: '{patient_id}'}})\n",
    "            MERGE (p)-[:UNDERWENT_TEST]->(t)\n",
    "            \"\"\"\n",
    "            neo4j_graph.query(test_query)\n",
    "\n",
    "# Execute the function to build the KG\n",
    "build_knowledge_graph_generalized(merged_df, neo4j_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb2fe5c4-ad94-4851-903d-2120a373b3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Counts by Type:\n",
      "Node Type: ['Problem'], Count: 3841\n",
      "Node Type: ['Treatment'], Count: 1686\n",
      "Node Type: ['Test'], Count: 1468\n",
      "Node Type: ['Patient'], Count: 100\n",
      "\n",
      "Relationship Counts by Type:\n",
      "Relationship Type: HAS_PROBLEM, Count: 6760\n",
      "Relationship Type: UNDERWENT_TEST, Count: 5469\n",
      "Relationship Type: WAS_TREATED_WITH, Count: 3214\n",
      "\n",
      "Total Counts:\n",
      "Total Nodes: 7095\n",
      "Total Relationships: 15443\n"
     ]
    }
   ],
   "source": [
    "def get_graph_statistics(neo4j_graph):\n",
    "    # Query to count nodes by type\n",
    "    node_count_query = \"\"\"\n",
    "    MATCH (n)\n",
    "    RETURN labels(n) AS node_type, COUNT(*) AS count\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "\n",
    "    # Query to count relationships by type\n",
    "    relationship_count_query = \"\"\"\n",
    "    MATCH ()-[r]->()\n",
    "    RETURN TYPE(r) AS relationship_type, COUNT(*) AS count\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "\n",
    "    # Query to count total nodes\n",
    "    total_nodes_query = \"\"\"\n",
    "    MATCH (n)\n",
    "    RETURN COUNT(*) AS total_nodes\n",
    "    \"\"\"\n",
    "\n",
    "    # Query to count total relationships\n",
    "    total_relationships_query = \"\"\"\n",
    "    MATCH ()-[r]->()\n",
    "    RETURN COUNT(*) AS total_relationships\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute queries and fetch results\n",
    "    node_counts = neo4j_graph.query(node_count_query)\n",
    "    relationship_counts = neo4j_graph.query(relationship_count_query)\n",
    "    total_nodes = neo4j_graph.query(total_nodes_query)\n",
    "    total_relationships = neo4j_graph.query(total_relationships_query)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Node Counts by Type:\")\n",
    "    for record in node_counts:\n",
    "        print(f\"Node Type: {record['node_type']}, Count: {record['count']}\")\n",
    "\n",
    "    print(\"\\nRelationship Counts by Type:\")\n",
    "    for record in relationship_counts:\n",
    "        print(f\"Relationship Type: {record['relationship_type']}, Count: {record['count']}\")\n",
    "\n",
    "    print(\"\\nTotal Counts:\")\n",
    "    print(f\"Total Nodes: {total_nodes[0]['total_nodes']}\")\n",
    "    print(f\"Total Relationships: {total_relationships[0]['total_relationships']}\")\n",
    "\n",
    "# Call the function\n",
    "get_graph_statistics(neo4j_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ee5a918-312d-4c4b-8918-ba89dfe8c1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Irrelevant nodes and relationships have been deleted.\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# GraphDB configuration\n",
    "NEO4J_URI = \"neo4j+s://0e49642b.databases.neo4j.io\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"XB8uxzAOAquawNok7UiA5DlrnC2oncJdgPfNUmWYvnI\"\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "# Function to execute a query\n",
    "def execute_query(query):\n",
    "    with driver.session() as session:\n",
    "        session.run(query)\n",
    "\n",
    "# Query to delete irrelevant relationships\n",
    "delete_relationships_query = \"\"\"\n",
    "MATCH ()-[r]->()\n",
    "WHERE NOT type(r) IN ['HAS_PROBLEM', 'UNDERWENT_TEST', 'WAS_TREATED_WITH']\n",
    "DELETE r;\n",
    "\"\"\"\n",
    "\n",
    "# Query to delete irrelevant nodes\n",
    "delete_nodes_query = \"\"\"\n",
    "MATCH (n)\n",
    "WHERE NOT labels(n)[0] IN ['Problem', 'Treatment', 'Test', 'Patient']\n",
    "DETACH DELETE n;\n",
    "\"\"\"\n",
    "\n",
    "# Execute queries sequentially\n",
    "execute_query(delete_relationships_query)\n",
    "execute_query(delete_nodes_query)\n",
    "\n",
    "# Close the driver connection\n",
    "driver.close()\n",
    "\n",
    "print(\"Irrelevant nodes and relationships have been deleted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1981a9bc-361b-4b72-ad6b-29f903c22453",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node Counts by Type:\n",
      "Node Type: ['Problem'], Count: 3841\n",
      "Node Type: ['Treatment'], Count: 1686\n",
      "Node Type: ['Test'], Count: 1468\n",
      "Node Type: ['Patient'], Count: 100\n",
      "\n",
      "Relationship Counts by Type:\n",
      "Relationship Type: HAS_PROBLEM, Count: 6760\n",
      "Relationship Type: UNDERWENT_TEST, Count: 5469\n",
      "Relationship Type: WAS_TREATED_WITH, Count: 3214\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "\n",
    "# GraphDB configuration\n",
    "NEO4J_URI = \"neo4j+s://0e49642b.databases.neo4j.io\"\n",
    "NEO4J_USERNAME = \"neo4j\"\n",
    "NEO4J_PASSWORD = \"XB8uxzAOAquawNok7UiA5DlrnC2oncJdgPfNUmWYvnI\"\n",
    "\n",
    "# Connect to Neo4j\n",
    "driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USERNAME, NEO4J_PASSWORD))\n",
    "\n",
    "# Function to execute a query and return results\n",
    "def fetch_query_results(query):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query)\n",
    "        return [record.data() for record in result]\n",
    "\n",
    "# Query to count nodes by label\n",
    "node_count_query = \"\"\"\n",
    "MATCH (n)\n",
    "RETURN labels(n) AS NodeType, COUNT(n) AS Count\n",
    "ORDER BY Count DESC\n",
    "\"\"\"\n",
    "\n",
    "# Query to count relationships by type\n",
    "relationship_count_query = \"\"\"\n",
    "MATCH ()-[r]->()\n",
    "RETURN type(r) AS RelationshipType, COUNT(r) AS Count\n",
    "ORDER BY Count DESC\n",
    "\"\"\"\n",
    "\n",
    "# Fetch and display node counts\n",
    "node_counts = fetch_query_results(node_count_query)\n",
    "print(\"Node Counts by Type:\")\n",
    "for record in node_counts:\n",
    "    print(f\"Node Type: {record['NodeType']}, Count: {record['Count']}\")\n",
    "\n",
    "# Fetch and display relationship counts\n",
    "relationship_counts = fetch_query_results(relationship_count_query)\n",
    "print(\"\\nRelationship Counts by Type:\")\n",
    "for record in relationship_counts:\n",
    "    print(f\"Relationship Type: {record['RelationshipType']}, Count: {record['Count']}\")\n",
    "\n",
    "# Close the driver connection\n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26702fb-a290-4f67-95e5-947a5ad38027",
   "metadata": {},
   "source": [
    "### Summarization Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19b312c2-8de2-492f-9729-f26fdc5e88d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Use your Hugging Face token\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3710ebf-d246-463e-a624-23f06e5effb8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup and quantization configuration done.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variable for better memory management\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Configure quantization (8-bit)\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_enable_fp32_cpu_offload=True\n",
    ")\n",
    "print(\"Environment setup and quantization configuration done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a4e3f4-d6d2-4a82-8aee-b59432ae0463",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pathos 0.3.3 requires dill>=0.3.9, but you have dill 0.3.8 which is incompatible.\n",
      "pathos 0.3.3 requires multiprocess>=0.70.17, but you have multiprocess 0.70.16 which is incompatible.\n",
      "s3fs 2024.12.0 requires fsspec==2024.12.0.*, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "#!pip install -q --upgrade packaging\n",
    "#!pip install -q --upgrade transformers bitsandbytes datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a377856-874c-48fc-a542-1d0f50edbf6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Model and Tokenizer: 100%|██████████| 2/2 [00:02<00:00,  1.42s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "print(\"Loading model and tokenizer...\")\n",
    "with tqdm(total=2, desc=\"Initializing Model and Tokenizer\", unit=\"step\") as pbar:\n",
    "    model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\",\n",
    "        #output_attentions=True,  # Enable attention outputs for AGTD\n",
    "        #return_dict_in_generate=True  # Ensures attention outputs are generated\n",
    "    )\n",
    "    pbar.update(1)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.padding_side = 'left'\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    pbar.update(1)\n",
    "print(\"Model and tokenizer loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7d4119c-3dec-452f-b2a6-4518e76ad5c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>note_id</th>\n",
       "      <th>input</th>\n",
       "      <th>reduced_text</th>\n",
       "      <th>entities</th>\n",
       "      <th>problems</th>\n",
       "      <th>treatments</th>\n",
       "      <th>tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16002318-DS-17</td>\n",
       "      <td>&lt;SEX&gt; F &lt;SERVICE&gt; SURGERY &lt;ALLERGIES&gt; Iodine /...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;SEX&gt; F &lt;SERVICE&gt; SURGERY &lt;AL...</td>\n",
       "      <td>{'PROBLEM': ['101', '7 pound weight loss', 'a ...</td>\n",
       "      <td>['101', '7 pound weight loss', 'a fever', 'a l...</td>\n",
       "      <td>['abdominal exercises', 'albuterol sulfate', '...</td>\n",
       "      <td>['b12', 'bmi', 'calcium', 'physical exam']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15638884-DS-4</td>\n",
       "      <td>&lt;SEX&gt; M &lt;SERVICE&gt; MEDICINE &lt;ALLERGIES&gt; Augment...</td>\n",
       "      <td>&lt;|begin_of_text|&gt;&lt;SEX&gt; M &lt;SERVICE&gt; MEDICINE &lt;A...</td>\n",
       "      <td>{'PROBLEM': ['+', '-', '1 cm area', 'a \" cyst ...</td>\n",
       "      <td>['+', '-', '1 cm area', 'a \" cyst \"', 'a 2cm d...</td>\n",
       "      <td>['a bankart repair', 'a nicotine patch', 'a st...</td>\n",
       "      <td>['.', '_', 'a', 'a ct scan', 'absbaso', 'abseo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          note_id                                              input  \\\n",
       "0  16002318-DS-17  <SEX> F <SERVICE> SURGERY <ALLERGIES> Iodine /...   \n",
       "1   15638884-DS-4  <SEX> M <SERVICE> MEDICINE <ALLERGIES> Augment...   \n",
       "\n",
       "                                        reduced_text  \\\n",
       "0  <|begin_of_text|><SEX> F <SERVICE> SURGERY <AL...   \n",
       "1  <|begin_of_text|><SEX> M <SERVICE> MEDICINE <A...   \n",
       "\n",
       "                                            entities  \\\n",
       "0  {'PROBLEM': ['101', '7 pound weight loss', 'a ...   \n",
       "1  {'PROBLEM': ['+', '-', '1 cm area', 'a \" cyst ...   \n",
       "\n",
       "                                            problems  \\\n",
       "0  ['101', '7 pound weight loss', 'a fever', 'a l...   \n",
       "1  ['+', '-', '1 cm area', 'a \" cyst \"', 'a 2cm d...   \n",
       "\n",
       "                                          treatments  \\\n",
       "0  ['abdominal exercises', 'albuterol sulfate', '...   \n",
       "1  ['a bankart repair', 'a nicotine patch', 'a st...   \n",
       "\n",
       "                                               tests  \n",
       "0         ['b12', 'bmi', 'calcium', 'physical exam']  \n",
       "1  ['.', '_', 'a', 'a ct scan', 'absbaso', 'abseo...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1b83384-d121-4fd2-9188-13db75bbf709",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Model and Tokenizer: 100%|██████████| 2/2 [00:02<00:00,  1.27s/step]\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n",
      "Pipeline and generation parameters are ready.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Model name\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "# Load the model with quantization\n",
    "print(\"Loading model and tokenizer...\")\n",
    "with tqdm(total=2, desc=\"Initializing Model and Tokenizer\", unit=\"step\") as pbar:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quantization_config,  # Quantization applied here\n",
    "        device_map=\"auto\",  # Use `accelerate` to manage device allocation\n",
    "    )\n",
    "    pbar.update(1)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.padding_side = 'left'\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id  # Avoid padding errors\n",
    "    pbar.update(1)\n",
    "\n",
    "print(\"Model and tokenizer loaded successfully.\")\n",
    "\n",
    "# Initialize the pipeline\n",
    "summarizer = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,  # Pass pre-loaded model\n",
    "    tokenizer=tokenizer,  # Pass pre-loaded tokenizer\n",
    ")\n",
    "\n",
    "# Generation parameters\n",
    "generation_params = {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.1,\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_k\": 80,\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"repetition_penalty\": 1.3\n",
    "}\n",
    "\n",
    "print(\"Pipeline and generation parameters are ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71425d6-950c-4aa1-82b7-2cc6182a4977",
   "metadata": {},
   "source": [
    "### Construct Zero Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1416acb9-5a11-405b-8020-6f25df14d82e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Function to retrieve context from KG with limits\n",
    "def retrieve_context(patient_id, neo4j_graph, limit=2):\n",
    "    query = f\"\"\"\n",
    "    MATCH (p:Patient {{id: '{patient_id}'}})-[r]-(n)\n",
    "    WHERE type(r) IN ['HAS_PROBLEM', 'UNDERWENT_TEST', 'WAS_TREATED_WITH']\n",
    "    RETURN n.title AS node, type(r) AS relationship_type\n",
    "    \"\"\"\n",
    "    results = neo4j_graph.query(query)\n",
    "    context = {\"Problems\": [], \"Treatments\": [], \"Tests\": []}\n",
    "    counts = {\"HAS_PROBLEM\": 0, \"WAS_TREATED_WITH\": 0, \"UNDERWENT_TEST\": 0}  # Initialize counts\n",
    "\n",
    "    for record in results:\n",
    "        relationship_type = record[\"relationship_type\"]\n",
    "        node = record[\"node\"]\n",
    "\n",
    "        # Check limits for each category and append if within limit\n",
    "        if relationship_type == \"HAS_PROBLEM\" and counts[\"HAS_PROBLEM\"] < limit:\n",
    "            context[\"Problems\"].append(node)\n",
    "            counts[\"HAS_PROBLEM\"] += 1\n",
    "        elif relationship_type == \"WAS_TREATED_WITH\" and counts[\"WAS_TREATED_WITH\"] < limit:\n",
    "            context[\"Treatments\"].append(node)\n",
    "            counts[\"WAS_TREATED_WITH\"] += 1\n",
    "        elif relationship_type == \"UNDERWENT_TEST\" and counts[\"UNDERWENT_TEST\"] < limit:\n",
    "            context[\"Tests\"].append(node)\n",
    "            counts[\"UNDERWENT_TEST\"] += 1\n",
    "\n",
    "        # Break early if all categories reach their limits\n",
    "        if all(count == limit for count in counts.values()):\n",
    "            break\n",
    "\n",
    "    return context\n",
    "\n",
    "\n",
    "# Function to construct a zero-shot prompt\n",
    "def construct_zero_shot_prompt(reduced_text, context):\n",
    "    prompt = f\"\"\"\n",
    "    ### Task ###\n",
    "    You are a highly knowledgeable and best medical expert working at NIH. Your task is to summarize clinical notes concisely and professionally using only the information provided in the Input and Context.\n",
    "    - Use a clear, organized structure.\n",
    "    - Summarize in a narrative storytelling tone.\n",
    "    - Avoid technical jargon when unnecessary, and focus on readability.\n",
    "    - Ensure the summary is factual, concise, and consistent with the provided data.\n",
    "\n",
    "    ### Task ###\n",
    "    Summarize the following patient note concisely and professionally in a clear and organized manner:\n",
    "    Input: {reduced_text}\n",
    "    Context: Problems: {context['Problems']}, Treatments: {context['Treatments']}, Tests: {context['Tests']}\n",
    "    Generated Summary:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Function to parse generated summaries\n",
    "def parse_summary_output(output):\n",
    "    if isinstance(output, dict) and \"generated_text\" in output:\n",
    "        return output[\"generated_text\"].split(\"Output:\")[-1].strip()\n",
    "    elif isinstance(output, str):\n",
    "        return output.split(\"Output:\")[-1].strip()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "print(\"Helper functions defined.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b68fb9-10cb-4c3c-b9b5-956fabc09fe6",
   "metadata": {},
   "source": [
    "### three shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "93c1b7f4-9dcc-40e0-88a4-d1ac6a2467eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Function to retrieve context from KG with limits\n",
    "def retrieve_context(patient_id, neo4j_graph, limit=2):\n",
    "    query = f\"\"\"\n",
    "    MATCH (p:Patient {{id: '{patient_id}'}})-[r]-(n)\n",
    "    WHERE type(r) IN ['HAS_PROBLEM', 'UNDERWENT_TEST', 'WAS_TREATED_WITH']\n",
    "    RETURN n.title AS node, type(r) AS relationship_type\n",
    "    \"\"\"\n",
    "    results = neo4j_graph.query(query)\n",
    "    context = {\"Problems\": [], \"Treatments\": [], \"Tests\": []}\n",
    "    counts = {\"HAS_PROBLEM\": 0, \"WAS_TREATED_WITH\": 0, \"UNDERWENT_TEST\": 0}  # Initialize counts\n",
    "\n",
    "    for record in results:\n",
    "        relationship_type = record[\"relationship_type\"]\n",
    "        node = record[\"node\"]\n",
    "\n",
    "        # Check limits for each category and append if within limit\n",
    "        if relationship_type == \"HAS_PROBLEM\" and counts[\"HAS_PROBLEM\"] < limit:\n",
    "            context[\"Problems\"].append(node)\n",
    "            counts[\"HAS_PROBLEM\"] += 1\n",
    "        elif relationship_type == \"WAS_TREATED_WITH\" and counts[\"WAS_TREATED_WITH\"] < limit:\n",
    "            context[\"Treatments\"].append(node)\n",
    "            counts[\"WAS_TREATED_WITH\"] += 1\n",
    "        elif relationship_type == \"UNDERWENT_TEST\" and counts[\"UNDERWENT_TEST\"] < limit:\n",
    "            context[\"Tests\"].append(node)\n",
    "            counts[\"UNDERWENT_TEST\"] += 1\n",
    "\n",
    "        # Break early if all categories reach their limits\n",
    "        if all(count == limit for count in counts.values()):\n",
    "            break\n",
    "\n",
    "    return context\n",
    "\n",
    "\n",
    "def construct_three_shot_prompt(reduced_text, context):\n",
    "    prompt = f\"\"\"\n",
    "    ### Task ###\n",
    "    You are a highly knowledgeable medical expert working at NIH. Your task is to summarize clinical notes concisely and professionally using only the information provided in the Input and Context. \n",
    "    - Do not include details or assumptions not explicitly mentioned.\n",
    "    - Do not add, infer, or guess any additional information.\n",
    "    - Ensure the summary is factual and consistent with the provided data.\n",
    "\n",
    "    ### Example 1 ###\n",
    "    Input: <SEX> F <CHIEF COMPLAINT> RUQ pain, nausea, vomiting\n",
    "    Context: Problems: [Acute cholecystitis, Obesity], Treatments: [Open cholecystectomy]\n",
    "    Output: Patient underwent cholecystectomy for acute cholecystitis and obesity.\n",
    "\n",
    "    ### Example 2 ###\n",
    "    Input: <SEX> M <CHIEF COMPLAINT> Severe chest pain, left arm pain\n",
    "    Context: Problems: [Myocardial infarction], Treatments: [PCI, Antiplatelet therapy]\n",
    "    Output: Patient had a myocardial infarction treated with PCI and therapy.\n",
    "\n",
    "    ### Example 3 ###\n",
    "    Input: <SEX> F <CHIEF COMPLAINT> Frequent urination, excessive thirst\n",
    "    Context: Problems: [Type 2 diabetes], Treatments: [Insulin therapy]\n",
    "    Output: Patient diagnosed with diabetes and started on insulin therapy.\n",
    "\n",
    "    ### Task ###\n",
    "    Summarize the following patient note concisely and professionally:\n",
    "    Input: {reduced_text}\n",
    "    Context: Problems: {context['Problems']}, Treatments: {context['Treatments']}, Tests: {context['Tests']}\n",
    "    Output:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Function to parse generated summaries\n",
    "def parse_summary_output(output):\n",
    "    if isinstance(output, dict) and \"generated_text\" in output:\n",
    "        return output[\"generated_text\"].split(\"Output:\")[-1].strip()\n",
    "    elif isinstance(output, str):\n",
    "        return output.split(\"Output:\")[-1].strip()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "print(\"Helper functions defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "219b4773-1bdb-4fb6-91cd-da5d328a4f06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Function to retrieve context from KG with limits\n",
    "def retrieve_context(patient_id, neo4j_graph, limit=2):\n",
    "    query = f\"\"\"\n",
    "    MATCH (p:Patient {{id: '{patient_id}'}})-[r]-(n)\n",
    "    WHERE type(r) IN ['HAS_PROBLEM', 'UNDERWENT_TEST', 'WAS_TREATED_WITH']\n",
    "    RETURN n.title AS node, type(r) AS relationship_type\n",
    "    \"\"\"\n",
    "    results = neo4j_graph.query(query)\n",
    "    context = {\"Problems\": [], \"Treatments\": [], \"Tests\": []}\n",
    "    counts = {\"HAS_PROBLEM\": 0, \"WAS_TREATED_WITH\": 0, \"UNDERWENT_TEST\": 0}  # Initialize counts\n",
    "\n",
    "    for record in results:\n",
    "        relationship_type = record[\"relationship_type\"]\n",
    "        node = record[\"node\"]\n",
    "\n",
    "        # Check limits for each category and append if within limit\n",
    "        if relationship_type == \"HAS_PROBLEM\" and counts[\"HAS_PROBLEM\"] < limit:\n",
    "            context[\"Problems\"].append(node)\n",
    "            counts[\"HAS_PROBLEM\"] += 1\n",
    "        elif relationship_type == \"WAS_TREATED_WITH\" and counts[\"WAS_TREATED_WITH\"] < limit:\n",
    "            context[\"Treatments\"].append(node)\n",
    "            counts[\"WAS_TREATED_WITH\"] += 1\n",
    "        elif relationship_type == \"UNDERWENT_TEST\" and counts[\"UNDERWENT_TEST\"] < limit:\n",
    "            context[\"Tests\"].append(node)\n",
    "            counts[\"UNDERWENT_TEST\"] += 1\n",
    "\n",
    "        # Break early if all categories reach their limits\n",
    "        if all(count == limit for count in counts.values()):\n",
    "            break\n",
    "\n",
    "    return context\n",
    "\n",
    "def construct_few_shot_prompt(reduced_text, context):\n",
    "    prompt = f\"\"\"\n",
    "    ### Task ###\n",
    "    You are the top of the world EXPERT AT WRITING CLINICAL SUMMARY. Summarize the input text in a very cohesive manner using only the information provided in the Input.\n",
    "    - Use a clear, organized structure.\n",
    "    - Do not infer anything from the prompt.\n",
    "    - Summarize in a narrative storytelling tone.\n",
    "    - Focus on readability.\n",
    "    - Ensure the summary is factual, concise, and consistent with the provided data.\n",
    "\n",
    "    ### Example ###\n",
    "    Input: <SEX> F <SERVICE> SURGERY <CHIEF COMPLAINT> RUQ pain, nausea, vomiting <HISTORY OF PRESENT ILLNESS> Patient with obesity and hypertension presented with right upper quadrant pain, nausea, and vomiting. Pain started 9 hours prior to admission after consuming a cheeseburger. Pain was constant and band-like, without radiation. No recent stool changes.\n",
    "    Context: Problems: [Acute cholecystitis, Obesity, Hypertension], Treatments: [Open cholecystectomy, Pain management]\n",
    "    Generated Summary:\n",
    "    The patient, a middle-aged woman with a history of obesity and hypertension, presented with right upper quadrant pain, nausea, and vomiting. Imaging confirmed acute cholecystitis. She underwent an open cholecystectomy and was managed postoperatively with IV fluids, JP drain placement, and antibiotics. Her recovery progressed well, and she transitioned to a regular diet. She was discharged with stable vitals, wound care instructions, and a prescription for pain management.\n",
    "\n",
    "    ### Task ###\n",
    "    Summarize the following patient note concisely and professionally in a clear and organized manner:\n",
    "    Input: {reduced_text}\n",
    "    Context: Problems: {context['Problems']}, Treatments: {context['Treatments']}, Tests: {context['Tests']}\n",
    "    Generated Summary:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Function to parse generated summaries\n",
    "def parse_summary_output(output):\n",
    "    if isinstance(output, dict) and \"generated_text\" in output:\n",
    "        return output[\"generated_text\"].split(\"Output:\")[-1].strip()\n",
    "    elif isinstance(output, str):\n",
    "        return output.split(\"Output:\")[-1].strip()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "print(\"Helper functions defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976e9a99-b296-4d66-877e-9ce8097e9857",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Summarizing Notes:   0%|          | 0/100 [00:38<?, ?notes/s]\u001b[A\n",
      "\n",
      "Summarizing Notes:   8%|▊         | 8/100 [00:53<10:19,  6.73s/notes]\u001b[A\n",
      "Summarizing Notes:  16%|█▌        | 16/100 [01:47<09:26,  6.74s/notes]\u001b[A\n",
      "Summarizing Notes:  24%|██▍       | 24/100 [02:41<08:32,  6.75s/notes]\u001b[A\n",
      "Summarizing Notes:  32%|███▏      | 32/100 [03:35<07:37,  6.73s/notes]\u001b[A\n",
      "Summarizing Notes:  40%|████      | 40/100 [04:29<06:43,  6.73s/notes]\u001b[A\n",
      "Summarizing Notes:  48%|████▊     | 48/100 [05:22<05:48,  6.71s/notes]\u001b[A\n",
      "Summarizing Notes:  56%|█████▌    | 56/100 [06:16<04:55,  6.71s/notes]\u001b[A\n",
      "Summarizing Notes:  64%|██████▍   | 64/100 [07:08<03:58,  6.63s/notes]\u001b[A\n",
      "Summarizing Notes:  72%|███████▏  | 72/100 [08:00<03:04,  6.59s/notes]\u001b[AYou seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "\n",
      "Summarizing Notes:  80%|████████  | 80/100 [08:52<02:11,  6.56s/notes]\u001b[A\n",
      "Summarizing Notes:  88%|████████▊ | 88/100 [09:43<01:18,  6.53s/notes]\u001b[A"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Load your merged_df here if not already loaded\n",
    "# merged_df = pd.read_csv(\"path_to_merged_data.csv\")\n",
    "\n",
    "batch_size = 8  # Adjust based on memory availability\n",
    "generated_summaries = []\n",
    "\n",
    "# Initialize the main progress bar\n",
    "main_progress = tqdm(total=len(merged_df), desc=\"Summarizing Notes\", unit=\"notes\")\n",
    "\n",
    "# Batch processing\n",
    "for i in range(0, len(merged_df), batch_size):\n",
    "    batch = merged_df.iloc[i:i+batch_size]\n",
    "    prompts = []\n",
    "\n",
    "    # Construct prompts with retrieved context\n",
    "    for _, row in batch.iterrows():\n",
    "        patient_id = row[\"note_id\"]\n",
    "        reduced_text = row[\"reduced_text\"]\n",
    "        \n",
    "        # Retrieve context from KG\n",
    "        context = retrieve_context(patient_id, neo4j_graph)\n",
    "        \n",
    "        # Construct the few-shot prompt\n",
    "        prompt = construct_few_shot_prompt(reduced_text, context)\n",
    "        prompts.append(prompt)\n",
    "\n",
    "    try:\n",
    "        # Generate summaries\n",
    "        summaries = summarizer(prompts, **generation_params)\n",
    "        \n",
    "        # Parse and store summaries\n",
    "        for summary in summaries:\n",
    "            generated_summaries.append(parse_summary_output(summary[0]))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch starting at index {i}: {e}\")\n",
    "        generated_summaries.extend([\"\"] * len(prompts))  # Add empty summaries in case of failure\n",
    "\n",
    "    # Update the progress bar by the batch size\n",
    "    main_progress.update(len(batch))\n",
    "\n",
    "# Close the progress bar\n",
    "main_progress.close()\n",
    "\n",
    "# Add summaries to the DataFrame\n",
    "merged_df[\"generated_summary\"] = generated_summaries\n",
    "\n",
    "print(\"Summarization complete. Sample output:\")\n",
    "print(merged_df[[\"reduced_text\", \"generated_summary\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbaceb1-453a-4036-a42d-74b0e61bfd56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d03e4-23a3-4947-a7dc-506b71d6814f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4d337-1ec3-4d1b-8921-0f0afbd63e70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262110f1-859e-419c-84c2-d8fe70c23dc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3e3ae2-db63-46f9-b1c9-c02ce4e93000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507af467-c9a6-49fb-818f-131c419cd3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aa90cc-47c5-44c8-b7ef-c61f29f5837d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45035ea7-fb0d-4713-b03b-0c9be08fc495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd935c76-f95f-4006-974d-8d2c36365069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f01dda-67f0-4ec3-985d-54ec15bb52c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163c6196-bf72-4148-8056-c59c1a852c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976109b-eed1-419f-a833-5154040e3a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7261588c-58b6-48ac-8155-04cedb4d4075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b24c703-37d9-47fd-8bc9-93c478fe713a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a94d2f7a-a8a3-400d-89b3-4cf999020ad0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "# Function to retrieve context from KG\n",
    "def retrieve_context(patient_id, neo4j_graph):\n",
    "    query = f\"\"\"\n",
    "    MATCH (p:Patient {{id: '{patient_id}'}})-[r]-(n)\n",
    "    WHERE type(r) IN ['HAS_PROBLEM', 'UNDERWENT_TEST', 'WAS_TREATED_WITH']\n",
    "    RETURN n.title AS node, type(r) AS relationship_type\n",
    "    \"\"\"\n",
    "    results = neo4j_graph.query(query)\n",
    "    context = {\"Problems\": [], \"Treatments\": [], \"Tests\": []}\n",
    "    for record in results:\n",
    "        if record[\"relationship_type\"] == \"HAS_PROBLEM\":\n",
    "            context[\"Problems\"].append(record[\"node\"])\n",
    "        elif record[\"relationship_type\"] == \"WAS_TREATED_WITH\":\n",
    "            context[\"Treatments\"].append(record[\"node\"])\n",
    "        elif record[\"relationship_type\"] == \"UNDERWENT_TEST\":\n",
    "            context[\"Tests\"].append(record[\"node\"])\n",
    "    return context\n",
    "\n",
    "def construct_few_shot_prompt(reduced_text, context):\n",
    "    prompt = f\"\"\"\n",
    "    ### Task ###\n",
    "    You are a highly knowledgeable medical expert working at NIH. Your task is to summarize clinical notes concisely and professionally using only the information provided in the Input and Context. \n",
    "    - Do not include details or assumptions not explicitly mentioned.\n",
    "    - Do not add, infer, or guess any additional information.\n",
    "    - Ensure the summary is factual and consistent with the provided data.\n",
    "\n",
    "    ### Example 1 ###\n",
    "    Input: <SEX> F <SERVICE> SURGERY <ALLERGIES> Patient recorded as having No Known Allergies to Drugs <ATTENDING> ___ <CHIEF COMPLAINT> ___ presents with RUQ pain, nausea, vomiting <MAJOR SURGICAL OR INVASIVE PROCEDURE> Open Cholecystectomy <HISTORY OF PRESENT ILLNESS> ___ with obesity, HTN, presented with RUQ pain, nausea and vomiting. Pain started 9 hours prior to presentation in the ED, after eating a cheeseburger and fries. Pain described as bandlike across RUQ without radiation. Pain is constant, not colicky. No recent stool changes <PAST MEDICAL HISTORY> OSA HTN Carpal Tunnel syndrome no prior abdominal surgery multiple burn surgeries at age ___ <SOCIAL HISTORY> ___ <FAMILY HISTORY> non contributory <PHYSICAL EXAM> On admission to the ED T 98.1 HR 90 BP 133/68 RR 18 94% RA Gen- NAD, comfortable; multiple facial scars ___: RRR Pulm: CTA b/l Abd: ND, +BS, soft, tender RUQ w/o rebound or guarding Multiple abdominal scars, equivocal ___. At Discharge: Vitals: T 98.8 HR 68 BP 132/80 RR 16 96% RA Gen- NAD, comfortable; multiple facial scars ___: RRR Pulm: CTA b/l Abd: ND, +BS, soft, appropriately tender RUQ along midline incision Multiple abdominal scars Incision: OTA with sutures. 5 selected sutures removed. Distal incision open 3cm long by 1cm wide, superficial, wound bed clean, pink well perfused tissue. packed with saline gauze w/ DSD secured w/ paper tape Extrem: no c/c/e <PERTINENT RESULTS> ___ 07: 35AM BLOOD WBC-12.6* RBC-3.57* Hgb-10.2* Hct-31.0* MCV-87 MCH-28.5 MCHC-32.8 RDW-13.1 Plt ___ ___ 04: 02AM BLOOD WBC-12.4* RBC-4.25 Hgb-12.2 Hct-36.4 MCV-86 MCH-28.7 MCHC-33.5 RDW-13.5 Plt ___ ___ 04: 02AM BLOOD Neuts-86.7* Bands-0 Lymphs-10.3* Monos-2.6 Eos-0.1 Baso-0.4 ___ 04: 02AM BLOOD ___ ___ 07: 35AM BLOOD Glucose-114* UreaN-10 Creat-0.9 Na-139 K-3.8 Cl-105 HCO3-29 AnGap-9 ___ 04: 02AM BLOOD Glucose-131* UreaN-21* Creat-1.0 Na-139 K-4.3 Cl-105 HCO3-25 AnGap-13 ___ 07: 15AM BLOOD ALT-42* AST-33 AlkPhos-66 Amylase-72 TotBili-0.4 ___ 10: 00AM BLOOD ALT-53* AST-24 AlkPhos-69 Amylase-88 TotBili-0.4 ___ 04: 02AM BLOOD ALT-59* AST-90* AlkPhos-85 TotBili-0.6 ___ 07: 15AM BLOOD Lipase-76* ___ 10: 00AM BLOOD Lipase-79* ___ 04: 02AM BLOOD Lipase-38 ___ 07: 35AM BLOOD Calcium-8.0* Phos-2.2* Mg-1.8 ___ 04: 02AM BLOOD Albumin-4.4 Calcium-9.1 Phos-3.4 Mg-2.1. RADIOLOGY Final Report LIVER OR GALLBLADDER US (SINGLE ORGAN) ___ 6: 39 AM REASON FOR THIS EXAMINATION: eval CBD; r/o cholecystitis HISTORY: ___ female with right upper quadrant tenderness to palpation and known cholelithiasis. Please evaluate for cholecystitis. IMPRESSION: 1. Cholelithiasis with gallbladder distention and wall thickening. These findings are suggestive of cholecystitis. Clinical correlation as well as HIDA scan for further evaluation are recommended. 2. Diffusely echogenic liver consistent with fatty infiltration. However, more advanced forms of liver disease, including significant fibrosis and cirrhosis, may also have this appearance.. Pathology Examination Procedure date ___ DIAGNOSIS: Gallbladder: 1. Acute and chronic cholecystitis. 2. Cholelithiasis, mixed-type. 3. One unremarkable lymph node. Clinical: Cholelithiasis. <MEDICATIONS ON ADMISSION> Lexapro 40mg qd Atenolol 25mg qd <DISCHARGE MEDICATIONS> 1. Escitalopram 10 mg Tablet Sig: Four (4) Tablet PO DAILY\n",
    "    Context: Problems: [Acute cholecystitis, Obesity, Hypertension], Treatments: [Open cholecystectomy, Pain management]\n",
    "    Output: The patient was admitted to the surgical service. She underwent an open cholecystectomy. Postoperatively, she was monitored on the surgical floor with JP drain placement, hydration via IV fluids, and antibiotic therapy. Her condition improved, and she was advanced to a regular diet. JP drain and sutures were removed before discharge. The patient was discharged with stable vitals, wound care instructions, and a prescription for pain control.\n",
    "\n",
    "    ### Task ###\n",
    "    Summarize the following patient note concisely and professionally:\n",
    "    Input: {reduced_text}\n",
    "    Context: Problems: {context['Problems']}, Treatments: {context['Treatments']}, Tests: {context['Tests']}\n",
    "    Output:\n",
    "    \"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Function to parse generated summaries\n",
    "def parse_summary_output(output):\n",
    "    if isinstance(output, dict) and \"generated_text\" in output:\n",
    "        return output[\"generated_text\"].split(\"Output:\")[-1].strip()\n",
    "    elif isinstance(output, str):\n",
    "        return output.split(\"Output:\")[-1].strip()\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "print(\"Helper functions defined.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72758a5-b7fa-4627-9a64-d26844a07eff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Load your merged_df here if not already loaded\n",
    "# merged_df = pd.read_csv(\"path_to_merged_data.csv\")\n",
    "\n",
    "batch_size = 2  # Adjust based on memory availability\n",
    "generated_summaries = []\n",
    "\n",
    "# Initialize the main progress bar\n",
    "main_progress = tqdm(total=len(merged_df), desc=\"Summarizing Notes\", unit=\"notes\")\n",
    "\n",
    "# Batch processing\n",
    "for i in range(0, len(merged_df), batch_size):\n",
    "    batch = merged_df.iloc[i:i+batch_size]\n",
    "    prompts = []\n",
    "\n",
    "    # Construct prompts with retrieved context\n",
    "    for _, row in batch.iterrows():\n",
    "        patient_id = row[\"note_id\"]\n",
    "        reduced_text = row[\"reduced_text\"]\n",
    "        \n",
    "        # Retrieve context from KG\n",
    "        context = retrieve_context(patient_id, neo4j_graph)\n",
    "        \n",
    "        # Construct the few-shot prompt\n",
    "        prompt = construct_few_shot_prompt(reduced_text, context)\n",
    "        prompts.append(prompt)\n",
    "\n",
    "    try:\n",
    "        # Generate summaries\n",
    "        summaries = summarizer(prompts, **generation_params)\n",
    "        \n",
    "        # Parse and store summaries\n",
    "        for summary in summaries:\n",
    "            generated_summaries.append(parse_summary_output(summary[0]))\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch starting at index {i}: {e}\")\n",
    "        generated_summaries.extend([\"\"] * len(prompts))  # Add empty summaries in case of failure\n",
    "\n",
    "    # Update the progress bar by the batch size\n",
    "    main_progress.update(len(batch))\n",
    "\n",
    "# Close the progress bar\n",
    "main_progress.close()\n",
    "\n",
    "# Add summaries to the DataFrame\n",
    "merged_df[\"generated_summary\"] = generated_summaries\n",
    "\n",
    "print(\"Summarization complete. Sample output:\")\n",
    "print(merged_df[[\"reduced_text\", \"generated_summary\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9eefc3a-ed80-4d49-b5a5-184cef95ccea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><SEX> F <SERVICE> MEDICINE <ALLERGIES> No Known Allergies / Adverse Drug Reactions <ATTENDING> ___. <CHIEF COMPLAINT> Lower extremity edema <MAJOR SURGICAL OR INVASIVE PROCEDURE> None <HISTORY OF PRESENT ILLNESS> ___ year-old woman with PMH of CAD, dementia, endometrial ca s/p hysterectomy ___ present with b/l ___ edema and erythema x 1 week. Patient was asymptomatic, ambulating well with no fevers or complaints of pain. She has not been maintained on any blood thinners, including ASA. Denies any chest pain, palpitations, SOB, cough, dysuria or other complaint. In ED, initial VS: T 98.2 BP 154/69 HR 78 RR 20 SaO2 96% RA. Labs significant for sterile pyuria (WBC 29), stable Hct 32.1 and elevated BNP > 1000 from unknown baseline. EKG with new twi in 1, avL and QTc prolongation 494.6. CXR showed possible RUL opacity, ___ dopplers negative for DVT. She was given levaquin and all home medications including seroquel. Admitted to medicine for further evaluation. ROS: Denies fever, chills, night sweats, headache, vision changes, rhinorrhea, congestion, sore throat, cough, shortness of breath, chest pain, abdominal pain, nausea, vomiting, diarrhea, constipation, BRBPR, melena, hematochezia, dysuria, hematuria. <PAST MEDICAL HISTORY> - Hypertension - CAD s/p MI, Last stress in ___ and per Dr. ___ she did not have any evid of ischemia with stress. - Hyperlipidemia - COPD/emphysema - Depression/ anxiety - Dementia- alzheimer's - CRI (baseline 1.1-1.5, most recently 1.5) - Arthritis - Anemia - Diverticulosis Past Surgical History - Laparotomy for ectopic pregnancy - R inguinal hernia repair - Polypectomy Ob/Gyn History - Spontaneous vaginal delivery x 1 - Ectopic pregnancy x 1 (laparotomy) - Denies abnormal Paps, most recent ___ wnl - Denies h/o pelvic infections - H/o endometrial polyps <SOCIAL HISTORY> ___ <FAMILY HISTORY> Non-contributory. <PHYSICAL EXAM> Exam on admission: PHYSICAL EXAM: VS: T96.5 BP 120/76 P 70 RR 22 SaO2 95% RA GENERAL: appears younger than stated age, NAD HEENT: EOMI, PERRL, MMM NECK: JVP at 10cm HEART: RRR, grade II/VI systolic murmur LUNGS: CTA bilat, no r/rh/wh, good air movement, resp unlabored. ABDOMEN: Soft/NT/ND, incisions c/d/i EXTREMITIES: 2+ b/l edema, induration and warmth to mid-calf; +2 DP NEURO: Awake, A&Ox2 (not fully to date), CNs II-XII grossly intact, moving all extremities At discharge: Objective: V/S T98 BP ___ RR22 94% RA 540 in 420 out BRx2 Examination: HEENT: EOMI, PERRL, MMM NECK: JVP at 10cm HEART: RRR, grade II/VI systolic murmur LUNGS: CTA bilat, no r/rh/wh, good air movement, resp unlabored. ABDOMEN: Soft/NT/ND, incisions c/d/i EXTREMITIES: Lower extremities edematous to knee bilaterally; non-pitting; edema is improved, pt has on ___ stockings. NEURO: Awake, A&Ox2 (not fully to date), CNs II-XII grossly intact, moving all extremities <PERTINENT RESULTS> ___ 06: 00PM WBC-4.4 RBC-3.52* HGB-10.3* HCT-32.1* MCV-91 MCH-29.1 MCHC-31.9 RDW-15.1 ___ 06: 00PM ALBUMIN-4.0 CALCIUM-9.2 PHOSPHATE-3.6 MAGNESIUM-2.4 ___ 06: 00PM CK-MB-2 cTropnT-0.02* proBNP-1827* ___ 06: 00PM GLUCOSE-89 UREA N-21* CREAT-1.1 SODIUM-144 POTASSIUM-5.1 CHLORIDE-110* TOTAL CO2-25 ANION GAP-14 ___ 06: 05AM BLOOD WBC-5.0 RBC-3.39* Hgb-9.8* Hct-31.4* MCV-93 MCH-29.0 MCHC-31.3 RDW-15.0 Plt ___ ___ 06: 05AM BLOOD Glucose-100 UreaN-23* Creat-1.5* Na-143 K-4.1 Cl-108 HCO3-25 AnGap-14 ___ 06: 05AM BLOOD CK(CPK)-28* TTE: ___ The left atrium is mildly dilated. No atrial septal defect is seen by 2D or color Doppler. Left ventricular wall thickness, cavity size and regional/global systolic function are normal (LVEF >55%). There is no ventricular septal defect. Right ventricular chamber size and free wall motion are normal. The diameters of aorta at the sinus, ascending and arch levels are normal. The aortic valve leaflets (3) are mildly thickened but aortic stenosis is not present. Trace aortic regurgitation is seen. The mitral valve leaflets are mildly thickened. There is no mitral valve prolapse. Mild (1+) mitral regurgitation is seen. The left ventricular inflow pattern suggests impaired relaxation. The tricuspid valve leaflets are mildly thickened. Tricuspid regurgitation is present but cannot be quantified. There is mild pulmonary artery systolic hypertension. There is a trivial/physiologic pericardial effusion. <MEDICATIONS ON ADMISSION> - acetaminophen 325 mg 2 tabs prn pain - tramadol 50 mg Tablet\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['reduced_text'].iloc[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c04a9fb9-0da5-458d-961c-b958a47e5dca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**Patient Summary:** This patient presents with acute onset of left-leg weakness, blurred vision, decreased consciousness, and dizziness. Initial evaluation reveals mild hypotension (<60 mm Hg); normal heart rate (>100 beats per minute); respiratory distress; slight nasal discharge; bilateral ophthalmoplegia; bradycardiac rhythm; low serum lactate dehydrogenase levels (-30 IU/L); mildly elevated creatinine level (+10 mg/dL).\\n    \\n### Answer Explanation\\n\\nThe above output summarizes the key points about the case:\\n\\n*   Age: Male, age-related hypertension, obesity, hypercholesterolemia, osteoporosis, psoriasis, atrial fibrillation, peripheral vascular diseases, previous myocardial infarction, diabetes mellitus type II, rheumatoid arthritis, chronic obstructive pulmonary disease (COPD)\\n*   Chief complaint: Acute-onset left-leg weakness, visual disturbances, altered mental state, and transient ischemic attack-like episode\\n*   Symptoms: Decreased motor function, impaired cognitive functions such as attention deficit disorder, aphasia, slurred tongue movements, diplopia, syncope, fainting spells, orthostatic intolerance, postural instability, poor coordination, sensory changes like paresthesiae, taste alterations, dry skin rash, feverish sensations around eyes, painless swelling of eyelashes, etc., which may indicate systemic involvement beyond just neurological issues\\n\\n\\n**Key Points**\\n\\n| Key Point | Description |\\n| :'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['generated_summary'].iloc[79]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e818c12c-7f23-499c-a816-62bb3139da9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summaries saved to summarized_notes.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the dataframe to a CSV file\n",
    "output_file = \"summarized_notes.csv\"\n",
    "merged_df.to_csv(output_file, index=False)\n",
    "print(f\"Summaries saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e22802-a29d-432a-af1c-bb4dd25a0353",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
