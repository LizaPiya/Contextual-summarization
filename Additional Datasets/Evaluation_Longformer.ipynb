{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5639ff5d-867d-4563-9858-be35b5dc13d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (3.9.1)\n",
      "Requirement already satisfied: bert-score in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (0.3.13)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bert-score) (2.2.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bert-score) (4.51.2)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bert-score) (3.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bert-score) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.9->bert-score) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2025.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2025.2.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.30.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.5.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (11.1.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->bert-score) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->bert-score) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->bert-score) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Requirement already satisfied: rouge-metric in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk bert-score\n",
    "!pip install rouge-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c204078-9af1-4962-bf4d-0e655f607c06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  \\\n",
      "0  Good afternoon, champ, how you holding up? Goo...   \n",
      "1  What brings you in here today? Hi, I'm um, I'm...   \n",
      "\n",
      "                                              output  \\\n",
      "0  Subjective:\\n- Symptoms: Lower back pain, radi...   \n",
      "1  Subjective:\\n- Presenting with dry cough for 1...   \n",
      "\n",
      "                                   generated_summary  \n",
      "0  A 75-year-old man is experiencing chronic lowe...  \n",
      "1  , but after that it seemed to clear up a bit. ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the saved CSV file\n",
    "longformer_generated_summaries = pd.read_csv(\"Longformer_soap_generated_summaries.csv\")\n",
    "\n",
    "# Verify the data\n",
    "print(longformer_generated_summaries.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1ded385-c124-47c6-a065-cd704f918a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning, young lady, how old are you? Good morning, doctor. I'm thirteen. Good, and what seems to be the problem today? Mom, can you explain for me? Guest_family: Well, if you look, doctor, her back posture is very rounded. I think, it's rounding about the thoracic spine. Is there a family history of this problem? Guest_family: Yes, on my side, my aunt and grandfather had, um, kyphosis. Yes, that's what this is. This is thoracic kyphosis to be specific. Has she seen another doctor for this? Guest_family: Yes, we saw another orthopedist. What did they recommend? Guest_family: They recommended we come in for further observation, so we're here for a second opinion. Good, is there any back pain, numbness or tingling? No, I don't have any of that. Is there any weakness, numbness or tingling in your legs and arms, my dear? No, I'm very strong, especially for my age. Are you going to the bathroom with no problem? Yes, doctor, everything is regular there.\n"
     ]
    }
   ],
   "source": [
    "print(longformer_generated_summaries['input'].iloc[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a43f60d0-45a7-49c0-969d-7208d6ba5fdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 13-year-old girl comes to see her mother's doctor because she is concerned about her back\n"
     ]
    }
   ],
   "source": [
    "print(longformer_generated_summaries['generated_summary'].iloc[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25838670-c517-44a6-81c0-15f5283ad61c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing BLEU and ROUGE-L scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|██████████| 100/100 [00:00<00:00, 578.92row/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing BERTScore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics (in percentages):\n",
      "Average BLEU-1: 2.1845065608225953 %\n",
      "Average BLEU-2: 1.1891421036571728 %\n",
      "Average ROUGE-L: 6.762804383330671 %\n",
      "Average BERT P: 85.6003046631813 %\n",
      "Average BERT R: 79.89022243022919 %\n",
      "Average BERT F1: 82.63759052753448 %\n",
      "\n",
      "Standard Deviations (in percentages):\n",
      "BLEU-1 Std: 3.6347510655731963 %\n",
      "BLEU-2 Std: 2.562401702906771 %\n",
      "ROUGE-L Std: 5.85447961411285 %\n",
      "BERT F1 Std: 2.877933082281974 %\n",
      "BERT P Std: 2.944374474744506 %\n",
      "BERT R Std: 3.044152994052751 %\n",
      "\n",
      "Results saved to 'longformer_evaluation_results.csv'\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from bert_score import score\n",
    "from rouge_metric import PyRouge\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and normalize text.\"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return ' '.join(text.strip().lower().split())  # Lowercase, strip spaces, normalize.\n",
    "\n",
    "def compute_bleu_scores(reference, candidate):\n",
    "    \"\"\"Compute BLEU-1 and BLEU-2 scores.\"\"\"\n",
    "    try:\n",
    "        smoothing_function = SmoothingFunction().method1\n",
    "        # Compute BLEU-1\n",
    "        bleu1 = sentence_bleu(\n",
    "            [reference.split()],\n",
    "            candidate.split(),\n",
    "            weights=(1.0, 0, 0, 0),  # Only unigrams\n",
    "            smoothing_function=smoothing_function\n",
    "        )\n",
    "        # Compute BLEU-2\n",
    "        bleu2 = sentence_bleu(\n",
    "            [reference.split()],\n",
    "            candidate.split(),\n",
    "            weights=(0.5, 0.5, 0, 0),  # Unigrams and bigrams only\n",
    "            smoothing_function=smoothing_function\n",
    "        )\n",
    "        return bleu1 * 100, bleu2 * 100  # Convert to percentages\n",
    "    except Exception as e:\n",
    "        print(f\"BLEU Error: {e}\")\n",
    "        print(f\"Reference: '{reference[:50]}...'\")\n",
    "        print(f\"Candidate: '{candidate[:50]}...'\")\n",
    "        return 0.0, 0.0\n",
    "\n",
    "def compute_rouge_l(reference, candidate):\n",
    "    \"\"\"Compute ROUGE-L score.\"\"\"\n",
    "    rouge = PyRouge(rouge_n=(1, 2), rouge_l=True, rouge_w=False,\n",
    "                    rouge_w_weight=1.2, rouge_s=False, rouge_su=False, skip_gap=4)\n",
    "    try:\n",
    "        scores = rouge.evaluate([candidate], [[reference]])\n",
    "        return scores['rouge-l']['f'] * 100  # Convert to percentage\n",
    "    except Exception as e:\n",
    "        print(f\"ROUGE-L Error: {e}\")\n",
    "        print(f\"Reference: '{reference[:50]}...'\")\n",
    "        print(f\"Candidate: '{candidate[:50]}...'\")\n",
    "        return 0.0\n",
    "\n",
    "def compute_bert_score_batched(references, candidates, batch_size=32):\n",
    "    \"\"\"Compute BERTScore in batches.\"\"\"\n",
    "    all_P, all_R, all_F1 = [], [], []\n",
    "    for i in range(0, len(references), batch_size):\n",
    "        batch_refs = references[i:i + batch_size]\n",
    "        batch_cands = candidates[i:i + batch_size]\n",
    "        try:\n",
    "            P, R, F1 = score(batch_cands, batch_refs, lang=\"en\", verbose=False)\n",
    "            all_P.extend([p * 100 for p in P.tolist()])  # Convert to percentages\n",
    "            all_R.extend([r * 100 for r in R.tolist()])  # Convert to percentages\n",
    "            all_F1.extend([f * 100 for f in F1.tolist()])  # Convert to percentages\n",
    "        except Exception as e:\n",
    "            print(f\"BERTScore Error in batch {i}: {e}\")\n",
    "            batch_len = len(batch_refs)\n",
    "            all_P.extend([0.0] * batch_len)\n",
    "            all_R.extend([0.0] * batch_len)\n",
    "            all_F1.extend([0.0] * batch_len)\n",
    "    return all_P, all_R, all_F1\n",
    "\n",
    "def evaluate_summaries(df):\n",
    "    bleu1_scores, bleu2_scores, rouge_l_scores = [], [], []\n",
    "    print(\"Computing BLEU and ROUGE-L scores...\")\n",
    "    \n",
    "    with tqdm(total=len(df), desc=\"Processing Rows\", unit=\"row\") as pbar:\n",
    "        for _, row in df.iterrows():\n",
    "            reference = clean_text(row['output'])\n",
    "            candidate = clean_text(row['generated_summary'])  # Updated field name\n",
    "            \n",
    "            if not reference or not candidate:\n",
    "                print(f\"Empty text - Reference: '{reference}', Candidate: '{candidate}'\")\n",
    "                bleu1_scores.append(0.0)\n",
    "                bleu2_scores.append(0.0)\n",
    "                rouge_l_scores.append(0.0)\n",
    "            else:\n",
    "                bleu1, bleu2 = compute_bleu_scores(reference, candidate)\n",
    "                bleu1_scores.append(bleu1)\n",
    "                bleu2_scores.append(bleu2)\n",
    "                rouge_l_scores.append(compute_rouge_l(reference, candidate))\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    print(\"\\nComputing BERTScore...\")\n",
    "    references = [clean_text(text) for text in df['output'].tolist()]\n",
    "    candidates = [clean_text(text) for text in df['generated_summary'].tolist()]\n",
    "    bert_p, bert_r, bert_f1 = compute_bert_score_batched(references, candidates)\n",
    "    \n",
    "    # Add all scores to DataFrame\n",
    "    df['bleu1'] = bleu1_scores\n",
    "    df['bleu2'] = bleu2_scores\n",
    "    df['rouge_l'] = rouge_l_scores\n",
    "    df['bert_p'] = bert_p\n",
    "    df['bert_r'] = bert_r\n",
    "    df['bert_f1'] = bert_f1\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(\"\\nEvaluation Metrics (in percentages):\")\n",
    "    print(\"Average BLEU-1:\", df['bleu1'].mean(), \"%\")\n",
    "    print(\"Average BLEU-2:\", df['bleu2'].mean(), \"%\")\n",
    "    print(\"Average ROUGE-L:\", df['rouge_l'].mean(), \"%\")\n",
    "    print(\"Average BERT P:\", df['bert_p'].mean(), \"%\")\n",
    "    print(\"Average BERT R:\", df['bert_r'].mean(), \"%\")\n",
    "    print(\"Average BERT F1:\", df['bert_f1'].mean(), \"%\")\n",
    "    \n",
    "    # Print standard deviations\n",
    "    print(\"\\nStandard Deviations (in percentages):\")\n",
    "    print(\"BLEU-1 Std:\", df['bleu1'].std(), \"%\")\n",
    "    print(\"BLEU-2 Std:\", df['bleu2'].std(), \"%\")\n",
    "    print(\"ROUGE-L Std:\", df['rouge_l'].std(), \"%\")\n",
    "    print(\"BERT F1 Std:\", df['bert_f1'].std(), \"%\")\n",
    "    print(\"BERT P Std:\", df['bert_p'].std(), \"%\")\n",
    "    print(\"BERT R Std:\", df['bert_r'].std(), \"%\")\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "# Updated DataFrame Name\n",
    "longformer_generated_summaries = evaluate_summaries(longformer_generated_summaries)\n",
    "longformer_generated_summaries.to_csv(\"longformer_evaluation_results.csv\", index=False)\n",
    "print(\"\\nResults saved to 'longformer_evaluation_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d31551-fe04-47d2-88ec-022f455fee99",
   "metadata": {},
   "source": [
    "### LLM as a judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "334bb0a1-70ba-46ae-a244-ae0d9f8d5466",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Use your Hugging Face token\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f477ed60-ae19-4e18-a544-00086e9316e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (3.17.0)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading transformers-4.51.2-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 kB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m159.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.30.2 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.51.2\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: regex in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacremoses) (2024.11.6)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacremoses) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacremoses) (1.4.2)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacremoses) (4.67.1)\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sacremoses\n",
      "Successfully installed sacremoses-0.1.1\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: torch<3,>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bitsandbytes) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (6.1.1)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.2.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes) (3.1.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch<3,>=2.0->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m171.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-1.6.0-py3-none-any.whl (354 kB)\n",
      "Installing collected packages: bitsandbytes, accelerate\n",
      "Successfully installed accelerate-1.6.0 bitsandbytes-0.45.5\n"
     ]
    }
   ],
   "source": [
    "# Install Hugging Face Transformers\n",
    "!pip install transformers\n",
    "!pip install sacremoses\n",
    "!pip install bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d77b0e2b-22b6-4d99-8ea9-7ac71bacca4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [48:30<00:00, 29.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  \\\n",
      "0  Good afternoon, champ, how you holding up? Goo...   \n",
      "1  What brings you in here today? Hi, I'm um, I'm...   \n",
      "2  Do you have any known allergies to medications...   \n",
      "3  How may I help you today? Yeah I've had, a fev...   \n",
      "4  It sounds like that you're experiencing some c...   \n",
      "\n",
      "                                   generated_summary  \\\n",
      "0  A 75-year-old man is experiencing chronic lowe...   \n",
      "1  , but after that it seemed to clear up a bit. ...   \n",
      "2  The individual in question is a patient who ha...   \n",
      "3  that someone else could be infected. But, yeah...   \n",
      "4  into this further, including running some test...   \n",
      "\n",
      "                                    evaluation_gemma  \n",
      "0  You are a helpful clinical NLP evaluation assi...  \n",
      "1  You are a helpful clinical NLP evaluation assi...  \n",
      "2  You are a helpful clinical NLP evaluation assi...  \n",
      "3  You are a helpful clinical NLP evaluation assi...  \n",
      "4  You are a helpful clinical NLP evaluation assi...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# Step 1: Use 8-bit quantization for efficient inference\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_compute_dtype=torch.float16,\n",
    "    llm_int8_enable_fp32_cpu_offload=True\n",
    ")\n",
    "\n",
    "# Step 2: Load tokenizer & model (Gemma 3 1B Instruction-tuned)\n",
    "model_id = \"google/gemma-3-1b-it\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ").eval()\n",
    "\n",
    "# Step 3: Use your existing DataFrame\n",
    "df = longformer_generated_summaries\n",
    "\n",
    "# Step 4: Define the evaluation prompt\n",
    "def create_prompt(input_text, output_text, summary):\n",
    "    return f\"\"\"You are a helpful clinical NLP evaluation assistant.\n",
    "\n",
    "Input Text:\n",
    "{input_text}\n",
    "\n",
    "Reference Summary:\n",
    "{output_text}\n",
    "\n",
    "Generated Summary:\n",
    "{summary}\n",
    "\n",
    "Evaluate the generated summary using the following criteria:\n",
    "1. Does it capture the main ideas of the reference summary? (Yes/No)\n",
    "2. Is it coherent and logically structured? (Yes/No)\n",
    "3. Are there factual inaccuracies or important omissions? (List any)\n",
    "4. Rate the summary from 1 to 5 based on how well it captures the reference summary.\n",
    "\n",
    "Please give your evaluation in this format:\n",
    "- Captures main ideas: [Yes/No]\n",
    "- Coherence: [Yes/No]\n",
    "- Issues: [Write here or 'None']\n",
    "- Score: [1-5]\n",
    "\"\"\"\n",
    "\n",
    "# Step 5: Run evaluation\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    prompt = create_prompt(row['input'], row['output'], row['generated_summary'])\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024).to(model.device)\n",
    "\n",
    "    # Use max_new_tokens instead of max_length to avoid the OOM error\n",
    "    outputs = model.generate(**inputs, max_new_tokens=150)\n",
    "    eval_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    results.append(eval_response)\n",
    "\n",
    "# Step 6: Save evaluations to the DataFrame\n",
    "df['evaluation_gemma'] = results\n",
    "\n",
    "# Optional: Save to file\n",
    "df.to_csv(\"evaluated_summaries_gemma.csv\", index=False)\n",
    "print(df[['input', 'generated_summary', 'evaluation_gemma']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ce0454c-d01e-47ed-8285-add4d0344832",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful clinical NLP evaluation assistant.\n",
      "\n",
      "Input Text:\n",
      "Hi there! What brings you in today? Guest_family: I think my baby got into the ant bait. I am not sure if he consumed any of it but he was under the counter and it was in his hands. What kind ant bait did he get into? Guest_family: It was the one with Borax in it. Do you have a picture of it? Guest_family: Yes. It is in my phone.\n",
      "\n",
      "Reference Summary:\n",
      "Subjective:\n",
      "- Concern that the baby may have gotten into ant bait containing Borax.\n",
      "- Uncertainty about whether the baby consumed any of it.\n",
      "- The baby was found under the counter with the ant bait in his hands.\n",
      "\n",
      "Objective:\n",
      "- No measurable or observable data provided.\n",
      "\n",
      "Assessment:\n",
      "- No clinician's interpretation or diagnosis provided.\n",
      "\n",
      "Plan:\n",
      "- No specific actions, medications, tests, follow-up, or patient education provided.\n",
      "\n",
      "Generated Summary:\n",
      "A guest's infant son was found to be under the kitchen counter, having ingested some type of\n",
      "\n",
      "Evaluate the generated summary using the following criteria:\n",
      "1. Does it capture the main ideas of the reference summary? (Yes/No)\n",
      "2. Is it coherent and logically structured? (Yes/No)\n",
      "3. Are there factual inaccuracies or important omissions? (List any)\n",
      "4. Rate the summary from 1 to 5 based on how well it captures the reference summary.\n",
      "\n",
      "Please give your evaluation in this format:\n",
      "- Captures main ideas: [Yes/No]\n",
      "- Coherence: [Yes/No]\n",
      "- Issues: [Write here or 'None']\n",
      "- Score: [1-5]\n",
      "- Justification: [Brief explanation]\n",
      "\n",
      "Evaluation:\n",
      "- Captures main ideas: Yes\n",
      "- Coherence: Yes\n",
      "- Issues: None\n",
      "- Score: 4\n",
      "- Justification: The summary accurately reflects the main points of the reference summary.\n",
      "\n",
      "- Captures main ideas: Yes\n",
      "- Coherence: Yes\n",
      "- Issues: None\n",
      "- Score: 4\n",
      "- Justification: The summary accurately reflects the main points of the reference summary.\n",
      "\n",
      "- Captures main ideas: No\n",
      "- Coherence: No\n",
      "- Issues: None\n",
      "- Score: 1\n",
      "- Justification: The summary is not accurate in capturing the core information.\n",
      "\n",
      "- Captures main ideas: Yes\n",
      "- Coherence: No\n"
     ]
    }
   ],
   "source": [
    "print(df['evaluation_gemma'].iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b7d07-625d-48c7-82f8-afb5af673575",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
