{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ab7934d-5679-4f54-a41e-48e5f1d5898e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  \\\n",
      "0  Good afternoon, champ, how you holding up? Goo...   \n",
      "1  What brings you in here today? Hi, I'm um, I'm...   \n",
      "2  Do you have any known allergies to medications...   \n",
      "3  How may I help you today? Yeah I've had, a fev...   \n",
      "4  It sounds like that you're experiencing some c...   \n",
      "\n",
      "                                              output  \n",
      "0  Subjective:\\n- Symptoms: Lower back pain, radi...  \n",
      "1  Subjective:\\n- Presenting with dry cough for 1...  \n",
      "2  Subjective:\\n- No known allergies to medicatio...  \n",
      "3  Subjective:\\n- Fever and dry cough started 4 d...  \n",
      "4  Subjective:\\n- Presenting with chest pain for ...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   100 non-null    object\n",
      " 1   output  100 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_sample = pd.read_csv(\"sample_summary.csv\")\n",
    "# Display the first few rows\n",
    "print(df_sample.head())\n",
    "\n",
    "# Check DataFrame info\n",
    "print(df_sample.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c941fe8-d84f-4c50-b1f5-16b89a20c9a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers huggingface_hub\n",
    "!pip install -q --upgrade accelerate\n",
    "!pip install -q -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd06c02a-66b3-4a20-afb7-a8acbbcf7737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Use your Hugging Face token\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b93b604-a0b3-4308-9fb2-72cf22912eed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the BioBART model and tokenizer\n",
    "# Replace 'GanjinZero/biobart-large' with the desired BioBART model version\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GanjinZero/biobart-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"GanjinZero/biobart-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab1bea74-41c0-45a9-b577-f7d1c6cdb798",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Summaries:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:14<00:14, 14.81s/row]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Output: Good afternoon, champ, how you holding up? Good afternoon, Doctor, I have a lot of lower back pain. Oh no, before we begin, how old are you, sir and which hand do you write with? I'm seventy five now. Right. Great, so tell me, how long have you had this lower back Pain? It's been about ten days now. Have your symptoms improved at all since they began? No, they keep getting worse. Does the pain radiate into your legs? Yes, it started radiating down my right leg three days after the lower backpain began, and then the left leg three day after the right. The next day I could barely walk, the pain was so severe. Do you remember the initial date of the beginning of your low back pain? Um, it was on December third nineteen ninety five. Have you seen another doctor for this pain? Yes; I saw my local physician, um, it were on December eleventh,\n",
      "Generated Summary: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Summaries: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:32<00:00, 16.15s/row]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Output: What brings you in here today? Hi, I'm um, I're just, so I am here because I have this cough that I've had for the past um, week and a half, and I'm just uh, I usually don't come in with symptoms this minor, but because it's, because we're in the middle of a pandemic, I thought I should come in and get checked out. Okay, yeah, so it's been going on for like more than a week. Um, can you describe to me what kind of cough you're having? Is it like a wet cough or a dry cough? It's a dry coughing. Okay), and has it been getting worse over the, over the time period you described? Um, it's kind of the same. It's the same, and has you noticed, although it's like dry, have you brought up any kind of sputum or phlegm at all? Um no, not, not\n",
      "Generated Summary: \n",
      "Summaries saved to 'Biobart_soap_generated_summaries.csv'\n",
      "\n",
      "ðŸ”¹ Efficiency Metrics\n",
      "ðŸ“Œ Average Latency: 16.1475 sec (Â±1.3411)\n",
      "ðŸ“Œ Average Throughput: 42.50 tokens/sec (Â±14.68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. Load only first 2 rows\n",
    "# -----------------------------------------------------\n",
    "df_sample = df_sample.iloc[:2].copy()\n",
    "inputs_list = df_sample[\"input\"].tolist()\n",
    "batch_size = 1  # Keep it low for debugging and simplicity\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. Simplified Prompt Construction (no instruction)\n",
    "# -----------------------------------------------------\n",
    "def construct_prompt(input_text):\n",
    "    return input_text.strip()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. Generation Parameters\n",
    "# -----------------------------------------------------\n",
    "generation_params = {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.8,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_k\": 100,\n",
    "    \"max_new_tokens\": 200,\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. Inference & Efficiency Tracking\n",
    "# -----------------------------------------------------\n",
    "generated_summaries = []\n",
    "latencies = []\n",
    "throughputs = []\n",
    "\n",
    "def process_batch(batch_inputs):\n",
    "    batch_generated = []\n",
    "    total_input_tokens = 0\n",
    "\n",
    "    for text in batch_inputs:\n",
    "        prompt = construct_prompt(text)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1000)\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        prompt_length = inputs[\"input_ids\"].shape[1]\n",
    "        total_input_tokens += prompt_length\n",
    "\n",
    "        start_time = time.time()\n",
    "        summary_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            **generation_params\n",
    "        )\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Optional Debug: Print full decoded output\n",
    "        full_output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        print(\"Full Output:\", full_output)\n",
    "\n",
    "        # Extract new tokens (skip prompt)\n",
    "        generated_tokens = summary_ids[0, prompt_length:]\n",
    "        generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
    "        print(\"Generated Summary:\", generated_text)  # Debug print\n",
    "\n",
    "        batch_generated.append(generated_text)\n",
    "\n",
    "        # Metrics\n",
    "        latency = end_time - start_time\n",
    "        latencies.append(latency)\n",
    "        total_tokens = prompt_length + generated_tokens.shape[0]\n",
    "        throughputs.append(total_tokens / latency)\n",
    "\n",
    "    return batch_generated\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. Process Batches\n",
    "# -----------------------------------------------------\n",
    "with tqdm(total=len(inputs_list), desc=\"Generating Summaries\", unit=\"row\") as pbar:\n",
    "    for i in range(0, len(inputs_list), batch_size):\n",
    "        batch = inputs_list[i:i + batch_size]\n",
    "        try:\n",
    "            batch_generated = process_batch(batch)\n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e):\n",
    "                torch.cuda.empty_cache()\n",
    "                print(\"Out of memory error; try reducing batch size.\")\n",
    "            raise e\n",
    "        generated_summaries.extend(batch_generated)\n",
    "        torch.cuda.empty_cache()\n",
    "        pbar.update(len(batch))\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6. Save Results\n",
    "# -----------------------------------------------------\n",
    "df_sample[\"generated_summary\"] = generated_summaries\n",
    "df_sample.to_csv(\"Biobart_soap_generated_summaries.csv\", index=False)\n",
    "print(\"Summaries saved to 'Biobart_soap_generated_summaries.csv'\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 7. Print Efficiency Metrics\n",
    "# -----------------------------------------------------\n",
    "avg_latency = np.mean(latencies)\n",
    "std_latency = np.std(latencies)\n",
    "avg_throughput = np.mean(throughputs)\n",
    "std_throughput = np.std(throughputs)\n",
    "\n",
    "print(\"\\nðŸ”¹ Efficiency Metrics\")\n",
    "print(f\"ðŸ“Œ Average Latency: {avg_latency:.4f} sec (Â±{std_latency:.4f})\")\n",
    "print(f\"ðŸ“Œ Average Throughput: {avg_throughput:.2f} tokens/sec (Â±{std_throughput:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e6b846a-a7e7-4268-8c6f-f99116bf1b45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>generated_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good afternoon, champ, how you holding up? Goo...</td>\n",
       "      <td>Subjective:\\n- Symptoms: Lower back pain, radi...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What brings you in here today? Hi, I'm um, I'm...</td>\n",
       "      <td>Subjective:\\n- Presenting with dry cough for 1...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  Good afternoon, champ, how you holding up? Goo...   \n",
       "1  What brings you in here today? Hi, I'm um, I'm...   \n",
       "\n",
       "                                              output generated_summary  \n",
       "0  Subjective:\\n- Symptoms: Lower back pain, radi...                    \n",
       "1  Subjective:\\n- Presenting with dry cough for 1...                    "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b36dd-f2ec-4d6a-935c-8fd2d7861b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
