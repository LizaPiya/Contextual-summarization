{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1da8995e-3813-48b0-a0e1-16fca6c4a87a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q nltk bert-score\n",
    "!pip install -q rouge-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e1fa7dd-ff40-4137-b930-fd164917f7c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  \\\n",
      "0  Good afternoon, champ, how you holding up? Goo...   \n",
      "1  What brings you in here today? Hi, I'm um, I'm...   \n",
      "2  Do you have any known allergies to medications...   \n",
      "3  How may I help you today? Yeah I've had, a fev...   \n",
      "4  It sounds like that you're experiencing some c...   \n",
      "\n",
      "                                        reduced_text  \\\n",
      "0  <|begin_of_text|>Good afternoon, champ, how yo...   \n",
      "1  <|begin_of_text|>What brings you in here today...   \n",
      "2  <|begin_of_text|>Do you have any known allergi...   \n",
      "3  <|begin_of_text|>How may I help you today? Yea...   \n",
      "4  <|begin_of_text|>It sounds like that you're ex...   \n",
      "\n",
      "                                              output  \\\n",
      "0  Subjective:\\n- Symptoms: Lower back pain, radi...   \n",
      "1  Subjective:\\n- Presenting with dry cough for 1...   \n",
      "2  Subjective:\\n- No known allergies to medicatio...   \n",
      "3  Subjective:\\n- Fever and dry cough started 4 d...   \n",
      "4  Subjective:\\n- Presenting with chest pain for ...   \n",
      "\n",
      "                                   generated_summary  \n",
      "0  A 75-year-old man presents with chronic lower ...  \n",
      "1  smell was fine, but now it's gone. Okay, okay....  \n",
      "2  A 35-year-old woman presents with symptoms of ...  \n",
      "3  A 35-year-old male patient presents with a 4-d...  \n",
      "4  least. OK, thank you for taking care of me today.  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the saved CSV file\n",
    "generated_summaries_soap_cptf = pd.read_csv(\"soap_cptf_generated_summaries.csv\")\n",
    "\n",
    "# Verify the data\n",
    "print(generated_summaries_soap_cptf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db6cc07-e110-46e0-be07-49463df02abc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  \\\n",
      "0  Good afternoon, champ, how you holding up? Goo...   \n",
      "1  What brings you in here today? Hi, I'm um, I'm...   \n",
      "2  Do you have any known allergies to medications...   \n",
      "3  How may I help you today? Yeah I've had, a fev...   \n",
      "4  It sounds like that you're experiencing some c...   \n",
      "\n",
      "                                        reduced_text  \\\n",
      "0  <|begin_of_text|>Good afternoon, champ, how yo...   \n",
      "1  <|begin_of_text|>What brings you in here today...   \n",
      "2  <|begin_of_text|>Do you have any known allergi...   \n",
      "3  <|begin_of_text|>How may I help you today? Yea...   \n",
      "4  <|begin_of_text|>It sounds like that you're ex...   \n",
      "\n",
      "                                              output  \\\n",
      "0  Subjective:\\n- Symptoms: Lower back pain, radi...   \n",
      "1  Subjective:\\n- Presenting with dry cough for 1...   \n",
      "2  Subjective:\\n- No known allergies to medicatio...   \n",
      "3  Subjective:\\n- Fever and dry cough started 4 d...   \n",
      "4  Subjective:\\n- Presenting with chest pain for ...   \n",
      "\n",
      "                                   generated_summary  \n",
      "0  A 75-year-old man presents with chronic lower ...  \n",
      "1  smell was fine, but now it's gone. Okay, okay....  \n",
      "2  A 35-year-old woman presents with symptoms of ...  \n",
      "3  A 35-year-old male patient presents with a 4-d...  \n",
      "4  least. OK, thank you for taking care of me today.  \n",
      "Computing BLEU and ROUGE-L scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|██████████| 100/100 [00:00<00:00, 126.91row/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing BERTScore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics (in percentages):\n",
      "Average BLEU-1: 8.208851051696572 %\n",
      "Average BLEU-2: 3.8448874901437575 %\n",
      "Average ROUGE-L: 7.741221691094791 %\n",
      "Average BERT P: 81.58745783567429 %\n",
      "Average BERT R: 82.03968781232834 %\n",
      "Average BERT F1: 81.76511943340302 %\n",
      "\n",
      "Standard Deviations (in percentages):\n",
      "BLEU-1 Std: 8.128537406866307 %\n",
      "BLEU-2 Std: 4.619881585077747 %\n",
      "ROUGE-L Std: 5.95253886850141 %\n",
      "BERT P Std: 3.5756507924822567 %\n",
      "BERT R Std: 3.2129288011864565 %\n",
      "BERT F1 Std: 2.7931763507413065 %\n",
      "\n",
      "Results saved to 'soap_cptf_evaluation_results.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from bert_score import score\n",
    "from rouge_metric import PyRouge\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. Text Cleaning\n",
    "# -----------------------------------------------------\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and normalize text.\"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return ' '.join(text.strip().lower().split())\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. BLEU Computation\n",
    "# -----------------------------------------------------\n",
    "def compute_bleu_scores(reference, candidate):\n",
    "    smoothing_function = SmoothingFunction().method1\n",
    "    bleu1 = sentence_bleu([reference.split()], candidate.split(), weights=(1.0, 0, 0, 0), smoothing_function=smoothing_function)\n",
    "    bleu2 = sentence_bleu([reference.split()], candidate.split(), weights=(0.5, 0.5, 0, 0), smoothing_function=smoothing_function)\n",
    "    return bleu1 * 100, bleu2 * 100\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. ROUGE-L Computation\n",
    "# -----------------------------------------------------\n",
    "def compute_rouge_l(reference, candidate):\n",
    "    rouge = PyRouge(rouge_n=(1, 2), rouge_l=True, skip_gap=4)\n",
    "    scores = rouge.evaluate([candidate], [[reference]])\n",
    "    return scores['rouge-l']['f'] * 100\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. BERTScore in Batches\n",
    "# -----------------------------------------------------\n",
    "def compute_bert_score_batched(references, candidates, batch_size=32):\n",
    "    all_P, all_R, all_F1 = [], [], []\n",
    "    for i in range(0, len(references), batch_size):\n",
    "        batch_refs = references[i:i + batch_size]\n",
    "        batch_cands = candidates[i:i + batch_size]\n",
    "        P, R, F1 = score(batch_cands, batch_refs, lang=\"en\", verbose=False)\n",
    "        all_P.extend([p * 100 for p in P.tolist()])\n",
    "        all_R.extend([r * 100 for r in R.tolist()])\n",
    "        all_F1.extend([f * 100 for f in F1.tolist()])\n",
    "    return all_P, all_R, all_F1\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. Main Evaluation Function\n",
    "# -----------------------------------------------------\n",
    "def evaluate_summaries(df):\n",
    "    bleu1_scores, bleu2_scores, rouge_l_scores = [], [], []\n",
    "    print(\"Computing BLEU and ROUGE-L scores...\")\n",
    "    \n",
    "    with tqdm(total=len(df), desc=\"Processing Rows\", unit=\"row\") as pbar:\n",
    "        for _, row in df.iterrows():\n",
    "            reference = clean_text(row['output'])\n",
    "            candidate = clean_text(row['generated_summary'])\n",
    "            \n",
    "            if not reference or not candidate:\n",
    "                print(f\"Empty text - Reference: '{reference}', Candidate: '{candidate}'\")\n",
    "                bleu1_scores.append(0.0)\n",
    "                bleu2_scores.append(0.0)\n",
    "                rouge_l_scores.append(0.0)\n",
    "            else:\n",
    "                bleu1, bleu2 = compute_bleu_scores(reference, candidate)\n",
    "                bleu1_scores.append(bleu1)\n",
    "                bleu2_scores.append(bleu2)\n",
    "                rouge_l_scores.append(compute_rouge_l(reference, candidate))\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    print(\"\\nComputing BERTScore...\")\n",
    "    references = [clean_text(text) for text in df['output'].tolist()]\n",
    "    candidates = [clean_text(text) for text in df['generated_summary'].tolist()]\n",
    "    \n",
    "    bert_p, bert_r, bert_f1 = compute_bert_score_batched(references, candidates)\n",
    "    \n",
    "    df['bleu1'] = bleu1_scores\n",
    "    df['bleu2'] = bleu2_scores\n",
    "    df['rouge_l'] = rouge_l_scores\n",
    "    df['bert_p'] = bert_p\n",
    "    df['bert_r'] = bert_r\n",
    "    df['bert_f1'] = bert_f1\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(\"\\nEvaluation Metrics (in percentages):\")\n",
    "    print(\"Average BLEU-1:\", np.mean(bleu1_scores), \"%\")\n",
    "    print(\"Average BLEU-2:\", np.mean(bleu2_scores), \"%\")\n",
    "    print(\"Average ROUGE-L:\", np.mean(rouge_l_scores), \"%\")\n",
    "    print(\"Average BERT P:\", np.mean(bert_p), \"%\")\n",
    "    print(\"Average BERT R:\", np.mean(bert_r), \"%\")\n",
    "    print(\"Average BERT F1:\", np.mean(bert_f1), \"%\")\n",
    "    \n",
    "    # Print standard deviations\n",
    "    print(\"\\nStandard Deviations (in percentages):\")\n",
    "    print(\"BLEU-1 Std:\", np.std(bleu1_scores), \"%\")\n",
    "    print(\"BLEU-2 Std:\", np.std(bleu2_scores), \"%\")\n",
    "    print(\"ROUGE-L Std:\", np.std(rouge_l_scores), \"%\")\n",
    "    print(\"BERT P Std:\", np.std(bert_p), \"%\")\n",
    "    print(\"BERT R Std:\", np.std(bert_r), \"%\")\n",
    "    print(\"BERT F1 Std:\", np.std(bert_f1), \"%\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6. Load CSV & Evaluate\n",
    "# -----------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the CSV with 'input', 'output', 'generated_summary'\n",
    "    df_summaries = pd.read_csv(\"soap_cptf_generated_summaries.csv\")\n",
    "    print(df_summaries.head())\n",
    "\n",
    "    # Evaluate\n",
    "    results_df = evaluate_summaries(df_summaries)\n",
    "\n",
    "    # Save the DataFrame with the metrics\n",
    "    results_df.to_csv(\"soap_cptf_evaluation_results.csv\", index=False)\n",
    "    print(\"\\nResults saved to 'soap_cptf_evaluation_results.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a733e7ff-b8a7-44ed-b28e-896e121301a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
