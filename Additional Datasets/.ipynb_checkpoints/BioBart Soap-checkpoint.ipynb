{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ab7934d-5679-4f54-a41e-48e5f1d5898e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               input  \\\n",
      "0  Good afternoon, champ, how you holding up? Goo...   \n",
      "1  What brings you in here today? Hi, I'm um, I'm...   \n",
      "2  Do you have any known allergies to medications...   \n",
      "3  How may I help you today? Yeah I've had, a fev...   \n",
      "4  It sounds like that you're experiencing some c...   \n",
      "\n",
      "                                              output  \n",
      "0  Subjective:\\n- Symptoms: Lower back pain, radi...  \n",
      "1  Subjective:\\n- Presenting with dry cough for 1...  \n",
      "2  Subjective:\\n- No known allergies to medicatio...  \n",
      "3  Subjective:\\n- Fever and dry cough started 4 d...  \n",
      "4  Subjective:\\n- Presenting with chest pain for ...  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   input   100 non-null    object\n",
      " 1   output  100 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 1.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_sample = pd.read_csv(\"sample_summary.csv\")\n",
    "# Display the first few rows\n",
    "print(df_sample.head())\n",
    "\n",
    "# Check DataFrame info\n",
    "print(df_sample.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c941fe8-d84f-4c50-b1f5-16b89a20c9a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers huggingface_hub\n",
    "!pip install -q --upgrade accelerate\n",
    "!pip install -q -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd06c02a-66b3-4a20-afb7-a8acbbcf7737",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "# Use token from environment variable (safer)\n",
    "login(os.getenv(\"HF_TOKEN\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b93b604-a0b3-4308-9fb2-72cf22912eed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the BioBART model and tokenizer\n",
    "# Replace 'GanjinZero/biobart-large' with the desired BioBART model version\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"GanjinZero/biobart-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"GanjinZero/biobart-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1bea74-41c0-45a9-b577-f7d1c6cdb798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1. Load only first 2 rows\n",
    "# -----------------------------------------------------\n",
    "df_sample = df_sample.iloc[:2].copy()\n",
    "inputs_list = df_sample[\"input\"].tolist()\n",
    "batch_size = 1  # Keep it low for debugging and simplicity\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2. Simplified Prompt Construction (no instruction)\n",
    "# -----------------------------------------------------\n",
    "def construct_prompt(input_text):\n",
    "    return input_text.strip()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3. Generation Parameters\n",
    "# -----------------------------------------------------\n",
    "generation_params = {\n",
    "    \"do_sample\": True,\n",
    "    \"top_p\": 0.8,\n",
    "    \"temperature\": 0.1,\n",
    "    \"top_k\": 100,\n",
    "    \"max_new_tokens\": 200,\n",
    "    \"repetition_penalty\": 1.1,\n",
    "    \"eos_token_id\": tokenizer.eos_token_id\n",
    "}\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4. Inference & Efficiency Tracking\n",
    "# -----------------------------------------------------\n",
    "generated_summaries = []\n",
    "latencies = []\n",
    "throughputs = []\n",
    "\n",
    "def process_batch(batch_inputs):\n",
    "    batch_generated = []\n",
    "    total_input_tokens = 0\n",
    "\n",
    "    for text in batch_inputs:\n",
    "        prompt = construct_prompt(text)\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1000)\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
    "        prompt_length = inputs[\"input_ids\"].shape[1]\n",
    "        total_input_tokens += prompt_length\n",
    "\n",
    "        start_time = time.time()\n",
    "        summary_ids = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            **generation_params\n",
    "        )\n",
    "        end_time = time.time()\n",
    "\n",
    "        # Optional Debug: Print full decoded output\n",
    "        full_output = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        print(\"Full Output:\", full_output)\n",
    "\n",
    "        # Extract new tokens (skip prompt)\n",
    "        generated_tokens = summary_ids[0, prompt_length:]\n",
    "        generated_text = tokenizer.decode(generated_tokens, skip_special_tokens=True).strip()\n",
    "        print(\"Generated Summary:\", generated_text)  # Debug print\n",
    "\n",
    "        batch_generated.append(generated_text)\n",
    "\n",
    "        # Metrics\n",
    "        latency = end_time - start_time\n",
    "        latencies.append(latency)\n",
    "        total_tokens = prompt_length + generated_tokens.shape[0]\n",
    "        throughputs.append(total_tokens / latency)\n",
    "\n",
    "    return batch_generated\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5. Process Batches\n",
    "# -----------------------------------------------------\n",
    "with tqdm(total=len(inputs_list), desc=\"Generating Summaries\", unit=\"row\") as pbar:\n",
    "    for i in range(0, len(inputs_list), batch_size):\n",
    "        batch = inputs_list[i:i + batch_size]\n",
    "        try:\n",
    "            batch_generated = process_batch(batch)\n",
    "        except RuntimeError as e:\n",
    "            if \"out of memory\" in str(e):\n",
    "                torch.cuda.empty_cache()\n",
    "                print(\"Out of memory error; try reducing batch size.\")\n",
    "            raise e\n",
    "        generated_summaries.extend(batch_generated)\n",
    "        torch.cuda.empty_cache()\n",
    "        pbar.update(len(batch))\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6. Save Results\n",
    "# -----------------------------------------------------\n",
    "df_sample[\"generated_summary\"] = generated_summaries\n",
    "df_sample.to_csv(\"Biobart_soap_generated_summaries.csv\", index=False)\n",
    "print(\"Summaries saved to 'Biobart_soap_generated_summaries.csv'\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 7. Print Efficiency Metrics\n",
    "# -----------------------------------------------------\n",
    "avg_latency = np.mean(latencies)\n",
    "std_latency = np.std(latencies)\n",
    "avg_throughput = np.mean(throughputs)\n",
    "std_throughput = np.std(throughputs)\n",
    "\n",
    "print(\"\\nðŸ”¹ Efficiency Metrics\")\n",
    "print(f\"ðŸ“Œ Average Latency: {avg_latency:.4f} sec (Â±{std_latency:.4f})\")\n",
    "print(f\"ðŸ“Œ Average Throughput: {avg_throughput:.2f} tokens/sec (Â±{std_throughput:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6b846a-a7e7-4268-8c6f-f99116bf1b45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2b36dd-f2ec-4d6a-935c-8fd2d7861b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
