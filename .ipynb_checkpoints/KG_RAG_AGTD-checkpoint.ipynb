{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22d804c3-8eba-4c14-b353-57b67324335c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers huggingface_hub langchain_community\n",
    "!pip install -q --upgrade accelerate\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q neo4j\n",
    "!pip install -q --upgrade accelerate\n",
    "!pip install -q -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac26a41-f158-4d63-8f01-abe7b07921ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "766bfb10-6f22-4d32-85e8-0238cacb74fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19605/919926656.py:12: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
      "  neo4j_graph=Neo4jGraph(\n"
     ]
    }
   ],
   "source": [
    "## Graphdb configuration\n",
    "NEO4J_URI=\"neo4j+s://8a886660.databases.neo4j.io\"\n",
    "NEO4J_USERNAME=\"neo4j\"\n",
    "NEO4J_PASSWORD=\"9FYDkCTM2Vq4qxWFFwik0uYP6BJ-fReP9XOYj-oDqZ4\"\n",
    "\n",
    "import os\n",
    "os.environ[\"NEO4J_URI\"]=NEO4J_URI\n",
    "os.environ[\"NEO4J_USERNAME\"]=NEO4J_USERNAME\n",
    "os.environ[\"NEO4J_PASSWORD\"]=NEO4J_PASSWORD\n",
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "neo4j_graph=Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=NEO4J_USERNAME,\n",
    "    password=NEO4J_PASSWORD,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f92af386-aa87-4367-bdd4-f947d33bc123",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.graphs.neo4j_graph.Neo4jGraph at 0x7fb6602d3130>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neo4j_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb0cd37-31b1-45d0-9d9b-00ed307cf086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "# Use your Hugging Face token\n",
    "login(\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb1aefa1-194d-4e96-ad04-3adaa3da280c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment setup and quantization configuration done.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variable for better memory management\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Configure quantization (8-bit)\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_enable_fp32_cpu_offload=True\n",
    ")\n",
    "print(\"Environment setup and quantization configuration done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "023a474a-d514-457f-b68b-458871e9bcda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Model and Tokenizer:   0%|          | 0/2 [00:00<?, ?step/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d860b1dbbbea4157b19b79daca1990fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a57ff0866834d888fcfc45a2a4612bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Model and Tokenizer:  50%|█████     | 1/2 [01:10<01:10, 70.31s/step]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ea86b56cfd427e9dd4a0db331b1237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/54.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d45742ae6aed4ad7939216228764e694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59adc07f1c124b2d890fb9191dcd8a9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing Model and Tokenizer: 100%|██████████| 2/2 [01:11<00:00, 35.79s/step]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "print(\"Loading model and tokenizer...\")\n",
    "with tqdm(total=2, desc=\"Initializing Model and Tokenizer\", unit=\"step\") as pbar:\n",
    "    model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        quantization_config=quantization_config,\n",
    "        device_map=\"auto\",\n",
    "        output_attentions=True,  # Enable attention outputs for AGTD\n",
    "        return_dict_in_generate=True  # Ensures attention outputs are generated\n",
    "    )\n",
    "    pbar.update(1)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    tokenizer.padding_side = 'left'\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "    pbar.update(1)\n",
    "print(\"Model and tokenizer loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c47cd92b-5033-4232-af10-a133bc8345dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Node Types and Their Counts:\n",
      "Node Labels: ['Patient'], Count: 92\n",
      "Node Labels: ['Procedure'], Count: 352\n",
      "Node Labels: ['Diagnosis'], Count: 1425\n",
      "Node Labels: ['Drug'], Count: 618\n",
      "\n",
      "Unique Relationships and Their Counts:\n",
      "Relationship: HAS_PROCEDURE, Count: 608\n",
      "Relationship: HAS_DIAGNOSIS, Count: 3061\n",
      "Relationship: PRESCRIBED, Count: 5334\n"
     ]
    }
   ],
   "source": [
    "# Query for unique non-null nodes and their counts\n",
    "node_query = \"\"\"\n",
    "MATCH (n)\n",
    "WHERE n IS NOT NULL\n",
    "RETURN DISTINCT labels(n) AS node_labels, COUNT(n) AS count\n",
    "\"\"\"\n",
    "node_results = neo4j_graph.query(node_query)\n",
    "\n",
    "print(\"Unique Node Types and Their Counts:\")\n",
    "for record in node_results:\n",
    "    print(f\"Node Labels: {record['node_labels']}, Count: {record['count']}\")\n",
    "\n",
    "# Query for unique non-null relationships and their counts\n",
    "relationship_query = \"\"\"\n",
    "MATCH ()-[r]->()\n",
    "WHERE r IS NOT NULL\n",
    "RETURN DISTINCT type(r) AS relationship, COUNT(r) AS count\n",
    "\"\"\"\n",
    "relationship_results = neo4j_graph.query(relationship_query)\n",
    "\n",
    "print(\"\\nUnique Relationships and Their Counts:\")\n",
    "for record in relationship_results:\n",
    "    print(f\"Relationship: {record['relationship']}, Count: {record['count']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f434edfd-0f75-4e06-9cc1-8bf53253c079",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          note_id                                              input  \\\n",
      "0  16002318-DS-17  <SEX> F <SERVICE> SURGERY <ALLERGIES> Iodine /...   \n",
      "1   15638884-DS-4  <SEX> M <SERVICE> MEDICINE <ALLERGIES> Augment...   \n",
      "2  12435705-DS-14  <SEX> M <SERVICE> MEDICINE <ALLERGIES> ibuprof...   \n",
      "3   12413577-DS-4  <SEX> F <SERVICE> OBSTETRICS/GYNECOLOGY <ALLER...   \n",
      "4  17967161-DS-29  <SEX> M <SERVICE> SURGERY <ALLERGIES> lisinopr...   \n",
      "\n",
      "                                        reduced_text  \\\n",
      "0  <|begin_of_text|><SEX> F <SERVICE> SURGERY <AL...   \n",
      "1  <|begin_of_text|><SEX> M <SERVICE> MEDICINE <A...   \n",
      "2  <|begin_of_text|><SEX> M <SERVICE> MEDICINE <A...   \n",
      "3  <|begin_of_text|><SEX> F <SERVICE> OBSTETRICS/...   \n",
      "4  <|begin_of_text|><SEX> M <SERVICE> SURGERY <AL...   \n",
      "\n",
      "                                            entities  \\\n",
      "0  {'PROBLEM': ['101', '7 pound weight loss', 'a ...   \n",
      "1  {'PROBLEM': ['+', '-', '1 cm area', 'a \" cyst ...   \n",
      "2  {'PROBLEM': ['a 0. 7 x 0. 7 x 0. 7 cm simple c...   \n",
      "3  {'PROBLEM': ['a third - degree uterine prolaps...   \n",
      "4  {'PROBLEM': ['101', 'abuse', 'acute pancreatit...   \n",
      "\n",
      "                                            problems  \\\n",
      "0  ['101', '7 pound weight loss', 'a fever', 'a l...   \n",
      "1  ['+', '-', '1 cm area', 'a \" cyst \"', 'a 2cm d...   \n",
      "2  ['a 0. 7 x 0. 7 x 0. 7 cm simple cyst', 'a 2. ...   \n",
      "3  ['a third - degree uterine prolapse', 'abnorma...   \n",
      "4  ['101', 'abuse', 'acute pancreatitis', 'angina...   \n",
      "\n",
      "                                          treatments  \\\n",
      "0  ['abdominal exercises', 'albuterol sulfate', '...   \n",
      "1  ['a bankart repair', 'a nicotine patch', 'a st...   \n",
      "2  ['2', 'a prolonged course', 'ampicillin', 'ant...   \n",
      "3  ['a stool softener', 'acetaminophen', 'admissi...   \n",
      "4  ['a', 'a 3 mm x 40 mm balloon percutaneous tra...   \n",
      "\n",
      "                                               tests  \n",
      "0         ['b12', 'bmi', 'calcium', 'physical exam']  \n",
      "1  ['.', '_', 'a', 'a ct scan', 'absbaso', 'abseo...  \n",
      "2  ['16s rdna primer set', 'aa', 'abl', 'acid fas...  \n",
      "3  ['hct', 'hgb', 'mch', 'mchc', 'mcv', 'nadr', '...  \n",
      "4  ['angap', 'blood', 'blood calcium', 'blood ck ...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the CSV file\n",
    "merged_df = pd.read_csv(\"merged_data.csv\")\n",
    "\n",
    "# Check the data\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b0e77cb-9af2-4748-9f12-f96fe67114bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ['101', '7 pound weight loss', 'a fever', 'a l...\n",
      "1    ['+', '-', '1 cm area', 'a \" cyst \"', 'a 2cm d...\n",
      "2    ['a 0. 7 x 0. 7 x 0. 7 cm simple cyst', 'a 2. ...\n",
      "3    ['a third - degree uterine prolapse', 'abnorma...\n",
      "4    ['101', 'abuse', 'acute pancreatitis', 'angina...\n",
      "Name: problems, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(merged_df['problems'].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "912af50a-8364-44d1-8785-16df220d75f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note_id                                            16956007-DS-20\n",
      "input           <SEX> M <SERVICE> SURGERY <ALLERGIES> Codeine ...\n",
      "reduced_text    <|begin_of_text|><SEX> M <SERVICE> SURGERY <AL...\n",
      "entities        {'PROBLEM': ['/ yellow / malodorous drainage',...\n",
      "problems        ['/ yellow / malodorous drainage', '5 x 8. 6 c...\n",
      "treatments      ['a completion colectomy', 'a new ileostomy', ...\n",
      "tests           ['a chest cat scan', 'absbaso', 'abseos', 'abs...\n",
      "Name: 5, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.iloc[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba24f603-2ebf-4594-a491-e724566e3127",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Iterate over the rows of the dataframe with a progress bar\n",
    "for index, row in tqdm(merged_df.iterrows(), total=len(merged_df), desc=\"Processing rows\"):\n",
    "    # Extract entities for the current row\n",
    "    problems = row['problems']\n",
    "    treatments = row['treatments']\n",
    "    tests = row['tests']\n",
    "    \n",
    "    # Build Cypher queries dynamically for subgraphs\n",
    "    problem_query = f\"\"\"\n",
    "    MATCH (n:Diagnosis)\n",
    "    WHERE any(x IN {problems} WHERE toLower(n.title) CONTAINS toLower(x))\n",
    "    OPTIONAL MATCH (n)-[r]-(connected)\n",
    "    RETURN n AS diagnosis, r, connected\n",
    "    \"\"\"\n",
    "    \n",
    "    treatment_procedure_query = f\"\"\"\n",
    "    MATCH (n:Procedure)\n",
    "    WHERE any(x IN {treatments} WHERE toLower(n.title) CONTAINS toLower(x))\n",
    "    OPTIONAL MATCH (n)-[r]-(connected)\n",
    "    RETURN n AS procedure, r, connected\n",
    "    \"\"\"\n",
    "    \n",
    "    treatment_drug_query = f\"\"\"\n",
    "    MATCH (n:Drug)\n",
    "    WHERE any(x IN {treatments} WHERE toLower(n.name) CONTAINS toLower(x))\n",
    "    OPTIONAL MATCH (n)-[r]-(connected)\n",
    "    RETURN n AS drug, r, connected\n",
    "    \"\"\"\n",
    "    \n",
    "    test_query = f\"\"\"\n",
    "    MATCH (n:Procedure)\n",
    "    WHERE any(x IN {tests} WHERE toLower(n.title) CONTAINS toLower(x))\n",
    "    OPTIONAL MATCH (n)-[r]-(connected)\n",
    "    RETURN n AS test, r, connected\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute queries to extract subgraphs\n",
    "    problem_context = neo4j_graph.query(problem_query)\n",
    "    treatment_procedure_context = neo4j_graph.query(treatment_procedure_query)\n",
    "    treatment_drug_context = neo4j_graph.query(treatment_drug_query)\n",
    "    test_context = neo4j_graph.query(test_query)\n",
    "    \n",
    "    # Print results for the subgraphs\n",
    "    print(f\"\\nRow {index} Subgraphs:\")\n",
    "    print(\"Problems (Diagnosis Subgraph):\", problem_context)\n",
    "    print(\"Treatments (Procedure Subgraph):\", treatment_procedure_context)\n",
    "    print(\"Treatments (Drug Subgraph):\", treatment_drug_context)\n",
    "    print(\"Tests (Procedure Subgraph):\", test_context)\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf7413-ee59-4a5d-9672-f1779bb65752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9a1597-2b71-4f51-9863-a60bdf55c565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0904aef8-d909-40cb-833a-f4ee2413af69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0027504d-e7a7-4798-84fd-d894cd75d2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d843c56-0278-4d3c-b7e2-da261c82cacf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e53592-3ea6-4079-8996-e78b9a9657dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_summary(input_text, model, tokenizer, generation_params):\n",
    "    \"\"\"\n",
    "    Generate a summary using the LLaMA model.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): Combined input of reduced text and KG context.\n",
    "        model: Pretrained LLaMA model.\n",
    "        tokenizer: Tokenizer for the LLaMA model.\n",
    "        generation_params (dict): Parameters for text generation.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated summary.\n",
    "    \"\"\"\n",
    "    # Tokenize the input\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=2048).to(model.device)\n",
    "\n",
    "    # Generate the summary\n",
    "    outputs = model.generate(**inputs, **generation_params)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
