{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82b70b59-330f-4c29-bce2-ffade9f15a11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bert-score) (2.2.2)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bert-score) (2.2.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bert-score) (4.47.1)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bert-score) (1.26.4)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bert-score) (2.32.3)\n",
      "Requirement already satisfied: matplotlib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bert-score) (3.9.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from bert-score) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.9->bert-score) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.2)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.12.2)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.13.3)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2024.10.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.27.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (4.55.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib->bert-score) (11.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->bert-score) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->bert-score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->bert-score) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->bert-score) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "Installing collected packages: nltk, bert-score\n",
      "Successfully installed bert-score-0.3.13 nltk-3.9.1\n",
      "Collecting rouge-metric\n",
      "  Downloading rouge_metric-1.0.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Downloading rouge_metric-1.0.1-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: rouge-metric\n",
      "Successfully installed rouge-metric-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk bert-score\n",
    "!pip install rouge-metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "416553b1-6d47-4441-8303-68d4c28941e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          note_id                                              input  \\\n",
      "0  16002318-DS-17  <SEX> F <SERVICE> SURGERY <ALLERGIES> Iodine /...   \n",
      "1   15638884-DS-4  <SEX> M <SERVICE> MEDICINE <ALLERGIES> Augment...   \n",
      "2  12435705-DS-14  <SEX> M <SERVICE> MEDICINE <ALLERGIES> ibuprof...   \n",
      "3   12413577-DS-4  <SEX> F <SERVICE> OBSTETRICS/GYNECOLOGY <ALLER...   \n",
      "4  17967161-DS-29  <SEX> M <SERVICE> SURGERY <ALLERGIES> lisinopr...   \n",
      "\n",
      "                                              target  input_tokens  \\\n",
      "0  This is a ___ yo F admitted to the hospital af...          1195   \n",
      "1  Mr. ___ is a ___ yo man with CAD with prior MI...          3496   \n",
      "2  Mr. ___ is a ___ w/ Ph+ve ALL on dasatanib and...          5591   \n",
      "3  On ___, Ms. ___ was admitted to the gynecology...          1119   \n",
      "4  Mr. ___ underwent an angiogram on ___ which sh...          3307   \n",
      "\n",
      "   target_tokens                                  generated_summary  \n",
      "0             75  The patient was admitted to oncology for worse...  \n",
      "1           1143  The patient underwent multiple tests, includin...  \n",
      "2           1098  The patient has undergone multiple surgeries i...  \n",
      "3            221  Patient presents with worsening back pain and ...  \n",
      "4            439  The patient was admitted to the hospital for w...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the saved CSV file\n",
    "Summaries_mimic_iv_bhc_100 = pd.read_csv(\"generated_summaries_100.csv\")\n",
    "\n",
    "# Verify the data\n",
    "print(Summaries_mimic_iv_bhc_100.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b80c9d1-16eb-4c0b-87e3-621fadfe9fda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "note_id              100\n",
       "input                100\n",
       "target               100\n",
       "input_tokens         100\n",
       "target_tokens         91\n",
       "generated_summary    100\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Summaries_mimic_iv_bhc_100.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ff9a7f6-a6d5-4bb8-b0b3-530a0a39263e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing BLEU and ROUGE-L scores...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Rows: 100%|██████████| 100/100 [00:02<00:00, 40.93row/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing BERTScore...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics (in percentages):\n",
      "Average BLEU-1: 7.284832167324136 %\n",
      "Average BLEU-2: 2.4818067422324237 %\n",
      "Average ROUGE-L: 9.312870433838427 %\n",
      "Average BERT P: 83.21119695901871 %\n",
      "Average BERT R: 79.79812425374985 %\n",
      "Average BERT F1: 81.44592022895813 %\n",
      "\n",
      "Standard Deviations (in percentages):\n",
      "BLEU-1 Std: 7.649636790251475 %\n",
      "BLEU-2 Std: 2.814637102989439 %\n",
      "ROUGE-L Std: 3.1379641820805078 %\n",
      "BERT F1 Std: 1.3877161362847719 %\n",
      "\n",
      "Results saved to 'evaluation_results.csv'\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from bert_score import score\n",
    "from rouge_metric import PyRouge\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean and normalize text.\"\"\"\n",
    "    if pd.isna(text) or not isinstance(text, str):\n",
    "        return \"\"\n",
    "    return ' '.join(text.strip().lower().split())  # Lowercase, strip spaces, normalize.\n",
    "\n",
    "def compute_bleu_scores(reference, candidate):\n",
    "    \"\"\"Compute BLEU-1 and BLEU-2 scores.\"\"\"\n",
    "    try:\n",
    "        smoothing_function = SmoothingFunction().method1\n",
    "        # Compute BLEU-1\n",
    "        bleu1 = sentence_bleu(\n",
    "            [reference.split()],\n",
    "            candidate.split(),\n",
    "            weights=(1.0, 0, 0, 0),  # Only unigrams\n",
    "            smoothing_function=smoothing_function\n",
    "        )\n",
    "        # Compute BLEU-2\n",
    "        bleu2 = sentence_bleu(\n",
    "            [reference.split()],\n",
    "            candidate.split(),\n",
    "            weights=(0.5, 0.5, 0, 0),  # Unigrams and bigrams only\n",
    "            smoothing_function=smoothing_function\n",
    "        )\n",
    "        return bleu1 * 100, bleu2 * 100  # Convert to percentages\n",
    "    except Exception as e:\n",
    "        print(f\"BLEU Error: {e}\")\n",
    "        print(f\"Reference: '{reference[:50]}...'\")\n",
    "        print(f\"Candidate: '{candidate[:50]}...'\")\n",
    "        return 0.0, 0.0\n",
    "\n",
    "def compute_rouge_l(reference, candidate):\n",
    "    \"\"\"Compute ROUGE-L score.\"\"\"\n",
    "    rouge = PyRouge(rouge_n=(1, 2), rouge_l=True, rouge_w=False,\n",
    "                    rouge_w_weight=1.2, rouge_s=False, rouge_su=False, skip_gap=4)\n",
    "    try:\n",
    "        scores = rouge.evaluate([candidate], [[reference]])\n",
    "        return scores['rouge-l']['f'] * 100  # Convert to percentage\n",
    "    except Exception as e:\n",
    "        print(f\"ROUGE-L Error: {e}\")\n",
    "        print(f\"Reference: '{reference[:50]}...'\")\n",
    "        print(f\"Candidate: '{candidate[:50]}...'\")\n",
    "        return 0.0\n",
    "\n",
    "def compute_bert_score_batched(references, candidates, batch_size=32):\n",
    "    \"\"\"Compute BERTScore in batches.\"\"\"\n",
    "    all_P, all_R, all_F1 = [], [], []\n",
    "    for i in range(0, len(references), batch_size):\n",
    "        batch_refs = references[i:i + batch_size]\n",
    "        batch_cands = candidates[i:i + batch_size]\n",
    "        try:\n",
    "            P, R, F1 = score(batch_cands, batch_refs, lang=\"en\", verbose=False)\n",
    "            all_P.extend([p * 100 for p in P.tolist()])  # Convert to percentages\n",
    "            all_R.extend([r * 100 for r in R.tolist()])  # Convert to percentages\n",
    "            all_F1.extend([f * 100 for f in F1.tolist()])  # Convert to percentages\n",
    "        except Exception as e:\n",
    "            print(f\"BERTScore Error in batch {i}: {e}\")\n",
    "            batch_len = len(batch_refs)\n",
    "            all_P.extend([0.0] * batch_len)\n",
    "            all_R.extend([0.0] * batch_len)\n",
    "            all_F1.extend([0.0] * batch_len)\n",
    "    return all_P, all_R, all_F1\n",
    "\n",
    "def evaluate_summaries(df):\n",
    "    bleu1_scores, bleu2_scores, rouge_l_scores = [], [], []\n",
    "    print(\"Computing BLEU and ROUGE-L scores...\")\n",
    "    \n",
    "    with tqdm(total=len(df), desc=\"Processing Rows\", unit=\"row\") as pbar:\n",
    "        for _, row in df.iterrows():\n",
    "            reference = clean_text(row['target'])\n",
    "            candidate = clean_text(row['generated_summary'])\n",
    "            \n",
    "            if not reference or not candidate:\n",
    "                print(f\"Empty text - Reference: '{reference}', Candidate: '{candidate}'\")\n",
    "                bleu1_scores.append(0.0)\n",
    "                bleu2_scores.append(0.0)\n",
    "                rouge_l_scores.append(0.0)\n",
    "            else:\n",
    "                bleu1, bleu2 = compute_bleu_scores(reference, candidate)\n",
    "                bleu1_scores.append(bleu1)\n",
    "                bleu2_scores.append(bleu2)\n",
    "                rouge_l_scores.append(compute_rouge_l(reference, candidate))\n",
    "            \n",
    "            pbar.update(1)\n",
    "    \n",
    "    print(\"\\nComputing BERTScore...\")\n",
    "    references = [clean_text(text) for text in df['target'].tolist()]\n",
    "    candidates = [clean_text(text) for text in df['generated_summary'].tolist()]\n",
    "    bert_p, bert_r, bert_f1 = compute_bert_score_batched(references, candidates)\n",
    "    \n",
    "    # Add all scores to DataFrame\n",
    "    df['bleu1'] = bleu1_scores\n",
    "    df['bleu2'] = bleu2_scores\n",
    "    df['rouge_l'] = rouge_l_scores\n",
    "    df['bert_p'] = bert_p\n",
    "    df['bert_r'] = bert_r\n",
    "    df['bert_f1'] = bert_f1\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(\"\\nEvaluation Metrics (in percentages):\")\n",
    "    print(\"Average BLEU-1:\", df['bleu1'].mean(), \"%\")\n",
    "    print(\"Average BLEU-2:\", df['bleu2'].mean(), \"%\")\n",
    "    print(\"Average ROUGE-L:\", df['rouge_l'].mean(), \"%\")\n",
    "    print(\"Average BERT P:\", df['bert_p'].mean(), \"%\")\n",
    "    print(\"Average BERT R:\", df['bert_r'].mean(), \"%\")\n",
    "    print(\"Average BERT F1:\", df['bert_f1'].mean(), \"%\")\n",
    "    \n",
    "    # Print standard deviations\n",
    "    print(\"\\nStandard Deviations (in percentages):\")\n",
    "    print(\"BLEU-1 Std:\", df['bleu1'].std(), \"%\")\n",
    "    print(\"BLEU-2 Std:\", df['bleu2'].std(), \"%\")\n",
    "    print(\"ROUGE-L Std:\", df['rouge_l'].std(), \"%\")\n",
    "    print(\"BERT F1 Std:\", df['bert_f1'].std(), \"%\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run the evaluation\n",
    "try:\n",
    "    Summaries_mimic_iv_bhc_100 = evaluate_summaries(Summaries_mimic_iv_bhc_100)\n",
    "    Summaries_mimic_iv_bhc_100.to_csv(\"evaluation_results.csv\", index=False)\n",
    "    print(\"\\nResults saved to 'evaluation_results.csv'\")\n",
    "except Exception as e:\n",
    "    print(f\"Error in evaluation process: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01069a88-ceb0-4dfc-b2b0-910feb3bd23f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
